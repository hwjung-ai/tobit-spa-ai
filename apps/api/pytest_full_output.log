============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-9.0.2, pluggy-1.6.0 -- /home/spa/tobit-spa-ai/apps/api/.venv/bin/python3.12
cachedir: .pytest_cache
rootdir: /home/spa/tobit-spa-ai/apps/api
configfile: pytest.ini
testpaths: tests
plugins: anyio-4.12.1, langsmith-0.6.3, asyncio-1.3.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 392 items

tests/test_api_keys.py::TestApiKeyGeneration::test_generate_api_key PASSED [  0%]
tests/test_api_keys.py::TestApiKeyGeneration::test_generate_unique_keys PASSED [  0%]
tests/test_api_keys.py::TestApiKeyCrud::test_create_api_key PASSED       [  0%]
tests/test_api_keys.py::TestApiKeyCrud::test_create_api_key_with_expiration PASSED [  1%]
tests/test_api_keys.py::TestApiKeyCrud::test_validate_api_key_valid PASSED [  1%]
tests/test_api_keys.py::TestApiKeyCrud::test_validate_api_key_invalid PASSED [  1%]
tests/test_api_keys.py::TestApiKeyCrud::test_validate_api_key_expired FAILED [  1%]
tests/test_api_keys.py::TestApiKeyCrud::test_validate_api_key_inactive PASSED [  2%]
tests/test_api_keys.py::TestApiKeyCrud::test_get_api_key PASSED          [  2%]
tests/test_api_keys.py::TestApiKeyCrud::test_get_api_key_wrong_user PASSED [  2%]
tests/test_api_keys.py::TestApiKeyCrud::test_list_api_keys PASSED        [  2%]
tests/test_api_keys.py::TestApiKeyCrud::test_list_api_keys_exclude_inactive PASSED [  3%]
tests/test_api_keys.py::TestApiKeyCrud::test_list_api_keys_include_inactive PASSED [  3%]
tests/test_api_keys.py::TestApiKeyCrud::test_revoke_api_key PASSED       [  3%]
tests/test_api_keys.py::TestApiKeyCrud::test_revoke_nonexistent_key PASSED [  3%]
tests/test_api_keys.py::TestApiKeyScopes::test_get_api_key_scopes PASSED [  4%]
tests/test_api_keys.py::TestApiKeyScopes::test_has_scope_true PASSED     [  4%]
tests/test_api_keys.py::TestApiKeyScopes::test_has_scope_false PASSED    [  4%]
tests/test_api_keys.py::TestApiKeysRouter::test_create_api_key_endpoint PASSED [  4%]
tests/test_api_keys.py::TestApiKeysRouter::test_list_api_keys_endpoint PASSED [  5%]
tests/test_api_keys.py::TestApiKeysRouter::test_revoke_api_key_endpoint PASSED [  5%]
tests/test_asset_models.py::TestSourceAsset::test_source_type_enum PASSED [  5%]
tests/test_asset_models.py::TestSourceAsset::test_source_connection_creation PASSED [  5%]
tests/test_asset_models.py::TestSourceAsset::test_source_connection_defaults PASSED [  6%]
tests/test_asset_models.py::TestSourceAsset::test_source_asset_creation PASSED [  6%]
tests/test_asset_models.py::TestSourceAsset::test_source_asset_spec_json_pattern PASSED [  6%]
tests/test_asset_models.py::TestSchemaAsset::test_schema_column_creation PASSED [  6%]
tests/test_asset_models.py::TestSchemaAsset::test_schema_table_creation PASSED [  7%]
tests/test_asset_models.py::TestSchemaAsset::test_schema_catalog_creation PASSED [  7%]
tests/test_asset_models.py::TestSchemaAsset::test_schema_catalog_computed_properties PASSED [  7%]
tests/test_asset_models.py::TestSchemaAsset::test_schema_catalog_get_table PASSED [  7%]
tests/test_asset_models.py::TestSchemaAsset::test_schema_asset_creation PASSED [  8%]
tests/test_asset_models.py::TestSchemaAsset::test_schema_asset_spec_json_pattern PASSED [  8%]
tests/test_asset_models.py::TestResolverAsset::test_resolver_type_enum PASSED [  8%]
tests/test_asset_models.py::TestResolverAsset::test_alias_mapping_creation PASSED [  8%]
tests/test_asset_models.py::TestResolverAsset::test_pattern_rule_creation PASSED [  9%]
tests/test_asset_models.py::TestResolverAsset::test_transformation_rule_creation PASSED [  9%]
tests/test_asset_models.py::TestResolverAsset::test_resolver_rule_with_alias PASSED [  9%]
tests/test_asset_models.py::TestResolverAsset::test_resolver_config_creation PASSED [  9%]
tests/test_asset_models.py::TestResolverAsset::test_resolver_config_get_rule_by_name PASSED [ 10%]
tests/test_asset_models.py::TestResolverAsset::test_resolver_config_get_rules_by_type PASSED [ 10%]
tests/test_asset_models.py::TestResolverAsset::test_resolver_config_add_remove_rule PASSED [ 10%]
tests/test_asset_models.py::TestResolverAsset::test_resolver_asset_creation PASSED [ 10%]
tests/test_asset_models.py::TestResolverAsset::test_rule_priority_ordering PASSED [ 11%]
tests/test_asset_models.py::TestAssetIntegration::test_source_to_schema_reference PASSED [ 11%]
tests/test_asset_models.py::TestAssetIntegration::test_resolver_with_multiple_rule_types PASSED [ 11%]
tests/test_audit_log.py::test_list_audit_logs_returns_matching_entries FAILED [ 11%]
tests/test_audit_log.py::test_get_audit_logs_by_trace_and_parent FAILED  [ 12%]
tests/test_chat_stream.py::test_chat_stream_returns_answer_chunk PASSED  [ 12%]
tests/test_ci_exact_candidate.py::test_find_exact_candidate_matches_ci_name_case_insensitive PASSED [ 12%]
tests/test_ci_exact_candidate.py::test_find_exact_candidate_matches_ci_code PASSED [ 13%]
tests/test_ci_exact_candidate.py::test_find_exact_candidate_returns_none_when_no_exact_match PASSED [ 13%]
tests/test_ci_list_llm_output.py::test_llm_list_payload_forces_list_intent PASSED [ 13%]
tests/test_ci_list_llm_output.py::test_llm_list_default_limit_applies PASSED [ 13%]
tests/test_ci_management.py::TestCIChangeCreation::test_create_change_basic ERROR [ 14%]
tests/test_ci_management.py::TestCIChangeCreation::test_create_change_minimal ERROR [ 14%]
tests/test_ci_management.py::TestCIChangeCreation::test_create_change_all_types ERROR [ 14%]
tests/test_ci_management.py::TestCIChangeCreation::test_get_change_by_id ERROR [ 14%]
tests/test_ci_management.py::TestCIChangeCreation::test_get_change_not_found ERROR [ 15%]
tests/test_ci_management.py::TestCIChangeCreation::test_list_changes_all ERROR [ 15%]
tests/test_ci_management.py::TestCIChangeCreation::test_list_changes_filter_by_ci_id ERROR [ 15%]
tests/test_ci_management.py::TestCIChangeCreation::test_list_changes_filter_by_status ERROR [ 15%]
tests/test_ci_management.py::TestCIChangeCreation::test_list_changes_pagination ERROR [ 16%]
tests/test_ci_management.py::TestCIChangeApproval::test_approve_change ERROR [ 16%]
tests/test_ci_management.py::TestCIChangeApproval::test_reject_change ERROR [ 16%]
tests/test_ci_management.py::TestCIChangeApproval::test_approve_non_existent_change ERROR [ 16%]
tests/test_ci_management.py::TestCIChangeApproval::test_apply_change ERROR [ 17%]
tests/test_ci_management.py::TestCIChangeApproval::test_apply_unapproved_change_fails ERROR [ 17%]
tests/test_ci_management.py::TestCIChangeHistory::test_get_change_history_single_ci ERROR [ 17%]
tests/test_ci_management.py::TestCIChangeHistory::test_change_history_counts ERROR [ 17%]
tests/test_ci_management.py::TestCIChangeHistory::test_change_history_pending_approvals ERROR [ 18%]
tests/test_ci_management.py::TestCIIntegrityValidation::test_create_integrity_issue ERROR [ 18%]
tests/test_ci_management.py::TestCIIntegrityValidation::test_get_integrity_issues ERROR [ 18%]
tests/test_ci_management.py::TestCIIntegrityValidation::test_filter_integrity_issues_unresolved ERROR [ 18%]
tests/test_ci_management.py::TestCIIntegrityValidation::test_resolve_integrity_issue ERROR [ 19%]
tests/test_ci_management.py::TestCIIntegrityValidation::test_validate_ci_integrity ERROR [ 19%]
tests/test_ci_management.py::TestCIIntegrityValidation::test_get_integrity_summary ERROR [ 19%]
tests/test_ci_management.py::TestCIDuplicateDetection::test_create_duplicate_entry ERROR [ 19%]
tests/test_ci_management.py::TestCIDuplicateDetection::test_get_duplicates_for_ci ERROR [ 20%]
tests/test_ci_management.py::TestCIDuplicateDetection::test_confirm_duplicate ERROR [ 20%]
tests/test_ci_management.py::TestCIDuplicateDetection::test_duplicate_statistics ERROR [ 20%]
tests/test_ci_management.py::TestCIChangeStatistics::test_get_change_statistics ERROR [ 20%]
tests/test_ci_management.py::TestCIChangeStatistics::test_change_statistics_time_range ERROR [ 21%]
tests/test_ci_management.py::TestCIIntegrationWorkflow::test_complete_change_workflow ERROR [ 21%]
tests/test_ci_management.py::TestCIIntegrationWorkflow::test_duplicate_detection_to_merge_workflow ERROR [ 21%]
tests/test_ci_management.py::TestCIIntegrationWorkflow::test_integrity_validation_workflow ERROR [ 21%]
tests/test_ci_management.py::TestTenantIsolation::test_changes_isolated_by_tenant ERROR [ 22%]
tests/test_ci_management.py::TestTenantIsolation::test_issues_isolated_by_tenant ERROR [ 22%]
tests/test_ci_management.py::TestTenantIsolation::test_duplicates_isolated_by_tenant ERROR [ 22%]
tests/test_ci_runner_tool_contracts.py::TestToolCallContract::test_tool_call_creation PASSED [ 22%]
tests/test_ci_runner_tool_contracts.py::TestToolCallContract::test_tool_call_with_error PASSED [ 23%]
tests/test_ci_runner_tool_contracts.py::TestToolCallContract::test_tool_call_serialization PASSED [ 23%]
tests/test_ci_runner_tool_contracts.py::TestToolCallContract::test_tool_call_default_values PASSED [ 23%]
tests/test_ci_runner_tool_contracts.py::TestToolCallTrace::test_multiple_tool_calls_accumulation PASSED [ 23%]
tests/test_ci_runner_tool_contracts.py::TestToolCallTrace::test_tool_calls_with_errors PASSED [ 24%]
tests/test_ci_runner_tool_contracts.py::TestReferenceExtraction::test_extract_references_from_dict_blocks PASSED [ 24%]
tests/test_ci_runner_tool_contracts.py::TestReferenceExtraction::test_no_references_in_blocks PASSED [ 24%]
tests/test_ci_runner_tool_contracts.py::TestReferenceExtraction::test_multiple_reference_blocks PASSED [ 25%]
tests/test_control_loop.py::TestControlLoopPolicy::test_policy_creation PASSED [ 25%]
tests/test_control_loop.py::TestControlLoopPolicy::test_policy_defaults PASSED [ 25%]
tests/test_control_loop.py::TestControlLoopPolicy::test_policy_validation_success PASSED [ 25%]
tests/test_control_loop.py::TestControlLoopPolicy::test_policy_validation_negative_max_replans PASSED [ 26%]
tests/test_control_loop.py::TestControlLoopPolicy::test_policy_validation_negative_interval PASSED [ 26%]
tests/test_control_loop.py::TestControlLoopPolicy::test_policy_validation_negative_cooling_period PASSED [ 26%]
tests/test_control_loop.py::TestControlLoopPolicy::test_policy_validation_interval_greater_than_cooling PASSED [ 26%]
tests/test_control_loop.py::TestControlLoopRuntime::test_runtime_creation PASSED [ 27%]
tests/test_control_loop.py::TestControlLoopRuntime::test_should_replan_allowed_trigger PASSED [ 27%]
tests/test_control_loop.py::TestControlLoopRuntime::test_should_replan_disallowed_trigger PASSED [ 27%]
tests/test_control_loop.py::TestControlLoopRuntime::test_should_replan_max_replans_exceeded PASSED [ 27%]
tests/test_control_loop.py::TestControlLoopRuntime::test_should_replan_min_interval_not_met PASSED [ 28%]
tests/test_control_loop.py::TestControlLoopRuntime::test_should_replan_cooling_period_active PASSED [ 28%]
tests/test_control_loop.py::TestControlLoopRuntime::test_should_replan_critical_severity_override PASSED [ 28%]
tests/test_control_loop.py::TestControlLoopRuntime::test_record_replan PASSED [ 28%]
tests/test_control_loop.py::TestControlLoopRuntime::test_trigger_counts_tracking PASSED [ 29%]
tests/test_control_loop.py::TestControlLoopRuntime::test_get_stats PASSED [ 29%]
tests/test_control_loop.py::TestControlLoopRuntime::test_should_replan_with_string_trigger PASSED [ 29%]
tests/test_control_loop.py::TestControlLoopRuntime::test_multiple_replans_sequence PASSED [ 29%]
tests/test_control_loop.py::TestReplanEventSchema::test_replan_event_creation PASSED [ 30%]
tests/test_control_loop.py::TestReplanEventSchema::test_replan_patch_diff PASSED [ 30%]
tests/test_control_loop.py::TestReplanEventSchema::test_replan_trigger_structure PASSED [ 30%]
tests/test_documents.py::test_upload_creates_metadata_and_list ERROR     [ 30%]
tests/test_documents.py::test_document_stream_done_contains_references ERROR [ 31%]
tests/test_encryption.py::TestEncryptionManager::test_generate_key PASSED [ 31%]
tests/test_encryption.py::TestEncryptionManager::test_encrypt_plaintext PASSED [ 31%]
tests/test_encryption.py::TestEncryptionManager::test_decrypt_ciphertext PASSED [ 31%]
tests/test_encryption.py::TestEncryptionManager::test_encrypt_decrypt_roundtrip PASSED [ 32%]
tests/test_encryption.py::TestEncryptionManager::test_encrypt_none_raises_error PASSED [ 32%]
tests/test_encryption.py::TestEncryptionManager::test_decrypt_none_raises_error PASSED [ 32%]
tests/test_encryption.py::TestEncryptionManager::test_decrypt_invalid_ciphertext_raises_error PASSED [ 32%]
tests/test_encryption.py::TestEncryptionManager::test_different_keys_cannot_decrypt PASSED [ 33%]
tests/test_encryption.py::TestEncryptionManager::test_encryption_is_deterministic PASSED [ 33%]
tests/test_encryption.py::TestEncryptionManager::test_derive_key_from_password PASSED [ 33%]
tests/test_encryption.py::TestEncryptionManager::test_password_derived_key_works PASSED [ 33%]
tests/test_encryption.py::TestEncryptionManager::test_encryption_manager_initialization_without_key_raises_error PASSED [ 34%]
tests/test_encryption.py::TestEncryptionManager::test_encryption_manager_with_invalid_key_raises_error PASSED [ 34%]
tests/test_encryption.py::TestEncryptionManager::test_encrypt_empty_string PASSED [ 34%]
tests/test_encryption.py::TestEncryptionManager::test_encrypt_very_long_string PASSED [ 34%]
tests/test_encryption.py::TestUserEncryption::test_user_set_get_email PASSED [ 35%]
tests/test_encryption.py::TestUserEncryption::test_user_set_get_phone PASSED [ 35%]
tests/test_encryption.py::TestUserEncryption::test_user_set_empty_email PASSED [ 35%]
tests/test_encryption.py::TestUserEncryption::test_user_set_none_phone PASSED [ 35%]
tests/test_encryption.py::TestApiKeyEncryption::test_api_key_encrypt_hash PASSED [ 36%]
tests/test_encryption.py::TestApiKeyEncryption::test_api_key_decrypt_hash PASSED [ 36%]
tests/test_health.py::test_health_endpoint_structure PASSED              [ 36%]
tests/test_hello.py::test_hello_endpoint_structure PASSED                [ 36%]
tests/test_hello.py::test_hello_endpoint_invalid_method PASSED           [ 37%]
tests/test_langgraph_advanced.py::TestQueryAnalyzer::test_detect_metric_query PASSED [ 37%]
tests/test_langgraph_advanced.py::TestQueryAnalyzer::test_detect_graph_query PASSED [ 37%]
tests/test_langgraph_advanced.py::TestQueryAnalyzer::test_detect_history_query PASSED [ 38%]
tests/test_langgraph_advanced.py::TestQueryAnalyzer::test_detect_ci_query PASSED [ 38%]
tests/test_langgraph_advanced.py::TestQueryAnalyzer::test_detect_conditional_query PASSED [ 38%]
tests/test_langgraph_advanced.py::TestQueryAnalyzer::test_detect_composite_query PASSED [ 38%]
tests/test_langgraph_advanced.py::TestQueryAnalyzer::test_calculate_simple_complexity PASSED [ 39%]
tests/test_langgraph_advanced.py::TestQueryAnalyzer::test_calculate_complex_complexity PASSED [ 39%]
tests/test_langgraph_advanced.py::TestQueryAnalyzer::test_decompose_composite_query PASSED [ 39%]
tests/test_langgraph_advanced.py::TestQueryAnalyzer::test_determine_tools_metric PASSED [ 39%]
tests/test_langgraph_advanced.py::TestQueryAnalyzer::test_determine_tools_graph PASSED [ 40%]
tests/test_langgraph_advanced.py::TestQueryAnalyzer::test_extract_conditions_if_then PASSED [ 40%]
tests/test_langgraph_advanced.py::TestQueryAnalyzer::test_analyze_full_query PASSED [ 40%]
tests/test_langgraph_advanced.py::TestConditionalRouter::test_should_execute_default PASSED [ 40%]
tests/test_langgraph_advanced.py::TestConditionalRouter::test_should_execute_respects_depth_limit PASSED [ 41%]
tests/test_langgraph_advanced.py::TestConditionalRouter::test_choose_path_first_option PASSED [ 41%]
tests/test_langgraph_advanced.py::TestConditionalRouter::test_evaluate_condition_error PASSED [ 41%]
tests/test_langgraph_advanced.py::TestConditionalRouter::test_evaluate_condition_empty PASSED [ 41%]
tests/test_langgraph_advanced.py::TestConditionalRouter::test_evaluate_condition_complex PASSED [ 42%]
tests/test_langgraph_advanced.py::TestToolComposer::test_register_tool PASSED [ 42%]
tests/test_langgraph_advanced.py::TestToolComposer::test_compose_single_tool PASSED [ 42%]
tests/test_langgraph_advanced.py::TestToolComposer::test_compose_multiple_tools PASSED [ 42%]
tests/test_langgraph_advanced.py::TestToolComposer::test_compose_nonexistent_tool PASSED [ 43%]
tests/test_langgraph_advanced.py::TestToolComposer::test_compose_with_dependencies_simple PASSED [ 43%]
tests/test_langgraph_advanced.py::TestToolComposer::test_compose_with_dependencies_multiple PASSED [ 43%]
tests/test_langgraph_advanced.py::TestLangGraphAdvancedRunner::test_initialization PASSED [ 43%]
tests/test_langgraph_advanced.py::TestLangGraphAdvancedRunner::test_missing_api_key PASSED [ 44%]
tests/test_langgraph_advanced.py::TestLangGraphAdvancedRunner::test_run_simple_query PASSED [ 44%]
tests/test_langgraph_advanced.py::TestLangGraphAdvancedRunner::test_run_complex_query PASSED [ 44%]
tests/test_langgraph_advanced.py::TestLangGraphAdvancedRunner::test_run_with_depth_limit PASSED [ 44%]
tests/test_langgraph_advanced.py::TestLangGraphAdvancedRunner::test_run_sequential_mode PASSED [ 45%]
tests/test_langgraph_advanced.py::TestLangGraphAdvancedRunner::test_run_parallel_mode PASSED [ 45%]
tests/test_langgraph_advanced.py::TestLangGraphAdvancedRunner::test_run_hybrid_mode PASSED [ 45%]
tests/test_langgraph_advanced.py::TestLangGraphAdvancedRunner::test_execute_simple_returns_blocks PASSED [ 45%]
tests/test_langgraph_advanced.py::TestLangGraphAdvancedRunner::test_execute_decomposed_returns_blocks PASSED [ 46%]
tests/test_langgraph_advanced.py::TestLangGraphAdvancedRunner::test_build_summary_block PASSED [ 46%]
tests/test_langgraph_advanced.py::TestExecutionState::test_execution_state_creation PASSED [ 46%]
tests/test_langgraph_advanced.py::TestExecutionState::test_execution_state_tracking PASSED [ 46%]
tests/test_langgraph_advanced.py::TestIntegration::test_full_workflow_simple_to_complex PASSED [ 47%]
tests/test_langgraph_advanced.py::TestIntegration::test_query_analysis_to_execution PASSED [ 47%]
tests/test_migration_final.py::test_streaming_migration PASSED           [ 47%]
tests/test_migration_final.py::test_embedding_migration PASSED           [ 47%]
tests/test_migration_final.py::test_llm_client_output_parsing PASSED     [ 48%]
tests/test_openai.py::test_openai_stream_hello PASSED                    [ 48%]
tests/test_operation_settings.py::test_get_all_operation_settings FAILED [ 48%]
tests/test_operation_settings.py::test_get_ops_mode_setting FAILED       [ 48%]
tests/test_operation_settings.py::test_get_unknown_setting PASSED        [ 49%]
tests/test_operation_settings.py::test_update_ops_mode_setting FAILED    [ 49%]
tests/test_operation_settings.py::test_update_setting_with_invalid_value PASSED [ 49%]
tests/test_operation_settings.py::test_update_setting_with_wrong_type PASSED [ 50%]
tests/test_operation_settings.py::test_update_boolean_setting FAILED     [ 50%]
tests/test_operation_settings.py::test_setting_persistence_across_requests FAILED [ 50%]
tests/test_operation_settings.py::test_setting_missing_value_field PASSED [ 50%]
tests/test_ops_executor_tool_contracts.py::TestExecutorResultStructure::test_executor_result_creation PASSED [ 51%]
tests/test_ops_executor_tool_contracts.py::TestExecutorResultStructure::test_executor_result_with_defaults PASSED [ 51%]
tests/test_ops_executor_tool_contracts.py::TestExecutorResultStructure::test_executor_result_serialization PASSED [ 51%]
tests/test_ops_executor_tool_contracts.py::TestMetricExecutorToolContract::test_metric_executor_structure_can_be_verified PASSED [ 51%]
tests/test_ops_executor_tool_contracts.py::TestMetricExecutorToolContract::test_hist_executor_structure_can_be_verified PASSED [ 52%]
tests/test_ops_executor_tool_contracts.py::TestHistExecutorToolContract::test_hist_executor_can_be_imported PASSED [ 52%]
tests/test_ops_executor_tool_contracts.py::TestGraphExecutorToolContract::test_graph_executor_can_be_imported PASSED [ 52%]
tests/test_ops_executor_tool_contracts.py::TestExecutorBackwardCompatibility::test_normalize_real_result_with_executor_result PASSED [ 52%]
tests/test_ops_executor_tool_contracts.py::TestExecutorBackwardCompatibility::test_normalize_real_result_with_legacy_tuple PASSED [ 53%]
tests/test_ops_executor_tool_contracts.py::TestExecutorBackwardCompatibility::test_normalize_real_result_with_legacy_tuple_and_error PASSED [ 53%]
tests/test_ops_executor_tool_contracts.py::TestToolCallSerialization::test_executor_result_tool_calls_serialize_correctly PASSED [ 53%]
tests/test_ops_executor_tool_contracts.py::TestReferenceExtraction::test_reference_extraction_from_references_block PASSED [ 53%]
tests/test_ops_executor_tool_contracts.py::TestReferenceExtraction::test_empty_references_handling PASSED [ 54%]
tests/test_ops_resolvers.py::test_ci_resolver_exact_code PASSED          [ 54%]
tests/test_ops_resolvers.py::test_ci_resolver_name_fallback PASSED       [ 54%]
tests/test_ops_resolvers.py::test_metric_resolver_cpu PASSED             [ 54%]
tests/test_ops_resolvers.py::test_time_range_last_7_days PASSED          [ 55%]
tests/test_ops_resolvers.py::test_time_range_month_2025_12 PASSED        [ 55%]
tests/test_ops_service.py::test_handle_ops_query_mock_mode_uses_mock_blocks PASSED [ 55%]
tests/test_ops_service.py::test_handle_ops_query_real_mode_fallbacks_and_flags_error PASSED [ 55%]
tests/test_ops_service.py::test_ops_metric_real_blocks_shape PASSED      [ 56%]
tests/test_ops_service.py::test_ops_hist_real_blocks_shape PASSED        [ 56%]
tests/test_ops_service.py::test_ops_graph_real_blocks_shape PASSED       [ 56%]
tests/test_ops_service.py::test_ops_all_real_blocks_shape FAILED         [ 56%]
tests/test_ops_service.py::test_ops_all_langgraph_without_key_falls_back FAILED [ 57%]
tests/test_ops_service.py::test_ops_all_partial_failure FAILED           [ 57%]
tests/test_ops_service.py::test_ops_config_placeholder PASSED            [ 57%]
tests/test_ops_service.py::test_ops_config_real_blocks_shape PASSED      [ 57%]
tests/test_permissions.py::TestRolePermissions::test_admin_permissions PASSED [ 58%]
tests/test_permissions.py::TestRolePermissions::test_manager_permissions FAILED [ 58%]
tests/test_permissions.py::TestRolePermissions::test_developer_permissions PASSED [ 58%]
tests/test_permissions.py::TestRolePermissions::test_viewer_permissions PASSED [ 58%]
tests/test_permissions.py::TestRolePermissions::test_initialize_role_permissions ERROR [ 59%]
tests/test_permissions.py::TestPermissionChecks::test_admin_check_permission ERROR [ 59%]
tests/test_permissions.py::TestPermissionChecks::test_developer_can_create_api ERROR [ 59%]
tests/test_permissions.py::TestPermissionChecks::test_developer_cannot_delete_api ERROR [ 59%]
tests/test_permissions.py::TestPermissionChecks::test_viewer_can_read ERROR [ 60%]
tests/test_permissions.py::TestPermissionChecks::test_viewer_cannot_write ERROR [ 60%]
tests/test_permissions.py::TestResourcePermissions::test_grant_resource_permission ERROR [ 60%]
tests/test_permissions.py::TestResourcePermissions::test_grant_resource_type_permission ERROR [ 60%]
tests/test_permissions.py::TestResourcePermissions::test_check_resource_specific_permission ERROR [ 61%]
tests/test_permissions.py::TestResourcePermissions::test_check_resource_type_permission ERROR [ 61%]
tests/test_permissions.py::TestResourcePermissions::test_revoke_resource_permission ERROR [ 61%]
tests/test_permissions.py::TestPermissionExpiration::test_expired_permission_denied ERROR [ 61%]
tests/test_permissions.py::TestPermissionExpiration::test_future_permission_allowed ERROR [ 62%]
tests/test_permissions.py::TestListPermissions::test_list_user_permissions ERROR [ 62%]
tests/test_plan_multistep.py::TestBudgetSpec::test_budget_spec_defaults PASSED [ 62%]
tests/test_plan_multistep.py::TestBudgetSpec::test_budget_spec_custom_values PASSED [ 63%]
tests/test_plan_multistep.py::TestStepCondition::test_step_condition_equality PASSED [ 63%]
tests/test_plan_multistep.py::TestStepCondition::test_step_condition_numeric_value PASSED [ 63%]
tests/test_plan_multistep.py::TestPlanStep::test_plan_step_minimal PASSED [ 63%]
tests/test_plan_multistep.py::TestPlanStep::test_plan_step_with_navigation PASSED [ 64%]
tests/test_plan_multistep.py::TestPlanStep::test_plan_step_with_condition PASSED [ 64%]
tests/test_plan_multistep.py::TestPlanBranch::test_plan_branch_creation PASSED [ 64%]
tests/test_plan_multistep.py::TestPlanBranch::test_plan_branch_with_steps PASSED [ 64%]
tests/test_plan_multistep.py::TestPlanLoop::test_plan_loop_creation PASSED [ 65%]
tests/test_plan_multistep.py::TestPlanLoop::test_plan_loop_with_break_condition PASSED [ 65%]
tests/test_plan_multistep.py::TestPlanMultiStep::test_plan_single_step_execution PASSED [ 65%]
tests/test_plan_multistep.py::TestPlanMultiStep::test_plan_multi_step_sequence PASSED [ 65%]
tests/test_plan_multistep.py::TestPlanMultiStep::test_plan_with_branches PASSED [ 66%]
tests/test_plan_multistep.py::TestPlanMultiStep::test_plan_with_loops PASSED [ 66%]
tests/test_plan_multistep.py::TestPlanValidation::test_validate_simple_plan_success PASSED [ 66%]
tests/test_plan_multistep.py::TestPlanValidation::test_validate_duplicate_step_ids_fails PASSED [ 66%]
tests/test_plan_multistep.py::TestPlanValidation::test_validate_invalid_next_step_reference_fails PASSED [ 67%]
tests/test_plan_multistep.py::TestPlanValidation::test_validate_budget_exceeded_fails PASSED [ 67%]
tests/test_plan_multistep.py::TestPlanValidation::test_validate_with_custom_budget PASSED [ 67%]
tests/test_plan_multistep.py::TestPlanValidation::test_validate_multistep_disabled PASSED [ 67%]
tests/test_plan_multistep.py::TestPlanValidation::test_validate_complex_plan PASSED [ 68%]
tests/test_plan_multistep.py::TestPlanValidation::test_validate_timeout_invalid_range PASSED [ 68%]
tests/test_plan_multistep.py::TestPlanValidation::test_validate_timeout_exceeds_maximum PASSED [ 68%]
tests/test_plan_multistep.py::TestPlanValidation::test_validate_timeout_valid_range PASSED [ 68%]
tests/test_plan_multistep.py::TestPlanValidation::test_validate_max_depth_invalid_range PASSED [ 69%]
tests/test_plan_multistep.py::TestPlanValidation::test_validate_max_depth_exceeds_maximum PASSED [ 69%]
tests/test_plan_multistep.py::TestPlanValidation::test_validate_max_depth_valid_range PASSED [ 69%]
tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_save_draft_requires_auth FAILED [ 69%]
tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_save_draft_with_valid_token SKIPPED [ 70%]
tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_invalid_token_rejected FAILED [ 70%]
tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_missing_authorization_header_error FAILED [ 70%]
tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_publish_requires_auth SKIPPED [ 70%]
tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_rollback_requires_auth SKIPPED [ 71%]
tests/test_screen_editor_auth.py::TestScreenEditorAuthFlow::test_complete_screen_save_workflow SKIPPED [ 71%]
tests/test_screen_editor_auth.py::TestScreenEditorAuthFlow::test_publish_invalid_asset_returns_validation_error SKIPPED [ 71%]
tests/test_screen_editor_auth.py::TestScreenEditorAuthFlow::test_stage_published_endpoint_blocks_drafts SKIPPED [ 71%]
tests/test_screen_editor_auth.py::TestScreenEditorAuthFlow::test_token_in_authorization_header SKIPPED [ 72%]
tests/test_security_headers.py::TestSecurityHeaders::test_hsts_header_present PASSED [ 72%]
tests/test_security_headers.py::TestSecurityHeaders::test_hsts_include_subdomains PASSED [ 72%]
tests/test_security_headers.py::TestSecurityHeaders::test_csp_header_present PASSED [ 72%]
tests/test_security_headers.py::TestSecurityHeaders::test_x_frame_options_header PASSED [ 73%]
tests/test_security_headers.py::TestSecurityHeaders::test_x_content_type_options_header PASSED [ 73%]
tests/test_security_headers.py::TestSecurityHeaders::test_x_xss_protection_header PASSED [ 73%]
tests/test_security_headers.py::TestSecurityHeaders::test_referrer_policy_header PASSED [ 73%]
tests/test_security_headers.py::TestSecurityHeaders::test_permissions_policy_header PASSED [ 74%]
tests/test_security_headers.py::TestSecurityHeaders::test_headers_disabled PASSED [ 74%]
tests/test_security_headers.py::TestHTTPSRedirect::test_http_to_https_redirect PASSED [ 74%]
tests/test_security_headers.py::TestHTTPSRedirect::test_health_check_no_redirect PASSED [ 75%]
tests/test_security_headers.py::TestHTTPSRedirect::test_no_redirect_in_dev PASSED [ 75%]
tests/test_security_headers.py::TestHTTPSRedirect::test_redirect_disabled PASSED [ 75%]
tests/test_security_headers.py::TestCSRFMiddleware::test_csrf_token_on_get PASSED [ 75%]
tests/test_security_headers.py::TestCSRFMiddleware::test_csrf_token_in_header PASSED [ 76%]
tests/test_security_headers.py::TestCSRFMiddleware::test_csrf_token_mismatch PASSED [ 76%]
tests/test_security_headers.py::TestCSRFMiddleware::test_trusted_origin_bypass PASSED [ 76%]
tests/test_security_headers.py::TestCSRFMiddleware::test_csrf_disabled PASSED [ 76%]
tests/test_security_headers.py::TestCORSConfig::test_cors_origins_list PASSED [ 77%]
tests/test_security_headers.py::TestCORSConfig::test_cors_allow_credentials PASSED [ 77%]
tests/test_security_headers.py::TestCORSConfig::test_cors_allowed_methods PASSED [ 77%]
tests/test_security_headers.py::TestCORSConfig::test_cors_allowed_headers PASSED [ 77%]
tests/test_security_headers.py::TestCORSConfig::test_cors_exposed_headers PASSED [ 78%]
tests/test_security_headers.py::TestCORSConfig::test_cors_max_age PASSED [ 78%]
tests/test_security_headers.py::TestCORSConfig::test_cors_validate_origin PASSED [ 78%]
tests/test_security_headers.py::TestAddSecurityMiddleware::test_add_all_middleware PASSED [ 78%]
tests/test_security_headers.py::TestIntegration::test_full_security_stack PASSED [ 79%]
tests/test_security_headers.py::TestIntegration::test_health_endpoint_unaffected PASSED [ 79%]
tests/test_stage_executor.py::TestStageExecutor::test_initialization PASSED [ 79%]
tests/test_stage_executor.py::TestStageExecutor::test_resolve_asset_no_override PASSED [ 79%]
tests/test_stage_executor.py::TestStageExecutor::test_resolve_asset_with_override PASSED [ 80%]
tests/test_stage_executor.py::TestStageExecutor::test_execute_stage_route_plan PASSED [ 80%]
tests/test_stage_executor.py::TestStageExecutor::test_execute_stage_with_error PASSED [ 80%]
tests/test_stage_executor.py::TestStageExecutor::test_build_diagnostics_success PASSED [ 80%]
tests/test_stage_executor.py::TestStageExecutor::test_build_diagnostics_empty_result PASSED [ 81%]
tests/test_stage_executor.py::TestStageExecutor::test_build_diagnostics_with_errors PASSED [ 81%]
tests/test_stage_executor.py::TestStageExecutor::test_stage_input_output_tracking PASSED [ 81%]
tests/test_stage_executor.py::TestStageExecutor::test_multiple_stages_execution PASSED [ 81%]
tests/test_stage_executor.py::TestStageExecutor::test_test_mode_flag PASSED [ 82%]
tests/test_stage_executor.py::TestStageExecutor::test_baseline_comparison PASSED [ 82%]
tests/test_stage_executor.py::TestStageExecutor::test_diagnostics_counts PASSED [ 82%]
tests/test_stage_executor.py::TestStageExecutor::test_stage_unknown_handler PASSED [ 82%]
tests/test_stage_executor.py::TestStageExecutor::test_stage_with_references PASSED [ 83%]
tests/test_stage_executor.py::TestStageDiagnostics::test_diagnostics_creation PASSED [ 83%]
tests/test_stage_executor.py::TestStageDiagnostics::test_diagnostics_with_warnings PASSED [ 83%]
tests/test_stage_executor.py::TestStageDiagnostics::test_diagnostics_with_errors PASSED [ 83%]
tests/test_stage_executor.py::TestExecutionContext::test_context_creation PASSED [ 84%]
tests/test_stage_executor.py::TestExecutionContext::test_context_defaults PASSED [ 84%]
tests/test_trace_id.py::test_ops_query_includes_trace_id PASSED          [ 84%]
tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id PASSED         [ 84%]
tests/test_trace_id.py::test_trace_id_persists_across_requests PASSED    [ 85%]
tests/test_trace_id.py::test_parent_trace_id_in_response PASSED          [ 85%]
tests/test_ui_actions_with_traces.py::test_list_maintenance_filtered_with_state_patch FAILED [ 85%]
tests/test_ui_actions_with_traces.py::test_create_maintenance_ticket_with_state_patch FAILED [ 85%]
tests/test_ui_actions_with_traces.py::test_ui_action_response_includes_state_patch PASSED [ 86%]
tests/test_ui_actions_with_traces.py::test_executor_result_includes_state_patch PASSED [ 86%]
tests/test_ui_contract.py::TestUIScreenBlock::test_ui_screen_block_structure PASSED [ 86%]
tests/test_ui_contract.py::TestUIScreenBlock::test_ui_screen_block_in_answer_block_union PASSED [ 86%]
tests/test_ui_contract.py::TestUIScreenBlock::test_ui_screen_block_optional_fields PASSED [ 87%]
tests/test_ui_contract.py::TestScreenAsset::test_screen_asset_create_schema PASSED [ 87%]
tests/test_ui_contract.py::TestScreenAsset::test_screen_asset_read_schema PASSED [ 87%]
tests/test_ui_contract.py::TestScreenAsset::test_screen_asset_with_tags PASSED [ 88%]
tests/test_ui_contract.py::TestBindingEngine::test_binding_dot_path_access PASSED [ 88%]
tests/test_ui_contract.py::TestBindingEngine::test_binding_missing_path PASSED [ 88%]
tests/test_ui_contract.py::TestBindingEngine::test_binding_render_inputs PASSED [ 88%]
tests/test_ui_contract.py::TestBindingEngine::test_binding_render_state PASSED [ 89%]
tests/test_ui_contract.py::TestBindingEngine::test_binding_render_context PASSED [ 89%]
tests/test_ui_contract.py::TestBindingEngine::test_binding_render_trace_id PASSED [ 89%]
tests/test_ui_contract.py::TestBindingEngine::test_binding_missing_required_value PASSED [ 89%]
tests/test_ui_contract.py::TestBindingEngine::test_binding_no_expressions PASSED [ 90%]
tests/test_ui_contract.py::TestBindingEngine::test_binding_type_preservation PASSED [ 90%]
tests/test_ui_contract.py::TestBindingEngine::test_binding_partial_expression_converts_to_string PASSED [ 90%]
tests/test_ui_contract.py::TestBindingEngine::test_binding_validate_template PASSED [ 90%]
tests/test_ui_contract.py::TestBindingEngine::test_binding_mask_sensitive_inputs PASSED [ 91%]
tests/test_ui_contract.py::TestActionRegistry::test_action_registry_register_handler PASSED [ 91%]
tests/test_ui_contract.py::TestActionRegistry::test_action_registry_multiple_handlers PASSED [ 91%]
tests/test_ui_contract.py::TestIntegration::test_screen_asset_and_ui_screen_block_integration PASSED [ 91%]
tests/test_ui_contract.py::TestIntegration::test_binding_with_action_payload PASSED [ 92%]
tests/unit/test_api_manager.py::TestSQLValidator::test_validator_initialization PASSED [ 92%]
tests/unit/test_api_manager.py::TestSQLValidator::test_safe_select_query PASSED [ 92%]
tests/unit/test_api_manager.py::TestSQLValidator::test_dangerous_drop_keyword PASSED [ 92%]
tests/unit/test_api_manager.py::TestSQLValidator::test_dangerous_truncate_keyword PASSED [ 93%]
tests/unit/test_api_manager.py::TestSQLValidator::test_dangerous_delete_keyword PASSED [ 93%]
tests/unit/test_api_manager.py::TestSQLValidator::test_sql_injection_pattern_detection PASSED [ 93%]
tests/unit/test_api_manager.py::TestSQLValidator::test_protected_table_detection PASSED [ 93%]
tests/unit/test_api_manager.py::TestSQLValidator::test_performance_warning_select_star PASSED [ 94%]
tests/unit/test_api_manager.py::TestSQLValidator::test_performance_warning_missing_where PASSED [ 94%]
tests/unit/test_api_manager.py::TestSQLValidator::test_performance_warning_like_wildcard PASSED [ 94%]
tests/unit/test_api_manager.py::TestSQLValidator::test_table_extraction PASSED [ 94%]
tests/unit/test_api_manager.py::TestSQLValidator::test_validation_result_to_dict PASSED [ 95%]
tests/unit/test_api_manager.py::TestSQLValidator::test_multiple_joins_warning PASSED [ 95%]
tests/unit/test_api_manager.py::TestSQLValidator::test_or_conditions_warning PASSED [ 95%]
tests/unit/test_api_manager.py::TestSQLValidator::test_complex_valid_query PASSED [ 95%]
tests/unit/test_document_processor.py::TestDocumentProcessor::test_processor_initialization PASSED [ 96%]
tests/unit/test_document_processor.py::TestDocumentProcessor::test_supported_formats PASSED [ 96%]
tests/unit/test_document_processor.py::TestDocumentProcessor::test_invalid_format_raises_error PASSED [ 96%]
tests/unit/test_document_processor.py::TestDocumentProcessor::test_unsupported_file_format PASSED [ 96%]
tests/unit/test_document_processor.py::TestChunkingStrategy::test_split_sentences PASSED [ 97%]
tests/unit/test_document_processor.py::TestChunkingStrategy::test_chunk_text_basic PASSED [ 97%]
tests/unit/test_document_processor.py::TestChunkingStrategy::test_chunk_text_empty PASSED [ 97%]
tests/unit/test_document_processor.py::TestChunkingStrategy::test_chunk_table_basic PASSED [ 97%]
tests/unit/test_document_processor.py::TestChunkingStrategy::test_compute_source_hash PASSED [ 98%]
tests/unit/test_document_processor.py::TestChunkingStrategy::test_has_content_changed PASSED [ 98%]
tests/unit/test_document_processor.py::TestDocumentExportService::test_export_to_json PASSED [ 98%]
tests/unit/test_document_processor.py::TestDocumentExportService::test_export_to_csv PASSED [ 98%]
tests/unit/test_document_processor.py::TestDocumentExportService::test_export_to_markdown PASSED [ 99%]
tests/unit/test_document_processor.py::TestDocumentExportService::test_export_to_text PASSED [ 99%]
tests/unit/test_document_processor.py::TestDocumentExportService::test_export_chunks_format_selection PASSED [ 99%]
tests/unit/test_document_processor.py::TestDocumentExportService::test_export_unsupported_format PASSED [100%]

==================================== ERRORS ====================================
_______ ERROR at setup of TestCIChangeCreation.test_create_change_basic ________
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 20
      def test_create_change_basic(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:20
______ ERROR at setup of TestCIChangeCreation.test_create_change_minimal _______
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 40
      def test_create_change_minimal(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:40
_____ ERROR at setup of TestCIChangeCreation.test_create_change_all_types ______
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 55
      def test_create_change_all_types(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:55
_________ ERROR at setup of TestCIChangeCreation.test_get_change_by_id _________
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 76
      def test_get_change_by_id(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:76
_______ ERROR at setup of TestCIChangeCreation.test_get_change_not_found _______
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 91
      def test_get_change_not_found(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:91
_________ ERROR at setup of TestCIChangeCreation.test_list_changes_all _________
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 96
      def test_list_changes_all(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:96
___ ERROR at setup of TestCIChangeCreation.test_list_changes_filter_by_ci_id ___
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 111
      def test_list_changes_filter_by_ci_id(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:111
__ ERROR at setup of TestCIChangeCreation.test_list_changes_filter_by_status ___
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 126
      def test_list_changes_filter_by_status(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:126
_____ ERROR at setup of TestCIChangeCreation.test_list_changes_pagination ______
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 156
      def test_list_changes_pagination(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:156
__________ ERROR at setup of TestCIChangeApproval.test_approve_change __________
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 177
      def test_approve_change(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:177
__________ ERROR at setup of TestCIChangeApproval.test_reject_change ___________
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 201
      def test_reject_change(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:201
___ ERROR at setup of TestCIChangeApproval.test_approve_non_existent_change ____
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 223
      def test_approve_non_existent_change(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:223
___________ ERROR at setup of TestCIChangeApproval.test_apply_change ___________
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 233
      def test_apply_change(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:233
__ ERROR at setup of TestCIChangeApproval.test_apply_unapproved_change_fails ___
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 255
      def test_apply_unapproved_change_fails(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:255
___ ERROR at setup of TestCIChangeHistory.test_get_change_history_single_ci ____
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 272
      def test_get_change_history_single_ci(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:272
_______ ERROR at setup of TestCIChangeHistory.test_change_history_counts _______
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 292
      def test_change_history_counts(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:292
_ ERROR at setup of TestCIChangeHistory.test_change_history_pending_approvals __
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 311
      def test_change_history_pending_approvals(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:311
___ ERROR at setup of TestCIIntegrityValidation.test_create_integrity_issue ____
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 340
      def test_create_integrity_issue(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:340
____ ERROR at setup of TestCIIntegrityValidation.test_get_integrity_issues _____
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 357
      def test_get_integrity_issues(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:357
_ ERROR at setup of TestCIIntegrityValidation.test_filter_integrity_issues_unresolved _
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 374
      def test_filter_integrity_issues_unresolved(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:374
___ ERROR at setup of TestCIIntegrityValidation.test_resolve_integrity_issue ___
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 405
      def test_resolve_integrity_issue(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:405
____ ERROR at setup of TestCIIntegrityValidation.test_validate_ci_integrity ____
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 428
      def test_validate_ci_integrity(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:428
____ ERROR at setup of TestCIIntegrityValidation.test_get_integrity_summary ____
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 443
      def test_get_integrity_summary(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:443
____ ERROR at setup of TestCIDuplicateDetection.test_create_duplicate_entry ____
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 476
      def test_create_duplicate_entry(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:476
____ ERROR at setup of TestCIDuplicateDetection.test_get_duplicates_for_ci _____
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 492
      def test_get_duplicates_for_ci(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:492
______ ERROR at setup of TestCIDuplicateDetection.test_confirm_duplicate _______
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 508
      def test_confirm_duplicate(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:508
_____ ERROR at setup of TestCIDuplicateDetection.test_duplicate_statistics _____
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 532
      def test_duplicate_statistics(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:532
_____ ERROR at setup of TestCIChangeStatistics.test_get_change_statistics ______
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 563
      def test_get_change_statistics(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:563
__ ERROR at setup of TestCIChangeStatistics.test_change_statistics_time_range __
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 580
      def test_change_statistics_time_range(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:580
__ ERROR at setup of TestCIIntegrationWorkflow.test_complete_change_workflow ___
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 615
      def test_complete_change_workflow(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:615
_ ERROR at setup of TestCIIntegrationWorkflow.test_duplicate_detection_to_merge_workflow _
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 648
      def test_duplicate_detection_to_merge_workflow(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:648
_ ERROR at setup of TestCIIntegrationWorkflow.test_integrity_validation_workflow _
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 684
      def test_integrity_validation_workflow(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:684
____ ERROR at setup of TestTenantIsolation.test_changes_isolated_by_tenant _____
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 716
      def test_changes_isolated_by_tenant(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:716
_____ ERROR at setup of TestTenantIsolation.test_issues_isolated_by_tenant _____
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 741
      def test_issues_isolated_by_tenant(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:741
___ ERROR at setup of TestTenantIsolation.test_duplicates_isolated_by_tenant ___
file /home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py, line 767
      def test_duplicates_isolated_by_tenant(self, session: Session):
E       fixture 'session' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, subtests, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/spa/tobit-spa-ai/apps/api/tests/test_ci_management.py:767
___________ ERROR at setup of test_upload_creates_metadata_and_list ____________

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8dc8d220>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8dc8df70>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8ec0e1b0>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8ec0dfd0>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8dc8df70>
cursor = <sqlite3.Cursor object at 0x7f4b913612c0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8ec0e1b0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f4b8e3a48f0>

    @pytest.fixture(autouse=True)
    def override_session(monkeypatch: pytest.MonkeyPatch):
        AppSettings.connection_cache.clear()
        _patch_jsonb_for_sqlite()
        engine = create_engine("sqlite:///:memory:", connect_args={"check_same_thread": False})
>       SQLModel.metadata.create_all(engine, checkfirst=True)

tests/test_documents.py:36: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8dc8df70>
cursor = <sqlite3.Cursor object at 0x7f4b913612c0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8ec0e1b0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
_______ ERROR at setup of test_document_stream_done_contains_references ________

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8ef2b110>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8ef2b200>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8eee2270>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8eee0560>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8ef2b200>
cursor = <sqlite3.Cursor object at 0x7f4b8ebfa540>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8eee2270>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f4b8ef2b050>

    @pytest.fixture(autouse=True)
    def override_session(monkeypatch: pytest.MonkeyPatch):
        AppSettings.connection_cache.clear()
        _patch_jsonb_for_sqlite()
        engine = create_engine("sqlite:///:memory:", connect_args={"check_same_thread": False})
>       SQLModel.metadata.create_all(engine, checkfirst=True)

tests/test_documents.py:36: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8ef2b200>
cursor = <sqlite3.Cursor object at 0x7f4b8ebfa540>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8eee2270>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
____ ERROR at setup of TestRolePermissions.test_initialize_role_permissions ____

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8ee56180>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8ee56de0>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f17a060>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8ee573e0>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8ee56de0>
cursor = <sqlite3.Cursor object at 0x7f4b8f17c4c0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f17a060>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8ee56de0>
cursor = <sqlite3.Cursor object at 0x7f4b8f17c4c0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f17a060>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
______ ERROR at setup of TestPermissionChecks.test_admin_check_permission ______

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8f179c70>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f17b0e0>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f243b00>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8f2434d0>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f17b0e0>
cursor = <sqlite3.Cursor object at 0x7f4b8ebbdf40>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f243b00>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f17b0e0>
cursor = <sqlite3.Cursor object at 0x7f4b8ebbdf40>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f243b00>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
_____ ERROR at setup of TestPermissionChecks.test_developer_can_create_api _____

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8f178bc0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f1793d0>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8ee554f0>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8ee56210>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f1793d0>
cursor = <sqlite3.Cursor object at 0x7f4b8f0abec0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8ee554f0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f1793d0>
cursor = <sqlite3.Cursor object at 0x7f4b8f0abec0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8ee554f0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
___ ERROR at setup of TestPermissionChecks.test_developer_cannot_delete_api ____

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8f241010>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f241f70>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f108440>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8f10be60>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f241f70>
cursor = <sqlite3.Cursor object at 0x7f4b8d83a8c0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f108440>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f241f70>
cursor = <sqlite3.Cursor object at 0x7f4b8d83a8c0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f108440>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
_________ ERROR at setup of TestPermissionChecks.test_viewer_can_read __________

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8f10bef0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f108740>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f10b590>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8f10ab40>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f108740>
cursor = <sqlite3.Cursor object at 0x7f4b8e232040>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f10b590>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f108740>
cursor = <sqlite3.Cursor object at 0x7f4b8e232040>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f10b590>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
_______ ERROR at setup of TestPermissionChecks.test_viewer_cannot_write ________

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8f240e60>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f241a60>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f3ca060>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8f3cabd0>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f241a60>
cursor = <sqlite3.Cursor object at 0x7f4b8df3f740>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f3ca060>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f241a60>
cursor = <sqlite3.Cursor object at 0x7f4b8df3f740>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f3ca060>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
___ ERROR at setup of TestResourcePermissions.test_grant_resource_permission ___

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8dc8eb70>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8dc8cb60>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8dc756a0>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8dc77080>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8dc8cb60>
cursor = <sqlite3.Cursor object at 0x7f4b8edccac0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8dc756a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8dc8cb60>
cursor = <sqlite3.Cursor object at 0x7f4b8edccac0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8dc756a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
_ ERROR at setup of TestResourcePermissions.test_grant_resource_type_permission _

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8f240890>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f2413d0>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8ebc1580>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8ebc1a30>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f2413d0>
cursor = <sqlite3.Cursor object at 0x7f4b8f4c6040>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8ebc1580>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f2413d0>
cursor = <sqlite3.Cursor object at 0x7f4b8f4c6040>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8ebc1580>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
_ ERROR at setup of TestResourcePermissions.test_check_resource_specific_permission _

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8d9a6570>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8d9a7230>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8eee2ba0>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8eee1df0>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8d9a7230>
cursor = <sqlite3.Cursor object at 0x7f4b8f17c6c0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8eee2ba0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8d9a7230>
cursor = <sqlite3.Cursor object at 0x7f4b8f17c6c0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8eee2ba0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
_ ERROR at setup of TestResourcePermissions.test_check_resource_type_permission _

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8d9c6cf0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8d9c7260>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8d9c69c0>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8d9c7c80>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8d9c7260>
cursor = <sqlite3.Cursor object at 0x7f4b8f2062c0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8d9c69c0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8d9c7260>
cursor = <sqlite3.Cursor object at 0x7f4b8f2062c0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8d9c69c0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
__ ERROR at setup of TestResourcePermissions.test_revoke_resource_permission ___

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8d9a7230>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8d9a4a10>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8eee1e50>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8eee30e0>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8d9a4a10>
cursor = <sqlite3.Cursor object at 0x7f4b8d838040>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8eee1e50>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8d9a4a10>
cursor = <sqlite3.Cursor object at 0x7f4b8d838040>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8eee1e50>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
__ ERROR at setup of TestPermissionExpiration.test_expired_permission_denied ___

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8f0b2270>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f0b00b0>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f0b2750>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8f0b2090>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f0b00b0>
cursor = <sqlite3.Cursor object at 0x7f4b8df37ec0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f0b2750>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8f0b00b0>
cursor = <sqlite3.Cursor object at 0x7f4b8df37ec0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f0b2750>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
__ ERROR at setup of TestPermissionExpiration.test_future_permission_allowed ___

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8eee1910>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8eee19d0>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f0b09e0>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8f0b2c00>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8eee19d0>
cursor = <sqlite3.Cursor object at 0x7f4b8edcf0c0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f0b09e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8eee19d0>
cursor = <sqlite3.Cursor object at 0x7f4b8edcf0c0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f0b09e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
_______ ERROR at setup of TestListPermissions.test_list_user_permissions _______

self = <sqlalchemy.engine.base.Connection object at 0x7f4b8edb0980>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8edb0d10>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8edb2720>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteDDLCompiler object at 0x7f4b8edb3e30>
parameters = [()]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8edb0d10>
cursor = <sqlite3.Cursor object at 0x7f4b8d838dc0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8edb2720>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: index ix_tb_user_tenant_id already exists

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

    from apps.api.core.security import get_password_hash
    
    
    @pytest.fixture
    def session():
        """Create an in-memory SQLite database for testing."""
        from sqlalchemy import text
    
        engine = create_engine(
            "sqlite:///:memory:",
>           connect_args={"check_same_thread": False},
            poolclass=StaticPool,
        )

tests/test_permissions.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/sqlalchemy/sql/schema.py:5928: in create_all
    bind._run_ddl_visitor(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3260: in _run_ddl_visitor
    conn._run_ddl_visitor(visitorcallable, element, **kwargs)
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2467: in _run_ddl_visitor
    ).traverse_single(element)
      ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:984: in visit_metadata
    self.traverse_single(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1026: in visit_table
    self.traverse_single(index, create_ok=True)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py:661: in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:1063: in visit_index
    CreateIndex(index)._invoke_with(self.connection)
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:321: in _invoke_with
    return bind.execute(self)
           ^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py:187: in _execute_on_connection
    return connection._execute_ddl(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1530: in _execute_ddl
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b8edb0d10>
cursor = <sqlite3.Cursor object at 0x7f4b8d838dc0>
statement = 'CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)'
parameters = ()
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8edb2720>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) index ix_tb_user_tenant_id already exists
E       [SQL: CREATE INDEX ix_tb_user_tenant_id ON tb_user (tenant_id)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
=================================== FAILURES ===================================
_________________ TestApiKeyCrud.test_validate_api_key_expired _________________

self = <test_api_keys.TestApiKeyCrud object at 0x7f4b915bec60>
session = <sqlmodel.orm.session.Session object at 0x7f4b90c0d8b0>
test_user = TbUser()

    def test_validate_api_key_expired(self, session: Session, test_user: TbUser):
        """Test validating an expired API key."""
        expired_time = datetime.now(timezone.utc) - timedelta(hours=1)
    
        api_key, full_key = create_api_key(
            session=session,
            user_id=test_user.id,
            name="Expired Key",
            scope=["api:read"],
            expires_at=expired_time,
        )
    
        # Should return None for expired key
>       result = validate_api_key(session, full_key)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_api_keys.py:210: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

session = <sqlmodel.orm.session.Session object at 0x7f4b90c0d8b0>
key = 'sk_b40a20044ff0431cae08ab9820075971'

    def validate_api_key(session: Session, key: str) -> Optional[TbApiKey]:
        """
        Validate an API key and return the associated API key record.
    
        Args:
            session: Database session
            key: The API key to validate
    
        Returns:
            TbApiKey record if valid, None otherwise
        """
        # Extract key prefix (first 8 chars)
        key_prefix = key[:8]
    
        # Query for active keys with matching prefix
        statement = select(TbApiKey).where(
            TbApiKey.key_prefix == key_prefix,
            TbApiKey.is_active,
        )
    
        candidates = session.exec(statement).all()
    
        # Verify full key against hash (only one should match)
        for candidate in candidates:
            # Check if expired
>           if candidate.expires_at and candidate.expires_at <= datetime.now(timezone.utc):
                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           TypeError: can't compare offset-naive and offset-aware datetimes

app/modules/api_keys/crud.py:99: TypeError
________________ test_list_audit_logs_returns_matching_entries _________________

self = <sqlalchemy.engine.base.Connection object at 0x7f4b90798830>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b91ab9d60>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b90799340>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7f4b90798d40>
parameters = [('settings', 'ops_mode', 5, 0)]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b91ab9d60>
cursor = <sqlite3.Cursor object at 0x7f4b9131d4c0>
statement = 'SELECT tb_audit_log.audit_id, tb_audit_log.trace_id, tb_audit_log.parent_trace_id, tb_audit_log.resource_type, tb_aud..._audit_log.resource_type = ? AND tb_audit_log.resource_id = ? ORDER BY tb_audit_log.created_at DESC\n LIMIT ? OFFSET ?'
parameters = ('settings', 'ops_mode', 5, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b90799340>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: no such table: tb_audit_log

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

client = <starlette.testclient.TestClient object at 0x7f4b907634a0>

    def test_list_audit_logs_returns_matching_entries(client: TestClient):
        trace_id, _, resource_type, resource_id = _seed_audit_log_entry()
>       response = client.get(
            "/audit-log",
            params={"resource_type": resource_type, "resource_id": resource_id, "limit": 5},
        )

tests/test_audit_log.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/starlette/testclient.py:473: in get
    return super().get(
.venv/lib/python3.12/site-packages/httpx/_client.py:1053: in get
    return self.request(
.venv/lib/python3.12/site-packages/starlette/testclient.py:445: in request
    return super().request(
.venv/lib/python3.12/site-packages/httpx/_client.py:825: in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/httpx/_client.py:914: in send
    response = self._send_handling_auth(
.venv/lib/python3.12/site-packages/httpx/_client.py:942: in _send_handling_auth
    response = self._send_handling_redirects(
.venv/lib/python3.12/site-packages/httpx/_client.py:979: in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/httpx/_client.py:1014: in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/starlette/testclient.py:348: in handle_request
    raise exc
.venv/lib/python3.12/site-packages/starlette/testclient.py:345: in handle_request
    portal.call(self.app, scope, receive, send)
.venv/lib/python3.12/site-packages/anyio/from_thread.py:334: in call
    return cast(T_Retval, self.start_task_soon(func, *args).result())
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/lib/python3.12/concurrent/futures/_base.py:456: in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
/usr/lib/python3.12/concurrent/futures/_base.py:401: in __get_result
    raise self._exception
.venv/lib/python3.12/site-packages/anyio/from_thread.py:259: in _call_func
    retval = await retval_or_awaitable
             ^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/fastapi/applications.py:1135: in __call__
    await super().__call__(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/applications.py:107: in __call__
    await self.middleware_stack(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/middleware/errors.py:186: in __call__
    raise exc
.venv/lib/python3.12/site-packages/starlette/middleware/errors.py:164: in __call__
    await self.app(scope, receive, _send)
.venv/lib/python3.12/site-packages/starlette/middleware/cors.py:85: in __call__
    await self.app(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: in __call__
    with recv_stream, send_stream, collapse_excgroups():
/usr/lib/python3.12/contextlib.py:158: in __exit__
    self.gen.throw(value)
.venv/lib/python3.12/site-packages/starlette/_utils.py:85: in collapse_excgroups
    raise exc
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
core/security_middleware.py:26: in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: in __call__
    with recv_stream, send_stream, collapse_excgroups():
/usr/lib/python3.12/contextlib.py:158: in __exit__
    self.gen.throw(value)
.venv/lib/python3.12/site-packages/starlette/_utils.py:85: in collapse_excgroups
    raise exc
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
core/security_middleware.py:107: in dispatch
    return await call_next(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: in __call__
    with recv_stream, send_stream, collapse_excgroups():
/usr/lib/python3.12/contextlib.py:158: in __exit__
    self.gen.throw(value)
.venv/lib/python3.12/site-packages/starlette/_utils.py:85: in collapse_excgroups
    raise exc
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
core/security_middleware.py:136: in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: in __call__
    with recv_stream, send_stream, collapse_excgroups():
/usr/lib/python3.12/contextlib.py:158: in __exit__
    self.gen.throw(value)
.venv/lib/python3.12/site-packages/starlette/_utils.py:85: in collapse_excgroups
    raise exc
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
core/middleware.py:26: in dispatch
    response: Response = await call_next(request)
                         ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py:63: in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/_exception_handler.py:53: in wrapped_app
    raise exc
.venv/lib/python3.12/site-packages/starlette/_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv/lib/python3.12/site-packages/fastapi/middleware/asyncexitstack.py:18: in __call__
    await self.app(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/routing.py:716: in __call__
    await self.middleware_stack(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/routing.py:736: in app
    await route.handle(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/routing.py:290: in handle
    await self.app(scope, receive, send)
.venv/lib/python3.12/site-packages/fastapi/routing.py:115: in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/_exception_handler.py:53: in wrapped_app
    raise exc
.venv/lib/python3.12/site-packages/starlette/_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv/lib/python3.12/site-packages/fastapi/routing.py:101: in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/fastapi/routing.py:355: in app
    raw_response = await run_endpoint_function(
.venv/lib/python3.12/site-packages/fastapi/routing.py:245: in run_endpoint_function
    return await run_in_threadpool(dependant.call, **values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/starlette/concurrency.py:32: in run_in_threadpool
    return await anyio.to_thread.run_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/anyio/to_thread.py:63: in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:2502: in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:986: in run
    result = context.run(func, *args)
             ^^^^^^^^^^^^^^^^^^^^^^^^
app/modules/audit_log/router.py:60: in list_audit_logs
    audit_logs = _normalize_rows(session.exec(statement).all())
                                 ^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py:81: in exec
    results = super().execute(
.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:2351: in execute
    return self._execute_internal(
.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:2249: in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
.venv/lib/python3.12/site-packages/sqlalchemy/orm/context.py:306: in orm_execute_statement
    result = conn.execute(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:527: in _execute_on_connection
    return connection._execute_clauseelement(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1641: in _execute_clauseelement
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b91ab9d60>
cursor = <sqlite3.Cursor object at 0x7f4b9131d4c0>
statement = 'SELECT tb_audit_log.audit_id, tb_audit_log.trace_id, tb_audit_log.parent_trace_id, tb_audit_log.resource_type, tb_aud..._audit_log.resource_type = ? AND tb_audit_log.resource_id = ? ORDER BY tb_audit_log.created_at DESC\n LIMIT ? OFFSET ?'
parameters = ('settings', 'ops_mode', 5, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b90799340>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: tb_audit_log
E       [SQL: SELECT tb_audit_log.audit_id, tb_audit_log.trace_id, tb_audit_log.parent_trace_id, tb_audit_log.resource_type, tb_audit_log.resource_id, tb_audit_log.action, tb_audit_log.actor, tb_audit_log.changes, tb_audit_log.old_values, tb_audit_log.new_values, tb_audit_log.metadata, tb_audit_log.created_at 
E       FROM tb_audit_log 
E       WHERE tb_audit_log.resource_type = ? AND tb_audit_log.resource_id = ? ORDER BY tb_audit_log.created_at DESC
E        LIMIT ? OFFSET ?]
E       [parameters: ('settings', 'ops_mode', 5, 0)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
----------------------------- Captured stdout call -----------------------------
2026-01-22 17:57:46,963 INFO sqlalchemy.engine.Engine select pg_catalog.version()
2026-01-22 17:57:46,964 INFO sqlalchemy.engine.Engine [raw sql] {}
2026-01-22 17:57:47,003 INFO sqlalchemy.engine.Engine select current_schema()
2026-01-22 17:57:47,004 INFO sqlalchemy.engine.Engine [raw sql] {}
2026-01-22 17:57:47,043 INFO sqlalchemy.engine.Engine show standard_conforming_strings
2026-01-22 17:57:47,043 INFO sqlalchemy.engine.Engine [raw sql] {}
2026-01-22 17:57:47,132 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2026-01-22 17:57:47,134 INFO sqlalchemy.engine.Engine INSERT INTO tb_audit_log (audit_id, trace_id, parent_trace_id, resource_type, resource_id, action, actor, changes, old_values, new_values, metadata, created_at) VALUES (%(audit_id)s::UUID, %(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(resource_type)s::VARCHAR, %(resource_id)s::VARCHAR, %(action)s::VARCHAR, %(actor)s::VARCHAR, %(changes)s::JSONB, %(old_values)s::JSONB, %(new_values)s::JSONB, %(metadata)s::JSONB, %(created_at)s::TIMESTAMP WITH TIME ZONE)
2026-01-22 17:57:47,135 INFO sqlalchemy.engine.Engine [generated in 0.00121s] {'audit_id': UUID('f5a8b9e3-57df-4275-baeb-46b6e46f57b9'), 'trace_id': '8ed86633-eb8a-4a35-8738-b4d96397c170', 'parent_trace_id': '1ba840e1-f6b4-484a-9a3b-4a2932f6f305', 'resource_type': 'settings', 'resource_id': 'ops_mode', 'action': 'update', 'actor': 'test-suite', 'changes': Jsonb({'value': 'test'}), 'old_values': Jsonb(None), 'new_values': Jsonb(None), 'metadata': Jsonb(None), 'created_at': datetime.datetime(2026, 1, 22, 8, 57, 46, 885682)}
2026-01-22 17:57:47,172 INFO sqlalchemy.engine.Engine COMMIT
2026-01-22 17:57:47,192 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2026-01-22 17:57:47,194 INFO sqlalchemy.engine.Engine SELECT tb_audit_log.audit_id, tb_audit_log.trace_id, tb_audit_log.parent_trace_id, tb_audit_log.resource_type, tb_audit_log.resource_id, tb_audit_log.action, tb_audit_log.actor, tb_audit_log.changes, tb_audit_log.old_values, tb_audit_log.new_values, tb_audit_log.metadata, tb_audit_log.created_at 
FROM tb_audit_log 
WHERE tb_audit_log.audit_id = %(pk_1)s::UUID
2026-01-22 17:57:47,194 INFO sqlalchemy.engine.Engine [generated in 0.00042s] {'pk_1': UUID('f5a8b9e3-57df-4275-baeb-46b6e46f57b9')}
2026-01-22 17:57:47,216 INFO sqlalchemy.engine.Engine ROLLBACK
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:57:46+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- select pg_catalog.version() taskName=None asctime=2026-01-22T17:57:46+0900
2026-01-22T17:57:46+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- [raw sql] {} taskName=None asctime=2026-01-22T17:57:46+0900
2026-01-22T17:57:47+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- select current_schema() taskName=None asctime=2026-01-22T17:57:47+0900
2026-01-22T17:57:47+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- [raw sql] {} taskName=None asctime=2026-01-22T17:57:47+0900
2026-01-22T17:57:47+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- show standard_conforming_strings taskName=None asctime=2026-01-22T17:57:47+0900
2026-01-22T17:57:47+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- [raw sql] {} taskName=None asctime=2026-01-22T17:57:47+0900
2026-01-22T17:57:47+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- BEGIN (implicit) taskName=None asctime=2026-01-22T17:57:47+0900
2026-01-22T17:57:47+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- INSERT INTO tb_audit_log (audit_id, trace_id, parent_trace_id, resource_type, resource_id, action, actor, changes, old_values, new_values, metadata, created_at) VALUES (%(audit_id)s::UUID, %(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(resource_type)s::VARCHAR, %(resource_id)s::VARCHAR, %(action)s::VARCHAR, %(actor)s::VARCHAR, %(changes)s::JSONB, %(old_values)s::JSONB, %(new_values)s::JSONB, %(metadata)s::JSONB, %(created_at)s::TIMESTAMP WITH TIME ZONE) taskName=None asctime=2026-01-22T17:57:47+0900
2026-01-22T17:57:47+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- [generated in 0.00121s] {'audit_id': UUID('f5a8b9e3-57df-4275-baeb-46b6e46f57b9'), 'trace_id': '8ed86633-eb8a-4a35-8738-b4d96397c170', 'parent_trace_id': '1ba840e1-f6b4-484a-9a3b-4a2932f6f305', 'resource_type': 'settings', 'resource_id': 'ops_mode', 'action': 'update', 'actor': 'test-suite', 'changes': Jsonb({'value': 'test'}), 'old_values': Jsonb(None), 'new_values': Jsonb(None), 'metadata': Jsonb(None), 'created_at': datetime.datetime(2026, 1, 22, 8, 57, 46, 885682)} taskName=None asctime=2026-01-22T17:57:47+0900
2026-01-22T17:57:47+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- COMMIT taskName=None asctime=2026-01-22T17:57:47+0900
2026-01-22T17:57:47+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- BEGIN (implicit) taskName=None asctime=2026-01-22T17:57:47+0900
2026-01-22T17:57:47+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- SELECT tb_audit_log.audit_id, tb_audit_log.trace_id, tb_audit_log.parent_trace_id, tb_audit_log.resource_type, tb_audit_log.resource_id, tb_audit_log.action, tb_audit_log.actor, tb_audit_log.changes, tb_audit_log.old_values, tb_audit_log.new_values, tb_audit_log.metadata, tb_audit_log.created_at 
FROM tb_audit_log 
WHERE tb_audit_log.audit_id = %(pk_1)s::UUID taskName=None asctime=2026-01-22T17:57:47+0900
2026-01-22T17:57:47+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- [generated in 0.00042s] {'pk_1': UUID('f5a8b9e3-57df-4275-baeb-46b6e46f57b9')} taskName=None asctime=2026-01-22T17:57:47+0900
2026-01-22T17:57:47+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- ROLLBACK taskName=None asctime=2026-01-22T17:57:47+0900
2026-01-22T17:57:47+0900 DEBUG asyncio request_id=- tenant_id=- trace_id=- mode=- Using selector: EpollSelector taskName=None asctime=2026-01-22T17:57:47+0900
------------------------------ Captured log call -------------------------------
INFO     sqlalchemy.engine.Engine:base.py:1846 select pg_catalog.version()
INFO     sqlalchemy.engine.Engine:base.py:1846 [raw sql] {}
INFO     sqlalchemy.engine.Engine:base.py:1846 select current_schema()
INFO     sqlalchemy.engine.Engine:base.py:1846 [raw sql] {}
INFO     sqlalchemy.engine.Engine:base.py:1846 show standard_conforming_strings
INFO     sqlalchemy.engine.Engine:base.py:1846 [raw sql] {}
INFO     sqlalchemy.engine.Engine:base.py:2710 BEGIN (implicit)
INFO     sqlalchemy.engine.Engine:base.py:1846 INSERT INTO tb_audit_log (audit_id, trace_id, parent_trace_id, resource_type, resource_id, action, actor, changes, old_values, new_values, metadata, created_at) VALUES (%(audit_id)s::UUID, %(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(resource_type)s::VARCHAR, %(resource_id)s::VARCHAR, %(action)s::VARCHAR, %(actor)s::VARCHAR, %(changes)s::JSONB, %(old_values)s::JSONB, %(new_values)s::JSONB, %(metadata)s::JSONB, %(created_at)s::TIMESTAMP WITH TIME ZONE)
INFO     sqlalchemy.engine.Engine:base.py:1846 [generated in 0.00121s] {'audit_id': UUID('f5a8b9e3-57df-4275-baeb-46b6e46f57b9'), 'trace_id': '8ed86633-eb8a-4a35-8738-b4d96397c170', 'parent_trace_id': '1ba840e1-f6b4-484a-9a3b-4a2932f6f305', 'resource_type': 'settings', 'resource_id': 'ops_mode', 'action': 'update', 'actor': 'test-suite', 'changes': Jsonb({'value': 'test'}), 'old_values': Jsonb(None), 'new_values': Jsonb(None), 'metadata': Jsonb(None), 'created_at': datetime.datetime(2026, 1, 22, 8, 57, 46, 885682)}
INFO     sqlalchemy.engine.Engine:base.py:2716 COMMIT
INFO     sqlalchemy.engine.Engine:base.py:2710 BEGIN (implicit)
INFO     sqlalchemy.engine.Engine:base.py:1846 SELECT tb_audit_log.audit_id, tb_audit_log.trace_id, tb_audit_log.parent_trace_id, tb_audit_log.resource_type, tb_audit_log.resource_id, tb_audit_log.action, tb_audit_log.actor, tb_audit_log.changes, tb_audit_log.old_values, tb_audit_log.new_values, tb_audit_log.metadata, tb_audit_log.created_at 
FROM tb_audit_log 
WHERE tb_audit_log.audit_id = %(pk_1)s::UUID
INFO     sqlalchemy.engine.Engine:base.py:1846 [generated in 0.00042s] {'pk_1': UUID('f5a8b9e3-57df-4275-baeb-46b6e46f57b9')}
INFO     sqlalchemy.engine.Engine:base.py:2713 ROLLBACK
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
___________________ test_get_audit_logs_by_trace_and_parent ____________________

self = <sqlalchemy.engine.base.Connection object at 0x7f4b90798830>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b91ab9d60>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f5dbb90>
statement = <sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7f4b8f5d9550>
parameters = [('4f44dce4-8338-40ea-83c9-0fa104fb2379',)]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b91ab9d60>
cursor = <sqlite3.Cursor object at 0x7f4b8d8aac40>
statement = 'SELECT tb_audit_log.audit_id, tb_audit_log.trace_id, tb_audit_log.parent_trace_id, tb_audit_log.resource_type, tb_aud...a, tb_audit_log.created_at \nFROM tb_audit_log \nWHERE tb_audit_log.trace_id = ? ORDER BY tb_audit_log.created_at DESC'
parameters = ('4f44dce4-8338-40ea-83c9-0fa104fb2379',)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f5dbb90>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: no such table: tb_audit_log

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError

The above exception was the direct cause of the following exception:

client = <starlette.testclient.TestClient object at 0x7f4b9077d250>

    def test_get_audit_logs_by_trace_and_parent(client: TestClient):
        trace_id, parent_trace_id, _, _ = _seed_audit_log_entry()
    
>       trace_response = client.get(f"/audit-log/by-trace/{trace_id}")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_audit_log.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.12/site-packages/starlette/testclient.py:473: in get
    return super().get(
.venv/lib/python3.12/site-packages/httpx/_client.py:1053: in get
    return self.request(
.venv/lib/python3.12/site-packages/starlette/testclient.py:445: in request
    return super().request(
.venv/lib/python3.12/site-packages/httpx/_client.py:825: in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/httpx/_client.py:914: in send
    response = self._send_handling_auth(
.venv/lib/python3.12/site-packages/httpx/_client.py:942: in _send_handling_auth
    response = self._send_handling_redirects(
.venv/lib/python3.12/site-packages/httpx/_client.py:979: in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/httpx/_client.py:1014: in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/starlette/testclient.py:348: in handle_request
    raise exc
.venv/lib/python3.12/site-packages/starlette/testclient.py:345: in handle_request
    portal.call(self.app, scope, receive, send)
.venv/lib/python3.12/site-packages/anyio/from_thread.py:334: in call
    return cast(T_Retval, self.start_task_soon(func, *args).result())
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/usr/lib/python3.12/concurrent/futures/_base.py:456: in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
/usr/lib/python3.12/concurrent/futures/_base.py:401: in __get_result
    raise self._exception
.venv/lib/python3.12/site-packages/anyio/from_thread.py:259: in _call_func
    retval = await retval_or_awaitable
             ^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/fastapi/applications.py:1135: in __call__
    await super().__call__(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/applications.py:107: in __call__
    await self.middleware_stack(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/middleware/errors.py:186: in __call__
    raise exc
.venv/lib/python3.12/site-packages/starlette/middleware/errors.py:164: in __call__
    await self.app(scope, receive, _send)
.venv/lib/python3.12/site-packages/starlette/middleware/cors.py:85: in __call__
    await self.app(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: in __call__
    with recv_stream, send_stream, collapse_excgroups():
/usr/lib/python3.12/contextlib.py:158: in __exit__
    self.gen.throw(value)
.venv/lib/python3.12/site-packages/starlette/_utils.py:85: in collapse_excgroups
    raise exc
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
core/security_middleware.py:26: in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: in __call__
    with recv_stream, send_stream, collapse_excgroups():
/usr/lib/python3.12/contextlib.py:158: in __exit__
    self.gen.throw(value)
.venv/lib/python3.12/site-packages/starlette/_utils.py:85: in collapse_excgroups
    raise exc
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
core/security_middleware.py:107: in dispatch
    return await call_next(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: in __call__
    with recv_stream, send_stream, collapse_excgroups():
/usr/lib/python3.12/contextlib.py:158: in __exit__
    self.gen.throw(value)
.venv/lib/python3.12/site-packages/starlette/_utils.py:85: in collapse_excgroups
    raise exc
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
core/security_middleware.py:136: in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: in __call__
    with recv_stream, send_stream, collapse_excgroups():
/usr/lib/python3.12/contextlib.py:158: in __exit__
    self.gen.throw(value)
.venv/lib/python3.12/site-packages/starlette/_utils.py:85: in collapse_excgroups
    raise exc
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
core/middleware.py:26: in dispatch
    response: Response = await call_next(request)
                         ^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py:63: in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/_exception_handler.py:53: in wrapped_app
    raise exc
.venv/lib/python3.12/site-packages/starlette/_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv/lib/python3.12/site-packages/fastapi/middleware/asyncexitstack.py:18: in __call__
    await self.app(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/routing.py:716: in __call__
    await self.middleware_stack(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/routing.py:736: in app
    await route.handle(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/routing.py:290: in handle
    await self.app(scope, receive, send)
.venv/lib/python3.12/site-packages/fastapi/routing.py:115: in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
.venv/lib/python3.12/site-packages/starlette/_exception_handler.py:53: in wrapped_app
    raise exc
.venv/lib/python3.12/site-packages/starlette/_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv/lib/python3.12/site-packages/fastapi/routing.py:101: in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/fastapi/routing.py:355: in app
    raw_response = await run_endpoint_function(
.venv/lib/python3.12/site-packages/fastapi/routing.py:245: in run_endpoint_function
    return await run_in_threadpool(dependant.call, **values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/starlette/concurrency.py:32: in run_in_threadpool
    return await anyio.to_thread.run_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/anyio/to_thread.py:63: in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:2502: in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:986: in run
    result = context.run(func, *args)
             ^^^^^^^^^^^^^^^^^^^^^^^^
app/modules/audit_log/router.py:85: in get_audit_logs_by_trace_endpoint
    logs = get_audit_logs_by_trace(session, trace_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
app/modules/audit_log/crud.py:72: in get_audit_logs_by_trace
    return _unwrap_result(session.exec(statement).all())
                          ^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py:81: in exec
    results = super().execute(
.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:2351: in execute
    return self._execute_internal(
.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py:2249: in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
.venv/lib/python3.12/site-packages/sqlalchemy/orm/context.py:306: in orm_execute_statement
    result = conn.execute(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1419: in execute
    return meth(
.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:527: in _execute_on_connection
    return connection._execute_clauseelement(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1641: in _execute_clauseelement
    ret = self._execute_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846: in _execute_context
    return self._exec_single_context(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986: in _exec_single_context
    self._handle_dbapi_exception(
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2363: in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967: in _exec_single_context
    self.dialect.do_execute(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7f4b91ab9d60>
cursor = <sqlite3.Cursor object at 0x7f4b8d8aac40>
statement = 'SELECT tb_audit_log.audit_id, tb_audit_log.trace_id, tb_audit_log.parent_trace_id, tb_audit_log.resource_type, tb_aud...a, tb_audit_log.created_at \nFROM tb_audit_log \nWHERE tb_audit_log.trace_id = ? ORDER BY tb_audit_log.created_at DESC'
parameters = ('4f44dce4-8338-40ea-83c9-0fa104fb2379',)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7f4b8f5dbb90>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: tb_audit_log
E       [SQL: SELECT tb_audit_log.audit_id, tb_audit_log.trace_id, tb_audit_log.parent_trace_id, tb_audit_log.resource_type, tb_audit_log.resource_id, tb_audit_log.action, tb_audit_log.actor, tb_audit_log.changes, tb_audit_log.old_values, tb_audit_log.new_values, tb_audit_log.metadata, tb_audit_log.created_at 
E       FROM tb_audit_log 
E       WHERE tb_audit_log.trace_id = ? ORDER BY tb_audit_log.created_at DESC]
E       [parameters: ('4f44dce4-8338-40ea-83c9-0fa104fb2379',)]
E       (Background on this error at: https://sqlalche.me/e/20/e3q8)

.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:952: OperationalError
----------------------------- Captured stdout call -----------------------------
2026-01-22 17:57:48,217 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2026-01-22 17:57:48,218 INFO sqlalchemy.engine.Engine INSERT INTO tb_audit_log (audit_id, trace_id, parent_trace_id, resource_type, resource_id, action, actor, changes, old_values, new_values, metadata, created_at) VALUES (%(audit_id)s::UUID, %(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(resource_type)s::VARCHAR, %(resource_id)s::VARCHAR, %(action)s::VARCHAR, %(actor)s::VARCHAR, %(changes)s::JSONB, %(old_values)s::JSONB, %(new_values)s::JSONB, %(metadata)s::JSONB, %(created_at)s::TIMESTAMP WITH TIME ZONE)
2026-01-22 17:57:48,218 INFO sqlalchemy.engine.Engine [cached since 1.084s ago] {'audit_id': UUID('e2002eb7-d890-4fd4-999b-19f7c6abfd29'), 'trace_id': '4f44dce4-8338-40ea-83c9-0fa104fb2379', 'parent_trace_id': 'a49e305c-d1ce-4492-8c9a-ca1fad270fae', 'resource_type': 'settings', 'resource_id': 'ops_mode', 'action': 'update', 'actor': 'test-suite', 'changes': Jsonb({'value': 'test'}), 'old_values': Jsonb(None), 'new_values': Jsonb(None), 'metadata': Jsonb(None), 'created_at': datetime.datetime(2026, 1, 22, 8, 57, 48, 216925)}
2026-01-22 17:57:48,260 INFO sqlalchemy.engine.Engine COMMIT
2026-01-22 17:57:48,280 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2026-01-22 17:57:48,281 INFO sqlalchemy.engine.Engine SELECT tb_audit_log.audit_id, tb_audit_log.trace_id, tb_audit_log.parent_trace_id, tb_audit_log.resource_type, tb_audit_log.resource_id, tb_audit_log.action, tb_audit_log.actor, tb_audit_log.changes, tb_audit_log.old_values, tb_audit_log.new_values, tb_audit_log.metadata, tb_audit_log.created_at 
FROM tb_audit_log 
WHERE tb_audit_log.audit_id = %(pk_1)s::UUID
2026-01-22 17:57:48,281 INFO sqlalchemy.engine.Engine [cached since 1.087s ago] {'pk_1': UUID('e2002eb7-d890-4fd4-999b-19f7c6abfd29')}
2026-01-22 17:57:48,303 INFO sqlalchemy.engine.Engine ROLLBACK
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:57:48+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- BEGIN (implicit) taskName=None asctime=2026-01-22T17:57:48+0900
2026-01-22T17:57:48+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- INSERT INTO tb_audit_log (audit_id, trace_id, parent_trace_id, resource_type, resource_id, action, actor, changes, old_values, new_values, metadata, created_at) VALUES (%(audit_id)s::UUID, %(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(resource_type)s::VARCHAR, %(resource_id)s::VARCHAR, %(action)s::VARCHAR, %(actor)s::VARCHAR, %(changes)s::JSONB, %(old_values)s::JSONB, %(new_values)s::JSONB, %(metadata)s::JSONB, %(created_at)s::TIMESTAMP WITH TIME ZONE) taskName=None asctime=2026-01-22T17:57:48+0900
2026-01-22T17:57:48+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- [cached since 1.084s ago] {'audit_id': UUID('e2002eb7-d890-4fd4-999b-19f7c6abfd29'), 'trace_id': '4f44dce4-8338-40ea-83c9-0fa104fb2379', 'parent_trace_id': 'a49e305c-d1ce-4492-8c9a-ca1fad270fae', 'resource_type': 'settings', 'resource_id': 'ops_mode', 'action': 'update', 'actor': 'test-suite', 'changes': Jsonb({'value': 'test'}), 'old_values': Jsonb(None), 'new_values': Jsonb(None), 'metadata': Jsonb(None), 'created_at': datetime.datetime(2026, 1, 22, 8, 57, 48, 216925)} taskName=None asctime=2026-01-22T17:57:48+0900
2026-01-22T17:57:48+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- COMMIT taskName=None asctime=2026-01-22T17:57:48+0900
2026-01-22T17:57:48+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- BEGIN (implicit) taskName=None asctime=2026-01-22T17:57:48+0900
2026-01-22T17:57:48+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- SELECT tb_audit_log.audit_id, tb_audit_log.trace_id, tb_audit_log.parent_trace_id, tb_audit_log.resource_type, tb_audit_log.resource_id, tb_audit_log.action, tb_audit_log.actor, tb_audit_log.changes, tb_audit_log.old_values, tb_audit_log.new_values, tb_audit_log.metadata, tb_audit_log.created_at 
FROM tb_audit_log 
WHERE tb_audit_log.audit_id = %(pk_1)s::UUID taskName=None asctime=2026-01-22T17:57:48+0900
2026-01-22T17:57:48+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- [cached since 1.087s ago] {'pk_1': UUID('e2002eb7-d890-4fd4-999b-19f7c6abfd29')} taskName=None asctime=2026-01-22T17:57:48+0900
2026-01-22T17:57:48+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- ROLLBACK taskName=None asctime=2026-01-22T17:57:48+0900
2026-01-22T17:57:48+0900 DEBUG asyncio request_id=- tenant_id=- trace_id=- mode=- Using selector: EpollSelector taskName=None asctime=2026-01-22T17:57:48+0900
------------------------------ Captured log call -------------------------------
INFO     sqlalchemy.engine.Engine:base.py:2710 BEGIN (implicit)
INFO     sqlalchemy.engine.Engine:base.py:1846 INSERT INTO tb_audit_log (audit_id, trace_id, parent_trace_id, resource_type, resource_id, action, actor, changes, old_values, new_values, metadata, created_at) VALUES (%(audit_id)s::UUID, %(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(resource_type)s::VARCHAR, %(resource_id)s::VARCHAR, %(action)s::VARCHAR, %(actor)s::VARCHAR, %(changes)s::JSONB, %(old_values)s::JSONB, %(new_values)s::JSONB, %(metadata)s::JSONB, %(created_at)s::TIMESTAMP WITH TIME ZONE)
INFO     sqlalchemy.engine.Engine:base.py:1846 [cached since 1.084s ago] {'audit_id': UUID('e2002eb7-d890-4fd4-999b-19f7c6abfd29'), 'trace_id': '4f44dce4-8338-40ea-83c9-0fa104fb2379', 'parent_trace_id': 'a49e305c-d1ce-4492-8c9a-ca1fad270fae', 'resource_type': 'settings', 'resource_id': 'ops_mode', 'action': 'update', 'actor': 'test-suite', 'changes': Jsonb({'value': 'test'}), 'old_values': Jsonb(None), 'new_values': Jsonb(None), 'metadata': Jsonb(None), 'created_at': datetime.datetime(2026, 1, 22, 8, 57, 48, 216925)}
INFO     sqlalchemy.engine.Engine:base.py:2716 COMMIT
INFO     sqlalchemy.engine.Engine:base.py:2710 BEGIN (implicit)
INFO     sqlalchemy.engine.Engine:base.py:1846 SELECT tb_audit_log.audit_id, tb_audit_log.trace_id, tb_audit_log.parent_trace_id, tb_audit_log.resource_type, tb_audit_log.resource_id, tb_audit_log.action, tb_audit_log.actor, tb_audit_log.changes, tb_audit_log.old_values, tb_audit_log.new_values, tb_audit_log.metadata, tb_audit_log.created_at 
FROM tb_audit_log 
WHERE tb_audit_log.audit_id = %(pk_1)s::UUID
INFO     sqlalchemy.engine.Engine:base.py:1846 [cached since 1.087s ago] {'pk_1': UUID('e2002eb7-d890-4fd4-999b-19f7c6abfd29')}
INFO     sqlalchemy.engine.Engine:base.py:2713 ROLLBACK
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
_______________________ test_get_all_operation_settings ________________________

client = <starlette.testclient.TestClient object at 0x7f4b8d9a66c0>

    def test_get_all_operation_settings(client):
        """Test GET /settings/operations returns all settings."""
        response = client.get("/settings/operations")
>       assert response.status_code == 200
E       assert 500 == 200
E        +  where 500 = <Response [500 Internal Server Error]>.status_code

tests/test_operation_settings.py:16: AssertionError
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:58:12+0900 DEBUG asyncio request_id=- tenant_id=- trace_id=- mode=- Using selector: EpollSelector taskName=None asctime=2026-01-22T17:58:12+0900
2026-01-22T17:58:12+0900 ERROR app.modules.operation_settings.router request_id=- tenant_id=- trace_id=- mode=- operation_settings.get_all.error
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: tb_operation_settings

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/router.py", line 30, in get_all_operation_settings
    settings = OperationSettingsService.get_all_settings(session, app_settings)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/services.py", line 111, in get_all_settings
    effective = get_setting_effective_value(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 139, in get_setting_effective_value
    setting = get_setting_by_key(session, setting_key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 19, in get_setting_by_key
    return session.exec(statement).first()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py", line 81, in exec
    results = super().execute(
              ^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2351, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2249, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 306, in orm_execute_statement
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: tb_operation_settings
[SQL: SELECT tb_operation_settings.setting_id, tb_operation_settings.setting_key, tb_operation_settings.setting_value, tb_operation_settings.source, tb_operation_settings.env_override, tb_operation_settings.restart_required, tb_operation_settings.description, tb_operation_settings.published_by, tb_operation_settings.published_at, tb_operation_settings.created_at, tb_operation_settings.updated_at 
FROM tb_operation_settings 
WHERE tb_operation_settings.setting_key = ?]
[parameters: ('ops_mode',)]
(Background on this error at: https://sqlalche.me/e/20/e3q8) taskName=None asctime=2026-01-22T17:58:12+0900
2026-01-22T17:58:12+0900 INFO httpx request_id=- tenant_id=- trace_id=- mode=- HTTP Request: GET http://testserver/settings/operations "HTTP/1.1 500 Internal Server Error" taskName=None asctime=2026-01-22T17:58:12+0900
------------------------------ Captured log call -------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
ERROR    app.modules.operation_settings.router:router.py:34 operation_settings.get_all.error
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: tb_operation_settings

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/router.py", line 30, in get_all_operation_settings
    settings = OperationSettingsService.get_all_settings(session, app_settings)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/services.py", line 111, in get_all_settings
    effective = get_setting_effective_value(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 139, in get_setting_effective_value
    setting = get_setting_by_key(session, setting_key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 19, in get_setting_by_key
    return session.exec(statement).first()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py", line 81, in exec
    results = super().execute(
              ^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2351, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2249, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 306, in orm_execute_statement
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: tb_operation_settings
[SQL: SELECT tb_operation_settings.setting_id, tb_operation_settings.setting_key, tb_operation_settings.setting_value, tb_operation_settings.source, tb_operation_settings.env_override, tb_operation_settings.restart_required, tb_operation_settings.description, tb_operation_settings.published_by, tb_operation_settings.published_at, tb_operation_settings.created_at, tb_operation_settings.updated_at 
FROM tb_operation_settings 
WHERE tb_operation_settings.setting_key = ?]
[parameters: ('ops_mode',)]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
INFO     httpx:_client.py:1025 HTTP Request: GET http://testserver/settings/operations "HTTP/1.1 500 Internal Server Error"
__________________________ test_get_ops_mode_setting ___________________________

client = <starlette.testclient.TestClient object at 0x7f4b8da1d070>

    def test_get_ops_mode_setting(client):
        """Test GET /settings/operations/ops_mode returns ops_mode setting."""
        response = client.get("/settings/operations/ops_mode")
>       assert response.status_code == 200
E       assert 500 == 200
E        +  where 500 = <Response [500 Internal Server Error]>.status_code

tests/test_operation_settings.py:45: AssertionError
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:58:12+0900 DEBUG asyncio request_id=- tenant_id=- trace_id=- mode=- Using selector: EpollSelector taskName=None asctime=2026-01-22T17:58:12+0900
2026-01-22T17:58:12+0900 ERROR app.modules.operation_settings.router request_id=- tenant_id=- trace_id=- mode=- operation_settings.get.error
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: tb_operation_settings

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/router.py", line 56, in get_operation_setting
    setting = OperationSettingsService.get_setting(session, setting_key, app_settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/services.py", line 155, in get_setting
    effective = get_setting_effective_value(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 139, in get_setting_effective_value
    setting = get_setting_by_key(session, setting_key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 19, in get_setting_by_key
    return session.exec(statement).first()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py", line 81, in exec
    results = super().execute(
              ^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2351, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2249, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 306, in orm_execute_statement
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: tb_operation_settings
[SQL: SELECT tb_operation_settings.setting_id, tb_operation_settings.setting_key, tb_operation_settings.setting_value, tb_operation_settings.source, tb_operation_settings.env_override, tb_operation_settings.restart_required, tb_operation_settings.description, tb_operation_settings.published_by, tb_operation_settings.published_at, tb_operation_settings.created_at, tb_operation_settings.updated_at 
FROM tb_operation_settings 
WHERE tb_operation_settings.setting_key = ?]
[parameters: ('ops_mode',)]
(Background on this error at: https://sqlalche.me/e/20/e3q8) taskName=None asctime=2026-01-22T17:58:12+0900
2026-01-22T17:58:12+0900 INFO httpx request_id=- tenant_id=- trace_id=- mode=- HTTP Request: GET http://testserver/settings/operations/ops_mode "HTTP/1.1 500 Internal Server Error" taskName=None asctime=2026-01-22T17:58:12+0900
------------------------------ Captured log call -------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
ERROR    app.modules.operation_settings.router:router.py:63 operation_settings.get.error
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: tb_operation_settings

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/router.py", line 56, in get_operation_setting
    setting = OperationSettingsService.get_setting(session, setting_key, app_settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/services.py", line 155, in get_setting
    effective = get_setting_effective_value(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 139, in get_setting_effective_value
    setting = get_setting_by_key(session, setting_key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 19, in get_setting_by_key
    return session.exec(statement).first()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py", line 81, in exec
    results = super().execute(
              ^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2351, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2249, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 306, in orm_execute_statement
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: tb_operation_settings
[SQL: SELECT tb_operation_settings.setting_id, tb_operation_settings.setting_key, tb_operation_settings.setting_value, tb_operation_settings.source, tb_operation_settings.env_override, tb_operation_settings.restart_required, tb_operation_settings.description, tb_operation_settings.published_by, tb_operation_settings.published_at, tb_operation_settings.created_at, tb_operation_settings.updated_at 
FROM tb_operation_settings 
WHERE tb_operation_settings.setting_key = ?]
[parameters: ('ops_mode',)]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
INFO     httpx:_client.py:1025 HTTP Request: GET http://testserver/settings/operations/ops_mode "HTTP/1.1 500 Internal Server Error"
_________________________ test_update_ops_mode_setting _________________________

client = <starlette.testclient.TestClient object at 0x7f4b8d9c6180>

    def test_update_ops_mode_setting(client):
        """Test PUT /settings/operations/ops_mode updates the setting."""
        # Get current value
        response = client.get("/settings/operations/ops_mode")
>       assert response.status_code == 200
E       assert 500 == 200
E        +  where 500 = <Response [500 Internal Server Error]>.status_code

tests/test_operation_settings.py:69: AssertionError
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:58:12+0900 DEBUG asyncio request_id=- tenant_id=- trace_id=- mode=- Using selector: EpollSelector taskName=None asctime=2026-01-22T17:58:12+0900
2026-01-22T17:58:12+0900 ERROR app.modules.operation_settings.router request_id=- tenant_id=- trace_id=- mode=- operation_settings.get.error
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: tb_operation_settings

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/router.py", line 56, in get_operation_setting
    setting = OperationSettingsService.get_setting(session, setting_key, app_settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/services.py", line 155, in get_setting
    effective = get_setting_effective_value(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 139, in get_setting_effective_value
    setting = get_setting_by_key(session, setting_key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 19, in get_setting_by_key
    return session.exec(statement).first()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py", line 81, in exec
    results = super().execute(
              ^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2351, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2249, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 306, in orm_execute_statement
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: tb_operation_settings
[SQL: SELECT tb_operation_settings.setting_id, tb_operation_settings.setting_key, tb_operation_settings.setting_value, tb_operation_settings.source, tb_operation_settings.env_override, tb_operation_settings.restart_required, tb_operation_settings.description, tb_operation_settings.published_by, tb_operation_settings.published_at, tb_operation_settings.created_at, tb_operation_settings.updated_at 
FROM tb_operation_settings 
WHERE tb_operation_settings.setting_key = ?]
[parameters: ('ops_mode',)]
(Background on this error at: https://sqlalche.me/e/20/e3q8) taskName=None asctime=2026-01-22T17:58:12+0900
2026-01-22T17:58:12+0900 INFO httpx request_id=- tenant_id=- trace_id=- mode=- HTTP Request: GET http://testserver/settings/operations/ops_mode "HTTP/1.1 500 Internal Server Error" taskName=None asctime=2026-01-22T17:58:12+0900
------------------------------ Captured log call -------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
ERROR    app.modules.operation_settings.router:router.py:63 operation_settings.get.error
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: tb_operation_settings

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/router.py", line 56, in get_operation_setting
    setting = OperationSettingsService.get_setting(session, setting_key, app_settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/services.py", line 155, in get_setting
    effective = get_setting_effective_value(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 139, in get_setting_effective_value
    setting = get_setting_by_key(session, setting_key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 19, in get_setting_by_key
    return session.exec(statement).first()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py", line 81, in exec
    results = super().execute(
              ^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2351, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2249, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 306, in orm_execute_statement
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: tb_operation_settings
[SQL: SELECT tb_operation_settings.setting_id, tb_operation_settings.setting_key, tb_operation_settings.setting_value, tb_operation_settings.source, tb_operation_settings.env_override, tb_operation_settings.restart_required, tb_operation_settings.description, tb_operation_settings.published_by, tb_operation_settings.published_at, tb_operation_settings.created_at, tb_operation_settings.updated_at 
FROM tb_operation_settings 
WHERE tb_operation_settings.setting_key = ?]
[parameters: ('ops_mode',)]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
INFO     httpx:_client.py:1025 HTTP Request: GET http://testserver/settings/operations/ops_mode "HTTP/1.1 500 Internal Server Error"
_________________________ test_update_boolean_setting __________________________

client = <starlette.testclient.TestClient object at 0x7f4b8eee2a20>

    def test_update_boolean_setting(client):
        """Test PUT /settings/operations/enable_system_apis updates boolean setting."""
        # Get current value
        response = client.get("/settings/operations/enable_system_apis")
>       assert response.status_code == 200
E       assert 500 == 200
E        +  where 500 = <Response [500 Internal Server Error]>.status_code

tests/test_operation_settings.py:119: AssertionError
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:58:12+0900 DEBUG asyncio request_id=- tenant_id=- trace_id=- mode=- Using selector: EpollSelector taskName=None asctime=2026-01-22T17:58:12+0900
2026-01-22T17:58:12+0900 ERROR app.modules.operation_settings.router request_id=- tenant_id=- trace_id=- mode=- operation_settings.get.error
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: tb_operation_settings

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/router.py", line 56, in get_operation_setting
    setting = OperationSettingsService.get_setting(session, setting_key, app_settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/services.py", line 155, in get_setting
    effective = get_setting_effective_value(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 139, in get_setting_effective_value
    setting = get_setting_by_key(session, setting_key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 19, in get_setting_by_key
    return session.exec(statement).first()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py", line 81, in exec
    results = super().execute(
              ^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2351, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2249, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 306, in orm_execute_statement
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: tb_operation_settings
[SQL: SELECT tb_operation_settings.setting_id, tb_operation_settings.setting_key, tb_operation_settings.setting_value, tb_operation_settings.source, tb_operation_settings.env_override, tb_operation_settings.restart_required, tb_operation_settings.description, tb_operation_settings.published_by, tb_operation_settings.published_at, tb_operation_settings.created_at, tb_operation_settings.updated_at 
FROM tb_operation_settings 
WHERE tb_operation_settings.setting_key = ?]
[parameters: ('enable_system_apis',)]
(Background on this error at: https://sqlalche.me/e/20/e3q8) taskName=None asctime=2026-01-22T17:58:12+0900
2026-01-22T17:58:12+0900 INFO httpx request_id=- tenant_id=- trace_id=- mode=- HTTP Request: GET http://testserver/settings/operations/enable_system_apis "HTTP/1.1 500 Internal Server Error" taskName=None asctime=2026-01-22T17:58:12+0900
------------------------------ Captured log call -------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
ERROR    app.modules.operation_settings.router:router.py:63 operation_settings.get.error
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: tb_operation_settings

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/router.py", line 56, in get_operation_setting
    setting = OperationSettingsService.get_setting(session, setting_key, app_settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/services.py", line 155, in get_setting
    effective = get_setting_effective_value(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 139, in get_setting_effective_value
    setting = get_setting_by_key(session, setting_key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 19, in get_setting_by_key
    return session.exec(statement).first()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py", line 81, in exec
    results = super().execute(
              ^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2351, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2249, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 306, in orm_execute_statement
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: tb_operation_settings
[SQL: SELECT tb_operation_settings.setting_id, tb_operation_settings.setting_key, tb_operation_settings.setting_value, tb_operation_settings.source, tb_operation_settings.env_override, tb_operation_settings.restart_required, tb_operation_settings.description, tb_operation_settings.published_by, tb_operation_settings.published_at, tb_operation_settings.created_at, tb_operation_settings.updated_at 
FROM tb_operation_settings 
WHERE tb_operation_settings.setting_key = ?]
[parameters: ('enable_system_apis',)]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
INFO     httpx:_client.py:1025 HTTP Request: GET http://testserver/settings/operations/enable_system_apis "HTTP/1.1 500 Internal Server Error"
___________________ test_setting_persistence_across_requests ___________________

client = <starlette.testclient.TestClient object at 0x7f4b8d9c4c80>

    def test_setting_persistence_across_requests(client):
        """Test that updated settings persist across requests."""
        # Update a setting
        new_value = "real"
        response1 = client.put(
            "/settings/operations/ops_mode",
            json={"value": new_value},
            params={"updated_by": "test_user"},
        )
>       assert response1.status_code == 200
E       assert 500 == 200
E        +  where 500 = <Response [500 Internal Server Error]>.status_code

tests/test_operation_settings.py:150: AssertionError
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:58:12+0900 DEBUG asyncio request_id=- tenant_id=- trace_id=- mode=- Using selector: EpollSelector taskName=None asctime=2026-01-22T17:58:12+0900
2026-01-22T17:58:12+0900 ERROR app.modules.operation_settings.router request_id=- tenant_id=- trace_id=- mode=- operation_settings.update.error
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: tb_operation_settings

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/router.py", line 99, in update_operation_setting
    updated_setting = OperationSettingsService.update_setting(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/services.py", line 213, in update_setting
    setting = create_or_update_setting(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 37, in create_or_update_setting
    existing = get_setting_by_key(session, setting_key)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 19, in get_setting_by_key
    return session.exec(statement).first()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py", line 81, in exec
    results = super().execute(
              ^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2351, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2249, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 306, in orm_execute_statement
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: tb_operation_settings
[SQL: SELECT tb_operation_settings.setting_id, tb_operation_settings.setting_key, tb_operation_settings.setting_value, tb_operation_settings.source, tb_operation_settings.env_override, tb_operation_settings.restart_required, tb_operation_settings.description, tb_operation_settings.published_by, tb_operation_settings.published_at, tb_operation_settings.created_at, tb_operation_settings.updated_at 
FROM tb_operation_settings 
WHERE tb_operation_settings.setting_key = ?]
[parameters: ('ops_mode',)]
(Background on this error at: https://sqlalche.me/e/20/e3q8) taskName=None asctime=2026-01-22T17:58:12+0900
2026-01-22T17:58:12+0900 INFO httpx request_id=- tenant_id=- trace_id=- mode=- HTTP Request: PUT http://testserver/settings/operations/ops_mode?updated_by=test_user "HTTP/1.1 500 Internal Server Error" taskName=None asctime=2026-01-22T17:58:12+0900
------------------------------ Captured log call -------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
ERROR    app.modules.operation_settings.router:router.py:125 operation_settings.update.error
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such table: tb_operation_settings

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/router.py", line 99, in update_operation_setting
    updated_setting = OperationSettingsService.update_setting(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/services.py", line 213, in update_setting
    setting = create_or_update_setting(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 37, in create_or_update_setting
    existing = get_setting_by_key(session, setting_key)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/operation_settings/crud.py", line 19, in get_setting_by_key
    return session.exec(statement).first()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py", line 81, in exec
    results = super().execute(
              ^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2351, in execute
    return self._execute_internal(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2249, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/context.py", line 306, in orm_execute_statement
    result = conn.execute(
             ^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: tb_operation_settings
[SQL: SELECT tb_operation_settings.setting_id, tb_operation_settings.setting_key, tb_operation_settings.setting_value, tb_operation_settings.source, tb_operation_settings.env_override, tb_operation_settings.restart_required, tb_operation_settings.description, tb_operation_settings.published_by, tb_operation_settings.published_at, tb_operation_settings.created_at, tb_operation_settings.updated_at 
FROM tb_operation_settings 
WHERE tb_operation_settings.setting_key = ?]
[parameters: ('ops_mode',)]
(Background on this error at: https://sqlalche.me/e/20/e3q8)
INFO     httpx:_client.py:1025 HTTP Request: PUT http://testserver/settings/operations/ops_mode?updated_by=test_user "HTTP/1.1 500 Internal Server Error"
________________________ test_ops_all_real_blocks_shape ________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f4b8f240e60>

    @pytest.mark.skipif(
        not (HAS_DB and HAS_NEO4J),
        reason="Postgres or Neo4j not configured",
    )
    def test_ops_all_real_blocks_shape(monkeypatch):
        monkeypatch.setenv("OPS_MODE", "real")
        envelope = handle_ops_query("all", "srv-erp-01 CPU   7 ")
        assert envelope.meta.route == "all"
        assert not envelope.meta.fallback
        assert envelope.blocks
>       assert envelope.blocks[0].title == "ALL summary"
E       AssertionError: assert 'LangGraph plan error' == 'ALL summary'
E         
E         - ALL summary
E         + LangGraph plan error

tests/test_ops_service.py:115: AssertionError
----------------------------- Captured stdout call -----------------------------
2026-01-22 17:58:15,487 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2026-01-22 17:58:15,487 INFO sqlalchemy.engine.Engine INSERT INTO tb_execution_trace (trace_id, parent_trace_id, feature, endpoint, method, ops_mode, question, status, duration_ms, request_payload, applied_assets, asset_versions, fallbacks, plan_raw, plan_validated, execution_steps, "references", answer, ui_render, audit_links, flow_spans, route, stage_inputs, stage_outputs, replan_events, created_at) VALUES (%(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(feature)s::VARCHAR, %(endpoint)s::VARCHAR, %(method)s::VARCHAR, %(ops_mode)s::VARCHAR, %(question)s::VARCHAR, %(status)s::VARCHAR, %(duration_ms)s::INTEGER, %(request_payload)s::JSON, %(applied_assets)s::JSON, %(asset_versions)s::JSON, %(fallbacks)s::JSON, %(plan_raw)s::JSON, %(plan_validated)s::JSON, %(execution_steps)s::JSON, %(references)s::JSON, %(answer)s::JSON, %(ui_render)s::JSON, %(audit_links)s::JSON, %(flow_spans)s::JSON, %(route)s::VARCHAR, %(stage_inputs)s::JSON, %(stage_outputs)s::JSON, %(replan_events)s::JSON, %(created_at)s::TIMESTAMP WITH TIME ZONE)
2026-01-22 17:58:15,487 INFO sqlalchemy.engine.Engine [cached since 3.051s ago] {'trace_id': '13bded5a681b4ca2b61c127514c9ec63', 'parent_trace_id': None, 'feature': 'all', 'endpoint': '/ops/query', 'method': 'POST', 'ops_mode': 'real', 'question': 'srv-erp-01 CPU   7 ', 'status': 'error', 'duration_ms': 262, 'request_payload': Json({'question': 'srv-erp-01 CPU   ... (59 chars)), 'applied_assets': Json({'prompt': None, 'policy': None, 'm ... (79 chars)), 'asset_versions': Json(None), 'fallbacks': Json({'prompt': True, 'policy': True, 'm ... (65 chars)), 'plan_raw': Json(None), 'plan_validated': Json(None), 'execution_steps': Json([]), 'references': Json([]), 'answer': Json({'envelope_meta': {'route': 'all',  ... (592 chars)), 'ui_render': Json(None), 'audit_links': Json({'related_audit_log_ids': []}), 'flow_spans': Json(None), 'route': 'orch', 'stage_inputs': Json([]), 'stage_outputs': Json([]), 'replan_events': Json([]), 'created_at': datetime.datetime(2026, 1, 22, 8, 58, 15, 487031)}
2026-01-22 17:58:15,502 INFO sqlalchemy.engine.Engine ROLLBACK
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:58:15+0900 INFO app.shared.config_loader request_id=- tenant_id=- trace_id=- mode=- Loaded and cached resource: prompts/ops/langgraph.yaml taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG root request_id=- tenant_id=- trace_id=- mode=- LLM create_response: model=gpt-5-nano, input=[{'role': 'system', 'content': 'You are a deterministic LangGraph planner/aggregator.\n'}, {'role':  taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- Request options: {'method': 'post', 'url': '/responses', 'files': None, 'idempotency_key': 'stainless-python-retry-96b36d43-d38b-4d8c-869a-0977c04e41b8', 'json_data': {'input': [{'role': 'system', 'content': 'You are a deterministic LangGraph planner/aggregator.\n'}, {'role': 'user', 'content': 'You are orchestrating OPS queries. The question is:\nsrv-erp-01 CPU   7 \n\nReturn only JSON that follows this schema:\n{\n  "run_metric": bool,\n  "run_hist": bool,\n  "run_graph": bool,\n  "time_hint": str | null,\n  "metric_hint": str | null,\n  "ci_hint": str | null\n}\n\nChoose the minimum set of executors needed to answer the question.\nHint fields help suffix the question to narrow the scope.\nIf unsure prefer both metric and hist.\n'}], 'model': 'gpt-5-nano', 'stream': False, 'temperature': 0.1, 'tools': None}} taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- Sending HTTP Request: POST https://api.openai.com/v1/responses taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.connection request_id=- tenant_id=- trace_id=- mode=- close.started taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.connection request_id=- tenant_id=- trace_id=- mode=- close.complete taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.connection request_id=- tenant_id=- trace_id=- mode=- connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.connection request_id=- tenant_id=- trace_id=- mode=- connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4b8da1f6b0> taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.connection request_id=- tenant_id=- trace_id=- mode=- start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4b8da5f650> server_hostname='api.openai.com' timeout=5.0 taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.connection request_id=- tenant_id=- trace_id=- mode=- start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4b8f0b15e0> taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- send_request_headers.started request=<Request [b'POST']> taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- send_request_headers.complete taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- send_request_body.started request=<Request [b'POST']> taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- send_request_body.complete taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- receive_response_headers.started request=<Request [b'POST']> taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 22 Jan 2026 08:58:16 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'191'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-kaavui2jbkapfiamtwmmzph7'), (b'openai-project', b'proj_qScKRtu1GYNIlwsdnYLEkSAp'), (b'x-request-id', b'req_2cfbf1e757ea46b8ac4fb4f1a8d6131b'), (b'openai-processing-ms', b'35'), (b'x-envoy-upstream-service-time', b'39'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9c1dd93b1b3ce9fd-ICN'), (b'alt-svc', b'h3=":443"; ma=86400')]) taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 INFO httpx request_id=- tenant_id=- trace_id=- mode=- HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request" taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- receive_response_body.started request=<Request [b'POST']> taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- receive_response_body.complete taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- response_closed.started taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- response_closed.complete taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- HTTP Response: POST https://api.openai.com/v1/responses "400 Bad Request" Headers({'date': 'Thu, 22 Jan 2026 08:58:16 GMT', 'content-type': 'application/json', 'content-length': '191', 'connection': 'keep-alive', 'openai-version': '2020-10-01', 'openai-organization': 'user-kaavui2jbkapfiamtwmmzph7', 'openai-project': 'proj_qScKRtu1GYNIlwsdnYLEkSAp', 'x-request-id': 'req_2cfbf1e757ea46b8ac4fb4f1a8d6131b', 'openai-processing-ms': '35', 'x-envoy-upstream-service-time': '39', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9c1dd93b1b3ce9fd-ICN', 'alt-svc': 'h3=":443"; ma=86400'}) taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- request_id: req_2cfbf1e757ea46b8ac4fb4f1a8d6131b taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1027, in request
    response.raise_for_status()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/responses'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400 taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- Not retrying taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- Re-raising status error taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 ERROR root request_id=- tenant_id=- trace_id=- mode=- LangGraph plan failed
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/langgraph.py", line 43, in run
    plan = self._plan(question)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/langgraph.py", line 92, in _plan
    response = self._call_llm(prompt, system_prompt)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/langgraph.py", line 160, in _call_llm
    response = self._llm.create_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/llm/client.py", line 33, in create_response
    return self.client.responses.create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/resources/responses/responses.py", line 866, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': None}} taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- BEGIN (implicit) taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- INSERT INTO tb_execution_trace (trace_id, parent_trace_id, feature, endpoint, method, ops_mode, question, status, duration_ms, request_payload, applied_assets, asset_versions, fallbacks, plan_raw, plan_validated, execution_steps, "references", answer, ui_render, audit_links, flow_spans, route, stage_inputs, stage_outputs, replan_events, created_at) VALUES (%(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(feature)s::VARCHAR, %(endpoint)s::VARCHAR, %(method)s::VARCHAR, %(ops_mode)s::VARCHAR, %(question)s::VARCHAR, %(status)s::VARCHAR, %(duration_ms)s::INTEGER, %(request_payload)s::JSON, %(applied_assets)s::JSON, %(asset_versions)s::JSON, %(fallbacks)s::JSON, %(plan_raw)s::JSON, %(plan_validated)s::JSON, %(execution_steps)s::JSON, %(references)s::JSON, %(answer)s::JSON, %(ui_render)s::JSON, %(audit_links)s::JSON, %(flow_spans)s::JSON, %(route)s::VARCHAR, %(stage_inputs)s::JSON, %(stage_outputs)s::JSON, %(replan_events)s::JSON, %(created_at)s::TIMESTAMP WITH TIME ZONE) taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- [cached since 3.051s ago] {'trace_id': '13bded5a681b4ca2b61c127514c9ec63', 'parent_trace_id': None, 'feature': 'all', 'endpoint': '/ops/query', 'method': 'POST', 'ops_mode': 'real', 'question': 'srv-erp-01 CPU   7 ', 'status': 'error', 'duration_ms': 262, 'request_payload': Json({'question': 'srv-erp-01 CPU   ... (59 chars)), 'applied_assets': Json({'prompt': None, 'policy': None, 'm ... (79 chars)), 'asset_versions': Json(None), 'fallbacks': Json({'prompt': True, 'policy': True, 'm ... (65 chars)), 'plan_raw': Json(None), 'plan_validated': Json(None), 'execution_steps': Json([]), 'references': Json([]), 'answer': Json({'envelope_meta': {'route': 'all',  ... (592 chars)), 'ui_render': Json(None), 'audit_links': Json({'related_audit_log_ids': []}), 'flow_spans': Json(None), 'route': 'orch', 'stage_inputs': Json([]), 'stage_outputs': Json([]), 'replan_events': Json([]), 'created_at': datetime.datetime(2026, 1, 22, 8, 58, 15, 487031)} taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- ROLLBACK taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 ERROR root request_id=- tenant_id=- trace_id=- mode=- ops.trace.persist_failed
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/psycopg/cursor.py", line 117, in execute
    raise ex.with_traceback(None)
psycopg.errors.UndefinedColumn: "route"  "tb_execution_trace" (relation) 
LINE 1: ...ces", answer, ui_render, audit_links, flow_spans, route, sta...
                                                             ^

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/__init__.py", line 145, in handle_ops_query
    persist_execution_trace(
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/inspector/service.py", line 208, in persist_execution_trace
    return create_execution_trace(session, trace_entry)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/inspector/crud.py", line 20, in create_execution_trace
    session.commit()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2030, in commit
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1311, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1286, in _prepare_impl
    self.session.flush()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4331, in flush
    self._flush(objects)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4466, in _flush
    with util.safe_reraise():
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4427, in _flush
    flush_context.execute()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1048, in _emit_insert_statements
    result = connection.execute(
             ^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/psycopg/cursor.py", line 117, in execute
    raise ex.with_traceback(None)
sqlalchemy.exc.ProgrammingError: (psycopg.errors.UndefinedColumn) "route"  "tb_execution_trace" (relation) 
LINE 1: ...ces", answer, ui_render, audit_links, flow_spans, route, sta...
                                                             ^
[SQL: INSERT INTO tb_execution_trace (trace_id, parent_trace_id, feature, endpoint, method, ops_mode, question, status, duration_ms, request_payload, applied_assets, asset_versions, fallbacks, plan_raw, plan_validated, execution_steps, "references", answer, ui_render, audit_links, flow_spans, route, stage_inputs, stage_outputs, replan_events, created_at) VALUES (%(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(feature)s::VARCHAR, %(endpoint)s::VARCHAR, %(method)s::VARCHAR, %(ops_mode)s::VARCHAR, %(question)s::VARCHAR, %(status)s::VARCHAR, %(duration_ms)s::INTEGER, %(request_payload)s::JSON, %(applied_assets)s::JSON, %(asset_versions)s::JSON, %(fallbacks)s::JSON, %(plan_raw)s::JSON, %(plan_validated)s::JSON, %(execution_steps)s::JSON, %(references)s::JSON, %(answer)s::JSON, %(ui_render)s::JSON, %(audit_links)s::JSON, %(flow_spans)s::JSON, %(route)s::VARCHAR, %(stage_inputs)s::JSON, %(stage_outputs)s::JSON, %(replan_events)s::JSON, %(created_at)s::TIMESTAMP WITH TIME ZONE)]
[parameters: {'trace_id': '13bded5a681b4ca2b61c127514c9ec63', 'parent_trace_id': None, 'feature': 'all', 'endpoint': '/ops/query', 'method': 'POST', 'ops_mode': 'real', 'question': 'srv-erp-01 CPU   7 ', 'status': 'error', 'duration_ms': 262, 'request_payload': Json({'question': 'srv-erp-01 CPU   ... (59 chars)), 'applied_assets': Json({'prompt': None, 'policy': None, 'm ... (79 chars)), 'asset_versions': Json(None), 'fallbacks': Json({'prompt': True, 'policy': True, 'm ... (65 chars)), 'plan_raw': Json(None), 'plan_validated': Json(None), 'execution_steps': Json([]), 'references': Json([]), 'answer': Json({'envelope_meta': {'route': 'all',  ... (592 chars)), 'ui_render': Json(None), 'audit_links': Json({'related_audit_log_ids': []}), 'flow_spans': Json(None), 'route': 'orch', 'stage_inputs': Json([]), 'stage_outputs': Json([]), 'replan_events': Json([]), 'created_at': datetime.datetime(2026, 1, 22, 8, 58, 15, 487031)}]
(Background on this error at: https://sqlalche.me/e/20/f405) taskName=None asctime=2026-01-22T17:58:15+0900
------------------------------ Captured log call -------------------------------
INFO     app.shared.config_loader:config_loader.py:63 Loaded and cached resource: prompts/ops/langgraph.yaml
DEBUG    root:client.py:32 LLM create_response: model=gpt-5-nano, input=[{'role': 'system', 'content': 'You are a deterministic LangGraph planner/aggregator.\n'}, {'role': 
DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/responses', 'files': None, 'idempotency_key': 'stainless-python-retry-96b36d43-d38b-4d8c-869a-0977c04e41b8', 'json_data': {'input': [{'role': 'system', 'content': 'You are a deterministic LangGraph planner/aggregator.\n'}, {'role': 'user', 'content': 'You are orchestrating OPS queries. The question is:\nsrv-erp-01 CPU   7 \n\nReturn only JSON that follows this schema:\n{\n  "run_metric": bool,\n  "run_hist": bool,\n  "run_graph": bool,\n  "time_hint": str | null,\n  "metric_hint": str | null,\n  "ci_hint": str | null\n}\n\nChoose the minimum set of executors needed to answer the question.\nHint fields help suffix the question to narrow the scope.\nIf unsure prefer both metric and hist.\n'}], 'model': 'gpt-5-nano', 'stream': False, 'temperature': 0.1, 'tools': None}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://api.openai.com/v1/responses
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4b8da1f6b0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4b8da5f650> server_hostname='api.openai.com' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4b8f0b15e0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 22 Jan 2026 08:58:16 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'191'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-kaavui2jbkapfiamtwmmzph7'), (b'openai-project', b'proj_qScKRtu1GYNIlwsdnYLEkSAp'), (b'x-request-id', b'req_2cfbf1e757ea46b8ac4fb4f1a8d6131b'), (b'openai-processing-ms', b'35'), (b'x-envoy-upstream-service-time', b'39'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9c1dd93b1b3ce9fd-ICN'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://api.openai.com/v1/responses "400 Bad Request" Headers({'date': 'Thu, 22 Jan 2026 08:58:16 GMT', 'content-type': 'application/json', 'content-length': '191', 'connection': 'keep-alive', 'openai-version': '2020-10-01', 'openai-organization': 'user-kaavui2jbkapfiamtwmmzph7', 'openai-project': 'proj_qScKRtu1GYNIlwsdnYLEkSAp', 'x-request-id': 'req_2cfbf1e757ea46b8ac4fb4f1a8d6131b', 'openai-processing-ms': '35', 'x-envoy-upstream-service-time': '39', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9c1dd93b1b3ce9fd-ICN', 'alt-svc': 'h3=":443"; ma=86400'})
DEBUG    openai._base_client:_base_client.py:1024 request_id: req_2cfbf1e757ea46b8ac4fb4f1a8d6131b
DEBUG    openai._base_client:_base_client.py:1029 Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1027, in request
    response.raise_for_status()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/responses'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
DEBUG    openai._base_client:_base_client.py:782 Not retrying
DEBUG    openai._base_client:_base_client.py:1046 Re-raising status error
ERROR    root:langgraph.py:45 LangGraph plan failed
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/langgraph.py", line 43, in run
    plan = self._plan(question)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/langgraph.py", line 92, in _plan
    response = self._call_llm(prompt, system_prompt)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/langgraph.py", line 160, in _call_llm
    response = self._llm.create_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/llm/client.py", line 33, in create_response
    return self.client.responses.create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/resources/responses/responses.py", line 866, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': None}}
INFO     sqlalchemy.engine.Engine:base.py:2710 BEGIN (implicit)
INFO     sqlalchemy.engine.Engine:base.py:1846 INSERT INTO tb_execution_trace (trace_id, parent_trace_id, feature, endpoint, method, ops_mode, question, status, duration_ms, request_payload, applied_assets, asset_versions, fallbacks, plan_raw, plan_validated, execution_steps, "references", answer, ui_render, audit_links, flow_spans, route, stage_inputs, stage_outputs, replan_events, created_at) VALUES (%(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(feature)s::VARCHAR, %(endpoint)s::VARCHAR, %(method)s::VARCHAR, %(ops_mode)s::VARCHAR, %(question)s::VARCHAR, %(status)s::VARCHAR, %(duration_ms)s::INTEGER, %(request_payload)s::JSON, %(applied_assets)s::JSON, %(asset_versions)s::JSON, %(fallbacks)s::JSON, %(plan_raw)s::JSON, %(plan_validated)s::JSON, %(execution_steps)s::JSON, %(references)s::JSON, %(answer)s::JSON, %(ui_render)s::JSON, %(audit_links)s::JSON, %(flow_spans)s::JSON, %(route)s::VARCHAR, %(stage_inputs)s::JSON, %(stage_outputs)s::JSON, %(replan_events)s::JSON, %(created_at)s::TIMESTAMP WITH TIME ZONE)
INFO     sqlalchemy.engine.Engine:base.py:1846 [cached since 3.051s ago] {'trace_id': '13bded5a681b4ca2b61c127514c9ec63', 'parent_trace_id': None, 'feature': 'all', 'endpoint': '/ops/query', 'method': 'POST', 'ops_mode': 'real', 'question': 'srv-erp-01 CPU   7 ', 'status': 'error', 'duration_ms': 262, 'request_payload': Json({'question': 'srv-erp-01 CPU   ... (59 chars)), 'applied_assets': Json({'prompt': None, 'policy': None, 'm ... (79 chars)), 'asset_versions': Json(None), 'fallbacks': Json({'prompt': True, 'policy': True, 'm ... (65 chars)), 'plan_raw': Json(None), 'plan_validated': Json(None), 'execution_steps': Json([]), 'references': Json([]), 'answer': Json({'envelope_meta': {'route': 'all',  ... (592 chars)), 'ui_render': Json(None), 'audit_links': Json({'related_audit_log_ids': []}), 'flow_spans': Json(None), 'route': 'orch', 'stage_inputs': Json([]), 'stage_outputs': Json([]), 'replan_events': Json([]), 'created_at': datetime.datetime(2026, 1, 22, 8, 58, 15, 487031)}
INFO     sqlalchemy.engine.Engine:base.py:2713 ROLLBACK
ERROR    root:__init__.py:164 ops.trace.persist_failed
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/psycopg/cursor.py", line 117, in execute
    raise ex.with_traceback(None)
psycopg.errors.UndefinedColumn: "route"  "tb_execution_trace" (relation) 
LINE 1: ...ces", answer, ui_render, audit_links, flow_spans, route, sta...
                                                             ^

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/__init__.py", line 145, in handle_ops_query
    persist_execution_trace(
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/inspector/service.py", line 208, in persist_execution_trace
    return create_execution_trace(session, trace_entry)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/inspector/crud.py", line 20, in create_execution_trace
    session.commit()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2030, in commit
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1311, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1286, in _prepare_impl
    self.session.flush()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4331, in flush
    self._flush(objects)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4466, in _flush
    with util.safe_reraise():
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4427, in _flush
    flush_context.execute()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1048, in _emit_insert_statements
    result = connection.execute(
             ^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/psycopg/cursor.py", line 117, in execute
    raise ex.with_traceback(None)
sqlalchemy.exc.ProgrammingError: (psycopg.errors.UndefinedColumn) "route"  "tb_execution_trace" (relation) 
LINE 1: ...ces", answer, ui_render, audit_links, flow_spans, route, sta...
                                                             ^
[SQL: INSERT INTO tb_execution_trace (trace_id, parent_trace_id, feature, endpoint, method, ops_mode, question, status, duration_ms, request_payload, applied_assets, asset_versions, fallbacks, plan_raw, plan_validated, execution_steps, "references", answer, ui_render, audit_links, flow_spans, route, stage_inputs, stage_outputs, replan_events, created_at) VALUES (%(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(feature)s::VARCHAR, %(endpoint)s::VARCHAR, %(method)s::VARCHAR, %(ops_mode)s::VARCHAR, %(question)s::VARCHAR, %(status)s::VARCHAR, %(duration_ms)s::INTEGER, %(request_payload)s::JSON, %(applied_assets)s::JSON, %(asset_versions)s::JSON, %(fallbacks)s::JSON, %(plan_raw)s::JSON, %(plan_validated)s::JSON, %(execution_steps)s::JSON, %(references)s::JSON, %(answer)s::JSON, %(ui_render)s::JSON, %(audit_links)s::JSON, %(flow_spans)s::JSON, %(route)s::VARCHAR, %(stage_inputs)s::JSON, %(stage_outputs)s::JSON, %(replan_events)s::JSON, %(created_at)s::TIMESTAMP WITH TIME ZONE)]
[parameters: {'trace_id': '13bded5a681b4ca2b61c127514c9ec63', 'parent_trace_id': None, 'feature': 'all', 'endpoint': '/ops/query', 'method': 'POST', 'ops_mode': 'real', 'question': 'srv-erp-01 CPU   7 ', 'status': 'error', 'duration_ms': 262, 'request_payload': Json({'question': 'srv-erp-01 CPU   ... (59 chars)), 'applied_assets': Json({'prompt': None, 'policy': None, 'm ... (79 chars)), 'asset_versions': Json(None), 'fallbacks': Json({'prompt': True, 'policy': True, 'm ... (65 chars)), 'plan_raw': Json(None), 'plan_validated': Json(None), 'execution_steps': Json([]), 'references': Json([]), 'answer': Json({'envelope_meta': {'route': 'all',  ... (592 chars)), 'ui_render': Json(None), 'audit_links': Json({'related_audit_log_ids': []}), 'flow_spans': Json(None), 'route': 'orch', 'stage_inputs': Json([]), 'stage_outputs': Json([]), 'replan_events': Json([]), 'created_at': datetime.datetime(2026, 1, 22, 8, 58, 15, 487031)}]
(Background on this error at: https://sqlalche.me/e/20/f405)
________________ test_ops_all_langgraph_without_key_falls_back _________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f4b8da1f0b0>

    @pytest.mark.skipif(
        not (HAS_DB and HAS_NEO4J),
        reason="Postgres or Neo4j not configured",
    )
    def test_ops_all_langgraph_without_key_falls_back(monkeypatch):
        monkeypatch.setenv("OPS_MODE", "real")
        monkeypatch.setenv("OPS_ENABLE_LANGGRAPH", "true")
        monkeypatch.setenv("OPENAI_API_KEY", "")
>       envelope = handle_ops_query("all", "srv-erp-01 CPU   7 ")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_ops_service.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
app/modules/ops/services/__init__.py:97: in handle_ops_query
    result = _execute_real_mode(mode, question, settings)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
app/modules/ops/services/__init__.py:181: in _execute_real_mode
    return executor(question, settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
app/modules/ops/services/__init__.py:240: in _run_all
    return _run_all_rule_based(question, settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

question = 'srv-erp-01 CPU   7 '
settings = AppSettings(app_env='dev', api_port=8000, cors_origins='http://localhost:3000', log_level='debug', ops_mode='real', op...ection_enabled=True, csrf_trusted_origins='http://localhost:3000', hsts_max_age=31536000, hsts_include_subdomains=True)

    def _run_all_rule_based(question: str, settings: Any) -> tuple[list[AnswerBlock], list[str], str | None]:
        selected = _determine_all_executors(question)
        successful_blocks: dict[str, list[AnswerBlock]] = {}
        used_tools: list[str] = []
        errors: list[str] = []
        for name in selected:
            executor = _resolve_executor(name)
            try:
                executor_blocks, executor_tools = executor(question, settings)
                successful_blocks[name] = executor_blocks
                for tool in executor_tools:
                    if tool not in used_tools:
                        used_tools.append(tool)
            except Exception as exc:
                logging.exception("ALL executor %s failed", name)
                errors.append(f"{name}: {exc}")
        if not successful_blocks:
>           raise RuntimeError("ALL executors all failed" + (f": {'; '.join(errors)}" if errors else ""))
E           RuntimeError: ALL executors all failed: metric: too many values to unpack (expected 2); graph: too many values to unpack (expected 2)

app/modules/ops/services/__init__.py:265: RuntimeError
----------------------------- Captured stdout call -----------------------------
2026-01-22 17:58:15,537 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2026-01-22 17:58:15,538 INFO sqlalchemy.engine.Engine SELECT tb_asset_registry.asset_id, tb_asset_registry.asset_type, tb_asset_registry.name, tb_asset_registry.description, tb_asset_registry.version, tb_asset_registry.status, tb_asset_registry.scope, tb_asset_registry.engine, tb_asset_registry.template, tb_asset_registry.input_schema, tb_asset_registry.output_contract, tb_asset_registry.mapping_type, tb_asset_registry.content, tb_asset_registry.policy_type, tb_asset_registry.limits, tb_asset_registry.query_sql, tb_asset_registry.query_params, tb_asset_registry.query_metadata, tb_asset_registry.screen_id, tb_asset_registry.schema_json, tb_asset_registry.tags, tb_asset_registry.created_by, tb_asset_registry.published_by, tb_asset_registry.published_at, tb_asset_registry.created_at, tb_asset_registry.updated_at 
FROM tb_asset_registry 
WHERE tb_asset_registry.asset_type = %(asset_type_1)s::VARCHAR AND tb_asset_registry.scope = %(scope_1)s::VARCHAR AND tb_asset_registry.name = %(name_1)s::VARCHAR AND tb_asset_registry.status = %(status_1)s::VARCHAR
2026-01-22 17:58:15,538 INFO sqlalchemy.engine.Engine [cached since 3.248s ago] {'asset_type_1': 'query', 'scope_1': 'metric', 'name_1': 'metric_timeseries', 'status_1': 'published'}
2026-01-22 17:58:15,545 INFO sqlalchemy.engine.Engine ROLLBACK
2026-01-22 17:58:15,682 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2026-01-22 17:58:15,682 INFO sqlalchemy.engine.Engine SELECT tb_asset_registry.asset_id, tb_asset_registry.asset_type, tb_asset_registry.name, tb_asset_registry.description, tb_asset_registry.version, tb_asset_registry.status, tb_asset_registry.scope, tb_asset_registry.engine, tb_asset_registry.template, tb_asset_registry.input_schema, tb_asset_registry.output_contract, tb_asset_registry.mapping_type, tb_asset_registry.content, tb_asset_registry.policy_type, tb_asset_registry.limits, tb_asset_registry.query_sql, tb_asset_registry.query_params, tb_asset_registry.query_metadata, tb_asset_registry.screen_id, tb_asset_registry.schema_json, tb_asset_registry.tags, tb_asset_registry.created_by, tb_asset_registry.published_by, tb_asset_registry.published_at, tb_asset_registry.created_at, tb_asset_registry.updated_at 
FROM tb_asset_registry 
WHERE tb_asset_registry.asset_type = %(asset_type_1)s::VARCHAR AND tb_asset_registry.scope = %(scope_1)s::VARCHAR AND tb_asset_registry.name = %(name_1)s::VARCHAR AND tb_asset_registry.status = %(status_1)s::VARCHAR
2026-01-22 17:58:15,682 INFO sqlalchemy.engine.Engine [cached since 3.392s ago] {'asset_type_1': 'query', 'scope_1': 'metric', 'name_1': 'metric_resolver', 'status_1': 'published'}
2026-01-22 17:58:15,705 INFO sqlalchemy.engine.Engine ROLLBACK
2026-01-22 17:58:16,511 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2026-01-22 17:58:16,512 INFO sqlalchemy.engine.Engine SELECT tb_asset_registry.asset_id, tb_asset_registry.asset_type, tb_asset_registry.name, tb_asset_registry.description, tb_asset_registry.version, tb_asset_registry.status, tb_asset_registry.scope, tb_asset_registry.engine, tb_asset_registry.template, tb_asset_registry.input_schema, tb_asset_registry.output_contract, tb_asset_registry.mapping_type, tb_asset_registry.content, tb_asset_registry.policy_type, tb_asset_registry.limits, tb_asset_registry.query_sql, tb_asset_registry.query_params, tb_asset_registry.query_metadata, tb_asset_registry.screen_id, tb_asset_registry.schema_json, tb_asset_registry.tags, tb_asset_registry.created_by, tb_asset_registry.published_by, tb_asset_registry.published_at, tb_asset_registry.created_at, tb_asset_registry.updated_at 
FROM tb_asset_registry 
WHERE tb_asset_registry.asset_type = %(asset_type_1)s::VARCHAR AND tb_asset_registry.scope = %(scope_1)s::VARCHAR AND tb_asset_registry.name = %(name_1)s::VARCHAR AND tb_asset_registry.status = %(status_1)s::VARCHAR
2026-01-22 17:58:16,512 INFO sqlalchemy.engine.Engine [cached since 4.222s ago] {'asset_type_1': 'query', 'scope_1': 'graph', 'name_1': 'dependency_expand', 'status_1': 'published'}
2026-01-22 17:58:16,519 INFO sqlalchemy.engine.Engine ROLLBACK
2026-01-22 17:58:16,536 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2026-01-22 17:58:16,536 INFO sqlalchemy.engine.Engine SELECT tb_asset_registry.asset_id, tb_asset_registry.asset_type, tb_asset_registry.name, tb_asset_registry.description, tb_asset_registry.version, tb_asset_registry.status, tb_asset_registry.scope, tb_asset_registry.engine, tb_asset_registry.template, tb_asset_registry.input_schema, tb_asset_registry.output_contract, tb_asset_registry.mapping_type, tb_asset_registry.content, tb_asset_registry.policy_type, tb_asset_registry.limits, tb_asset_registry.query_sql, tb_asset_registry.query_params, tb_asset_registry.query_metadata, tb_asset_registry.screen_id, tb_asset_registry.schema_json, tb_asset_registry.tags, tb_asset_registry.created_by, tb_asset_registry.published_by, tb_asset_registry.published_at, tb_asset_registry.created_at, tb_asset_registry.updated_at 
FROM tb_asset_registry 
WHERE tb_asset_registry.asset_type = %(asset_type_1)s::VARCHAR AND tb_asset_registry.scope = %(scope_1)s::VARCHAR AND tb_asset_registry.name = %(name_1)s::VARCHAR AND tb_asset_registry.status = %(status_1)s::VARCHAR
2026-01-22 17:58:16,536 INFO sqlalchemy.engine.Engine [cached since 4.246s ago] {'asset_type_1': 'query', 'scope_1': 'graph', 'name_1': 'component_composition', 'status_1': 'published'}
2026-01-22 17:58:16,559 INFO sqlalchemy.engine.Engine ROLLBACK
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:58:15+0900 WARNING root request_id=- tenant_id=- trace_id=- mode=- LangGraph requested but OpenAI API key missing; using rule-based ALL executor taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- BEGIN (implicit) taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- SELECT tb_asset_registry.asset_id, tb_asset_registry.asset_type, tb_asset_registry.name, tb_asset_registry.description, tb_asset_registry.version, tb_asset_registry.status, tb_asset_registry.scope, tb_asset_registry.engine, tb_asset_registry.template, tb_asset_registry.input_schema, tb_asset_registry.output_contract, tb_asset_registry.mapping_type, tb_asset_registry.content, tb_asset_registry.policy_type, tb_asset_registry.limits, tb_asset_registry.query_sql, tb_asset_registry.query_params, tb_asset_registry.query_metadata, tb_asset_registry.screen_id, tb_asset_registry.schema_json, tb_asset_registry.tags, tb_asset_registry.created_by, tb_asset_registry.published_by, tb_asset_registry.published_at, tb_asset_registry.created_at, tb_asset_registry.updated_at 
FROM tb_asset_registry 
WHERE tb_asset_registry.asset_type = %(asset_type_1)s::VARCHAR AND tb_asset_registry.scope = %(scope_1)s::VARCHAR AND tb_asset_registry.name = %(name_1)s::VARCHAR AND tb_asset_registry.status = %(status_1)s::VARCHAR taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- [cached since 3.248s ago] {'asset_type_1': 'query', 'scope_1': 'metric', 'name_1': 'metric_timeseries', 'status_1': 'published'} taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- ROLLBACK taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 ERROR app.shared.config_loader request_id=- tenant_id=- trace_id=- mode=- Resource file not found: /home/spa/tobit-spa-ai/apps/api/resources/queries/metric/metric_timeseries.sql taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 WARNING app.modules.asset_registry.loader request_id=- tenant_id=- trace_id=- mode=- Query asset not found: metric_timeseries (scope=metric) taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- BEGIN (implicit) taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- SELECT tb_asset_registry.asset_id, tb_asset_registry.asset_type, tb_asset_registry.name, tb_asset_registry.description, tb_asset_registry.version, tb_asset_registry.status, tb_asset_registry.scope, tb_asset_registry.engine, tb_asset_registry.template, tb_asset_registry.input_schema, tb_asset_registry.output_contract, tb_asset_registry.mapping_type, tb_asset_registry.content, tb_asset_registry.policy_type, tb_asset_registry.limits, tb_asset_registry.query_sql, tb_asset_registry.query_params, tb_asset_registry.query_metadata, tb_asset_registry.screen_id, tb_asset_registry.schema_json, tb_asset_registry.tags, tb_asset_registry.created_by, tb_asset_registry.published_by, tb_asset_registry.published_at, tb_asset_registry.created_at, tb_asset_registry.updated_at 
FROM tb_asset_registry 
WHERE tb_asset_registry.asset_type = %(asset_type_1)s::VARCHAR AND tb_asset_registry.scope = %(scope_1)s::VARCHAR AND tb_asset_registry.name = %(name_1)s::VARCHAR AND tb_asset_registry.status = %(status_1)s::VARCHAR taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- [cached since 3.392s ago] {'asset_type_1': 'query', 'scope_1': 'metric', 'name_1': 'metric_resolver', 'status_1': 'published'} taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- ROLLBACK taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 ERROR app.shared.config_loader request_id=- tenant_id=- trace_id=- mode=- Resource file not found: /home/spa/tobit-spa-ai/apps/api/resources/queries/metric/metric_resolver.sql taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:15+0900 WARNING app.modules.asset_registry.loader request_id=- tenant_id=- trace_id=- mode=- Query asset not found: metric_resolver (scope=metric) taskName=None asctime=2026-01-22T17:58:15+0900
2026-01-22T17:58:16+0900 ERROR root request_id=- tenant_id=- trace_id=- mode=- ALL executor metric failed
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/__init__.py", line 256, in _run_all_rule_based
    executor_blocks, executor_tools = executor(question, settings)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: too many values to unpack (expected 2) taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- BEGIN (implicit) taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- SELECT tb_asset_registry.asset_id, tb_asset_registry.asset_type, tb_asset_registry.name, tb_asset_registry.description, tb_asset_registry.version, tb_asset_registry.status, tb_asset_registry.scope, tb_asset_registry.engine, tb_asset_registry.template, tb_asset_registry.input_schema, tb_asset_registry.output_contract, tb_asset_registry.mapping_type, tb_asset_registry.content, tb_asset_registry.policy_type, tb_asset_registry.limits, tb_asset_registry.query_sql, tb_asset_registry.query_params, tb_asset_registry.query_metadata, tb_asset_registry.screen_id, tb_asset_registry.schema_json, tb_asset_registry.tags, tb_asset_registry.created_by, tb_asset_registry.published_by, tb_asset_registry.published_at, tb_asset_registry.created_at, tb_asset_registry.updated_at 
FROM tb_asset_registry 
WHERE tb_asset_registry.asset_type = %(asset_type_1)s::VARCHAR AND tb_asset_registry.scope = %(scope_1)s::VARCHAR AND tb_asset_registry.name = %(name_1)s::VARCHAR AND tb_asset_registry.status = %(status_1)s::VARCHAR taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- [cached since 4.222s ago] {'asset_type_1': 'query', 'scope_1': 'graph', 'name_1': 'dependency_expand', 'status_1': 'published'} taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- ROLLBACK taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 ERROR app.shared.config_loader request_id=- tenant_id=- trace_id=- mode=- Resource file not found: /home/spa/tobit-spa-ai/apps/api/resources/queries/graph/dependency_expand.sql taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 WARNING app.modules.asset_registry.loader request_id=- tenant_id=- trace_id=- mode=- Query asset not found: dependency_expand (scope=graph) taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- BEGIN (implicit) taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- SELECT tb_asset_registry.asset_id, tb_asset_registry.asset_type, tb_asset_registry.name, tb_asset_registry.description, tb_asset_registry.version, tb_asset_registry.status, tb_asset_registry.scope, tb_asset_registry.engine, tb_asset_registry.template, tb_asset_registry.input_schema, tb_asset_registry.output_contract, tb_asset_registry.mapping_type, tb_asset_registry.content, tb_asset_registry.policy_type, tb_asset_registry.limits, tb_asset_registry.query_sql, tb_asset_registry.query_params, tb_asset_registry.query_metadata, tb_asset_registry.screen_id, tb_asset_registry.schema_json, tb_asset_registry.tags, tb_asset_registry.created_by, tb_asset_registry.published_by, tb_asset_registry.published_at, tb_asset_registry.created_at, tb_asset_registry.updated_at 
FROM tb_asset_registry 
WHERE tb_asset_registry.asset_type = %(asset_type_1)s::VARCHAR AND tb_asset_registry.scope = %(scope_1)s::VARCHAR AND tb_asset_registry.name = %(name_1)s::VARCHAR AND tb_asset_registry.status = %(status_1)s::VARCHAR taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- [cached since 4.246s ago] {'asset_type_1': 'query', 'scope_1': 'graph', 'name_1': 'component_composition', 'status_1': 'published'} taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- ROLLBACK taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 ERROR app.shared.config_loader request_id=- tenant_id=- trace_id=- mode=- Resource file not found: /home/spa/tobit-spa-ai/apps/api/resources/queries/graph/component_composition.sql taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 WARNING app.modules.asset_registry.loader request_id=- tenant_id=- trace_id=- mode=- Query asset not found: component_composition (scope=graph) taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.pool request_id=- tenant_id=- trace_id=- mode=- [#0000]  _: <POOL> created, direct address IPv4Address(('115.21.12.151', 7687)) taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j request_id=- tenant_id=- trace_id=- mode=- [#0000]  _: <WORKSPACE> routing towards fixed database: None taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j request_id=- tenant_id=- trace_id=- mode=- [#0000]  _: <WORKSPACE> pinning database: None taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.pool request_id=- tenant_id=- trace_id=- mode=- [#0000]  _: <POOL> acquire direct connection, access_mode='WRITE', database=AcquisitionDatabase(name=None, guessed=False) taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.pool request_id=- tenant_id=- trace_id=- mode=- [#0000]  _: <POOL> trying to hand out new connection taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#0000]  _: <RESOLVE> in: 115.21.12.151:7687 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#0000]  _: <RESOLVE> dns resolver out: 115.21.12.151:7687 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#0000]  C: <OPEN> 115.21.12.151:7687 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  C: <MAGIC> 0x6060B017 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  C: <HANDSHAKE> 0x000001FF 0x00080805 0x00020404 0x00000003 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: <HANDSHAKE> 0x00000003 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  C: HELLO {'user_agent': 'neo4j-python/6.1.0 Python/3.12.3-final-0 (linux)', 'scheme': 'basic', 'principal': 'neo4j', 'credentials': '*******'} taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  _: <CONNECTION> client state: CONNECTED > READY taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: SUCCESS {'server': 'Neo4j/3.5.35', 'connection_id': 'bolt-136'} taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  _: <CONNECTION> server state: CONNECTED > READY taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  C: RUN '\nMATCH (n:CI)\nWHERE n.tenant_id = $tenant_id AND n.ci_code = $ci_code\nMATCH path = (n)-[r*1..3]-(m:CI)\nWHERE m.tenant_id = $tenant_id\nRETURN n, relationships(path) AS r, m\nLIMIT 300\n' {'tenant_id': 't1', 'ci_code': 'srv-erp-01', 'depth': 3} {} taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  _: <CONNECTION> client state: READY > STREAMING taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  C: PULL_ALL taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: SUCCESS {'t_first': 1, 'fields': ['n', 'r', 'm']} taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  _: <CONNECTION> server state: READY > STREAMING taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: RECORD * 1 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  S: SUCCESS {'bookmark': 'neo4j:bookmark:v1:tx6070', 'type': 'r', 't_last': 14} taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  _: <CONNECTION> server state: STREAMING > READY taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.pool request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  _: <POOL> released bolt-136 taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.pool request_id=- tenant_id=- trace_id=- mode=- [#0000]  _: <POOL> close taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  C: GOODBYE taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG neo4j.io request_id=- tenant_id=- trace_id=- mode=- [#A0C6]  C: <CLOSE> taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 ERROR root request_id=- tenant_id=- trace_id=- mode=- ALL executor graph failed
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/__init__.py", line 256, in _run_all_rule_based
    executor_blocks, executor_tools = executor(question, settings)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: too many values to unpack (expected 2) taskName=None asctime=2026-01-22T17:58:16+0900
------------------------------ Captured log call -------------------------------
WARNING  root:__init__.py:239 LangGraph requested but OpenAI API key missing; using rule-based ALL executor
INFO     sqlalchemy.engine.Engine:base.py:2710 BEGIN (implicit)
INFO     sqlalchemy.engine.Engine:base.py:1846 SELECT tb_asset_registry.asset_id, tb_asset_registry.asset_type, tb_asset_registry.name, tb_asset_registry.description, tb_asset_registry.version, tb_asset_registry.status, tb_asset_registry.scope, tb_asset_registry.engine, tb_asset_registry.template, tb_asset_registry.input_schema, tb_asset_registry.output_contract, tb_asset_registry.mapping_type, tb_asset_registry.content, tb_asset_registry.policy_type, tb_asset_registry.limits, tb_asset_registry.query_sql, tb_asset_registry.query_params, tb_asset_registry.query_metadata, tb_asset_registry.screen_id, tb_asset_registry.schema_json, tb_asset_registry.tags, tb_asset_registry.created_by, tb_asset_registry.published_by, tb_asset_registry.published_at, tb_asset_registry.created_at, tb_asset_registry.updated_at 
FROM tb_asset_registry 
WHERE tb_asset_registry.asset_type = %(asset_type_1)s::VARCHAR AND tb_asset_registry.scope = %(scope_1)s::VARCHAR AND tb_asset_registry.name = %(name_1)s::VARCHAR AND tb_asset_registry.status = %(status_1)s::VARCHAR
INFO     sqlalchemy.engine.Engine:base.py:1846 [cached since 3.248s ago] {'asset_type_1': 'query', 'scope_1': 'metric', 'name_1': 'metric_timeseries', 'status_1': 'published'}
INFO     sqlalchemy.engine.Engine:base.py:2713 ROLLBACK
ERROR    app.shared.config_loader:config_loader.py:48 Resource file not found: /home/spa/tobit-spa-ai/apps/api/resources/queries/metric/metric_timeseries.sql
WARNING  app.modules.asset_registry.loader:loader.py:353 Query asset not found: metric_timeseries (scope=metric)
INFO     sqlalchemy.engine.Engine:base.py:2710 BEGIN (implicit)
INFO     sqlalchemy.engine.Engine:base.py:1846 SELECT tb_asset_registry.asset_id, tb_asset_registry.asset_type, tb_asset_registry.name, tb_asset_registry.description, tb_asset_registry.version, tb_asset_registry.status, tb_asset_registry.scope, tb_asset_registry.engine, tb_asset_registry.template, tb_asset_registry.input_schema, tb_asset_registry.output_contract, tb_asset_registry.mapping_type, tb_asset_registry.content, tb_asset_registry.policy_type, tb_asset_registry.limits, tb_asset_registry.query_sql, tb_asset_registry.query_params, tb_asset_registry.query_metadata, tb_asset_registry.screen_id, tb_asset_registry.schema_json, tb_asset_registry.tags, tb_asset_registry.created_by, tb_asset_registry.published_by, tb_asset_registry.published_at, tb_asset_registry.created_at, tb_asset_registry.updated_at 
FROM tb_asset_registry 
WHERE tb_asset_registry.asset_type = %(asset_type_1)s::VARCHAR AND tb_asset_registry.scope = %(scope_1)s::VARCHAR AND tb_asset_registry.name = %(name_1)s::VARCHAR AND tb_asset_registry.status = %(status_1)s::VARCHAR
INFO     sqlalchemy.engine.Engine:base.py:1846 [cached since 3.392s ago] {'asset_type_1': 'query', 'scope_1': 'metric', 'name_1': 'metric_resolver', 'status_1': 'published'}
INFO     sqlalchemy.engine.Engine:base.py:2713 ROLLBACK
ERROR    app.shared.config_loader:config_loader.py:48 Resource file not found: /home/spa/tobit-spa-ai/apps/api/resources/queries/metric/metric_resolver.sql
WARNING  app.modules.asset_registry.loader:loader.py:353 Query asset not found: metric_resolver (scope=metric)
ERROR    root:__init__.py:262 ALL executor metric failed
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/__init__.py", line 256, in _run_all_rule_based
    executor_blocks, executor_tools = executor(question, settings)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: too many values to unpack (expected 2)
INFO     sqlalchemy.engine.Engine:base.py:2710 BEGIN (implicit)
INFO     sqlalchemy.engine.Engine:base.py:1846 SELECT tb_asset_registry.asset_id, tb_asset_registry.asset_type, tb_asset_registry.name, tb_asset_registry.description, tb_asset_registry.version, tb_asset_registry.status, tb_asset_registry.scope, tb_asset_registry.engine, tb_asset_registry.template, tb_asset_registry.input_schema, tb_asset_registry.output_contract, tb_asset_registry.mapping_type, tb_asset_registry.content, tb_asset_registry.policy_type, tb_asset_registry.limits, tb_asset_registry.query_sql, tb_asset_registry.query_params, tb_asset_registry.query_metadata, tb_asset_registry.screen_id, tb_asset_registry.schema_json, tb_asset_registry.tags, tb_asset_registry.created_by, tb_asset_registry.published_by, tb_asset_registry.published_at, tb_asset_registry.created_at, tb_asset_registry.updated_at 
FROM tb_asset_registry 
WHERE tb_asset_registry.asset_type = %(asset_type_1)s::VARCHAR AND tb_asset_registry.scope = %(scope_1)s::VARCHAR AND tb_asset_registry.name = %(name_1)s::VARCHAR AND tb_asset_registry.status = %(status_1)s::VARCHAR
INFO     sqlalchemy.engine.Engine:base.py:1846 [cached since 4.222s ago] {'asset_type_1': 'query', 'scope_1': 'graph', 'name_1': 'dependency_expand', 'status_1': 'published'}
INFO     sqlalchemy.engine.Engine:base.py:2713 ROLLBACK
ERROR    app.shared.config_loader:config_loader.py:48 Resource file not found: /home/spa/tobit-spa-ai/apps/api/resources/queries/graph/dependency_expand.sql
WARNING  app.modules.asset_registry.loader:loader.py:353 Query asset not found: dependency_expand (scope=graph)
INFO     sqlalchemy.engine.Engine:base.py:2710 BEGIN (implicit)
INFO     sqlalchemy.engine.Engine:base.py:1846 SELECT tb_asset_registry.asset_id, tb_asset_registry.asset_type, tb_asset_registry.name, tb_asset_registry.description, tb_asset_registry.version, tb_asset_registry.status, tb_asset_registry.scope, tb_asset_registry.engine, tb_asset_registry.template, tb_asset_registry.input_schema, tb_asset_registry.output_contract, tb_asset_registry.mapping_type, tb_asset_registry.content, tb_asset_registry.policy_type, tb_asset_registry.limits, tb_asset_registry.query_sql, tb_asset_registry.query_params, tb_asset_registry.query_metadata, tb_asset_registry.screen_id, tb_asset_registry.schema_json, tb_asset_registry.tags, tb_asset_registry.created_by, tb_asset_registry.published_by, tb_asset_registry.published_at, tb_asset_registry.created_at, tb_asset_registry.updated_at 
FROM tb_asset_registry 
WHERE tb_asset_registry.asset_type = %(asset_type_1)s::VARCHAR AND tb_asset_registry.scope = %(scope_1)s::VARCHAR AND tb_asset_registry.name = %(name_1)s::VARCHAR AND tb_asset_registry.status = %(status_1)s::VARCHAR
INFO     sqlalchemy.engine.Engine:base.py:1846 [cached since 4.246s ago] {'asset_type_1': 'query', 'scope_1': 'graph', 'name_1': 'component_composition', 'status_1': 'published'}
INFO     sqlalchemy.engine.Engine:base.py:2713 ROLLBACK
ERROR    app.shared.config_loader:config_loader.py:48 Resource file not found: /home/spa/tobit-spa-ai/apps/api/resources/queries/graph/component_composition.sql
WARNING  app.modules.asset_registry.loader:loader.py:353 Query asset not found: component_composition (scope=graph)
DEBUG    neo4j.pool:_pool.py:647 [#0000]  _: <POOL> created, direct address IPv4Address(('115.21.12.151', 7687))
DEBUG    neo4j:workspace.py:215 [#0000]  _: <WORKSPACE> routing towards fixed database: None
DEBUG    neo4j:workspace.py:106 [#0000]  _: <WORKSPACE> pinning database: None
DEBUG    neo4j.pool:_pool.py:672 [#0000]  _: <POOL> acquire direct connection, access_mode='WRITE', database=AcquisitionDatabase(name=None, guessed=False)
DEBUG    neo4j.pool:_pool.py:417 [#0000]  _: <POOL> trying to hand out new connection
DEBUG    neo4j.io:_util.py:226 [#0000]  _: <RESOLVE> in: 115.21.12.151:7687
DEBUG    neo4j.io:_util.py:247 [#0000]  _: <RESOLVE> dns resolver out: 115.21.12.151:7687
DEBUG    neo4j.io:_bolt_socket.py:511 [#0000]  C: <OPEN> 115.21.12.151:7687
DEBUG    neo4j.io:_bolt_socket.py:240 [#A0C6]  C: <MAGIC> 0x6060B017
DEBUG    neo4j.io:_bolt_socket.py:245 [#A0C6]  C: <HANDSHAKE> 0x000001FF 0x00080805 0x00020404 0x00000003
DEBUG    neo4j.io:_bolt_socket.py:79 [#A0C6]  S: <HANDSHAKE> 0x00000003
DEBUG    neo4j.io:_bolt3.py:225 [#A0C6]  C: HELLO {'user_agent': 'neo4j-python/6.1.0 Python/3.12.3-final-0 (linux)', 'scheme': 'basic', 'principal': 'neo4j', 'credentials': '*******'}
DEBUG    neo4j.io:_bolt3.py:179 [#A0C6]  _: <CONNECTION> client state: CONNECTED > READY
DEBUG    neo4j.io:_bolt3.py:562 [#A0C6]  S: SUCCESS {'server': 'Neo4j/3.5.35', 'connection_id': 'bolt-136'}
DEBUG    neo4j.io:_bolt3.py:168 [#A0C6]  _: <CONNECTION> server state: CONNECTED > READY
DEBUG    neo4j.io:_bolt3.py:371 [#A0C6]  C: RUN '\nMATCH (n:CI)\nWHERE n.tenant_id = $tenant_id AND n.ci_code = $ci_code\nMATCH path = (n)-[r*1..3]-(m:CI)\nWHERE m.tenant_id = $tenant_id\nRETURN n, relationships(path) AS r, m\nLIMIT 300\n' {'tenant_id': 't1', 'ci_code': 'srv-erp-01', 'depth': 3} {}
DEBUG    neo4j.io:_bolt3.py:179 [#A0C6]  _: <CONNECTION> client state: READY > STREAMING
DEBUG    neo4j.io:_bolt3.py:413 [#A0C6]  C: PULL_ALL
DEBUG    neo4j.io:_bolt3.py:562 [#A0C6]  S: SUCCESS {'t_first': 1, 'fields': ['n', 'r', 'm']}
DEBUG    neo4j.io:_bolt3.py:168 [#A0C6]  _: <CONNECTION> server state: READY > STREAMING
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:553 [#A0C6]  S: RECORD * 1
DEBUG    neo4j.io:_bolt3.py:562 [#A0C6]  S: SUCCESS {'bookmark': 'neo4j:bookmark:v1:tx6070', 'type': 'r', 't_last': 14}
DEBUG    neo4j.io:_bolt3.py:168 [#A0C6]  _: <CONNECTION> server state: STREAMING > READY
DEBUG    neo4j.pool:_pool.py:515 [#A0C6]  _: <POOL> released bolt-136
DEBUG    neo4j.pool:_pool.py:608 [#0000]  _: <POOL> close
DEBUG    neo4j.io:_bolt3.py:531 [#A0C6]  C: GOODBYE
DEBUG    neo4j.io:_bolt.py:1006 [#A0C6]  C: <CLOSE>
ERROR    root:__init__.py:262 ALL executor graph failed
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/__init__.py", line 256, in _run_all_rule_based
    executor_blocks, executor_tools = executor(question, settings)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: too many values to unpack (expected 2)
_________________________ test_ops_all_partial_failure _________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7f4b8f242660>

    def test_ops_all_partial_failure(monkeypatch):
        monkeypatch.setenv("OPS_MODE", "real")
    
        now = datetime.now(timezone.utc)
        fake_ci = CIHit(
            ci_id="stub-id",
            ci_code="srv-erp-01",
            ci_name="ERP Server 01",
            ci_type="HW",
            ci_subtype="server",
            ci_category="business",
            score=1.0,
        )
        fake_range = TimeRange(start=now - timedelta(hours=1), end=now, bucket="5 minutes")
    
        def fake_metric(_question: str):
            return (
                [
                    MarkdownBlock(type="markdown", title="Metric stub", content="stub"),
                    ReferencesBlock(
                        type="references",
                        title="metric stub ref",
                        items=[
                            ReferenceItem(
                                kind="sql",
                                title="stub query",
                                payload={"sql": "SELECT 1", "params": []},
                            )
                        ],
                    ),
                ],
                ["timescale"],
            )
    
        def failing_hist(_question: str):
            raise RuntimeError("hist service unavailable")
    
        def stub_ci(_question: str):
            return [fake_ci]
    
        def stub_time_range(_question: str, _now: datetime, tz=None):
            return fake_range
    
        monkeypatch.setattr("app.modules.ops.services.run_metric", fake_metric)
        monkeypatch.setattr("app.modules.ops.services.run_hist", failing_hist)
        monkeypatch.setattr("app.modules.ops.services.resolve_ci", stub_ci)
        monkeypatch.setattr("app.modules.ops.services.resolve_time_range", stub_time_range)
    
        envelope = handle_ops_query("all", "stub question")
        assert envelope.meta.route == "all"
        assert not envelope.meta.fallback
>       assert envelope.meta.error and "hist service unavailable" in envelope.meta.error
E       assert ('Error code: 400 - {\'error\': {\'message\': "Unsupported parameter: \'temperature\' is not supported with this model.", \'type\': \'invalid_request_error\', \'param\': \'temperature\', \'code\': None}}' and 'hist service unavailable' in 'Error code: 400 - {\'error\': {\'message\': "Unsupported parameter: \'temperature\' is not supported with this model.", \'type\': \'invalid_request_error\', \'param\': \'temperature\', \'code\': None}}')
E        +  where 'Error code: 400 - {\'error\': {\'message\': "Unsupported parameter: \'temperature\' is not supported with this model.", \'type\': \'invalid_request_error\', \'param\': \'temperature\', \'code\': None}}' = AnswerMeta(route='all', route_reason='OPS real mode', timing_ms=214, summary='Real mode response for all', used_tools=['prompt'], fallback=False, error='Error code: 400 - {\'error\': {\'message\': "Unsupported parameter: \'temperature\' is not supported with this model.", \'type\': \'invalid_request_error\', \'param\': \'temperature\', \'code\': None}}', trace_id='a8198dfa31e74921bce725e7c6917625', parent_trace_id=None).error
E        +    where AnswerMeta(route='all', route_reason='OPS real mode', timing_ms=214, summary='Real mode response for all', used_tools=['prompt'], fallback=False, error='Error code: 400 - {\'error\': {\'message\': "Unsupported parameter: \'temperature\' is not supported with this model.", \'type\': \'invalid_request_error\', \'param\': \'temperature\', \'code\': None}}', trace_id='a8198dfa31e74921bce725e7c6917625', parent_trace_id=None) = AnswerEnvelope(meta=AnswerMeta(route='all', route_reason='OPS real mode', timing_ms=214, summary='Real mode response for all', used_tools=['prompt'], fallback=False, error='Error code: 400 - {\'error\': {\'message\': "Unsupported parameter: \'temperature\' is not supported with this model.", \'type\': \'invalid_request_error\', \'param\': \'temperature\', \'code\': None}}', trace_id='a8198dfa31e74921bce725e7c6917625', parent_trace_id=None), blocks=[MarkdownBlock(type='markdown', title='LangGraph plan error', content='    LLM     .', id=None)]).meta
E        +  and   'Error code: 400 - {\'error\': {\'message\': "Unsupported parameter: \'temperature\' is not supported with this model.", \'type\': \'invalid_request_error\', \'param\': \'temperature\', \'code\': None}}' = AnswerMeta(route='all', route_reason='OPS real mode', timing_ms=214, summary='Real mode response for all', used_tools=['prompt'], fallback=False, error='Error code: 400 - {\'error\': {\'message\': "Unsupported parameter: \'temperature\' is not supported with this model.", \'type\': \'invalid_request_error\', \'param\': \'temperature\', \'code\': None}}', trace_id='a8198dfa31e74921bce725e7c6917625', parent_trace_id=None).error
E        +    where AnswerMeta(route='all', route_reason='OPS real mode', timing_ms=214, summary='Real mode response for all', used_tools=['prompt'], fallback=False, error='Error code: 400 - {\'error\': {\'message\': "Unsupported parameter: \'temperature\' is not supported with this model.", \'type\': \'invalid_request_error\', \'param\': \'temperature\', \'code\': None}}', trace_id='a8198dfa31e74921bce725e7c6917625', parent_trace_id=None) = AnswerEnvelope(meta=AnswerMeta(route='all', route_reason='OPS real mode', timing_ms=214, summary='Real mode response for all', used_tools=['prompt'], fallback=False, error='Error code: 400 - {\'error\': {\'message\': "Unsupported parameter: \'temperature\' is not supported with this model.", \'type\': \'invalid_request_error\', \'param\': \'temperature\', \'code\': None}}', trace_id='a8198dfa31e74921bce725e7c6917625', parent_trace_id=None), blocks=[MarkdownBlock(type='markdown', title='LangGraph plan error', content='    LLM     .', id=None)]).meta

tests/test_ops_service.py:185: AssertionError
----------------------------- Captured stdout call -----------------------------
2026-01-22 17:58:17,065 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2026-01-22 17:58:17,066 INFO sqlalchemy.engine.Engine INSERT INTO tb_execution_trace (trace_id, parent_trace_id, feature, endpoint, method, ops_mode, question, status, duration_ms, request_payload, applied_assets, asset_versions, fallbacks, plan_raw, plan_validated, execution_steps, "references", answer, ui_render, audit_links, flow_spans, route, stage_inputs, stage_outputs, replan_events, created_at) VALUES (%(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(feature)s::VARCHAR, %(endpoint)s::VARCHAR, %(method)s::VARCHAR, %(ops_mode)s::VARCHAR, %(question)s::VARCHAR, %(status)s::VARCHAR, %(duration_ms)s::INTEGER, %(request_payload)s::JSON, %(applied_assets)s::JSON, %(asset_versions)s::JSON, %(fallbacks)s::JSON, %(plan_raw)s::JSON, %(plan_validated)s::JSON, %(execution_steps)s::JSON, %(references)s::JSON, %(answer)s::JSON, %(ui_render)s::JSON, %(audit_links)s::JSON, %(flow_spans)s::JSON, %(route)s::VARCHAR, %(stage_inputs)s::JSON, %(stage_outputs)s::JSON, %(replan_events)s::JSON, %(created_at)s::TIMESTAMP WITH TIME ZONE)
2026-01-22 17:58:17,066 INFO sqlalchemy.engine.Engine [cached since 4.63s ago] {'trace_id': 'a8198dfa31e74921bce725e7c6917625', 'parent_trace_id': None, 'feature': 'all', 'endpoint': '/ops/query', 'method': 'POST', 'ops_mode': 'real', 'question': 'stub question', 'status': 'error', 'duration_ms': 214, 'request_payload': Json({'question': 'stub question', 'mode ... (44 chars)), 'applied_assets': Json({'prompt': None, 'policy': None, 'm ... (79 chars)), 'asset_versions': Json(None), 'fallbacks': Json({'prompt': True, 'policy': True, 'm ... (65 chars)), 'plan_raw': Json(None), 'plan_validated': Json(None), 'execution_steps': Json([]), 'references': Json([]), 'answer': Json({'envelope_meta': {'route': 'all',  ... (592 chars)), 'ui_render': Json(None), 'audit_links': Json({'related_audit_log_ids': []}), 'flow_spans': Json(None), 'route': 'orch', 'stage_inputs': Json([]), 'stage_outputs': Json([]), 'replan_events': Json([]), 'created_at': datetime.datetime(2026, 1, 22, 8, 58, 17, 64186)}
2026-01-22 17:58:17,079 INFO sqlalchemy.engine.Engine ROLLBACK
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:58:16+0900 DEBUG root request_id=- tenant_id=- trace_id=- mode=- LLM create_response: model=gpt-5-nano, input=[{'role': 'system', 'content': 'You are a deterministic LangGraph planner/aggregator.\n'}, {'role':  taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- Request options: {'method': 'post', 'url': '/responses', 'files': None, 'idempotency_key': 'stainless-python-retry-2dd91263-688d-4fea-8c19-7b13c21d3f7f', 'json_data': {'input': [{'role': 'system', 'content': 'You are a deterministic LangGraph planner/aggregator.\n'}, {'role': 'user', 'content': 'You are orchestrating OPS queries. The question is:\nstub question\n\nReturn only JSON that follows this schema:\n{\n  "run_metric": bool,\n  "run_hist": bool,\n  "run_graph": bool,\n  "time_hint": str | null,\n  "metric_hint": str | null,\n  "ci_hint": str | null\n}\n\nChoose the minimum set of executors needed to answer the question.\nHint fields help suffix the question to narrow the scope.\nIf unsure prefer both metric and hist.\n'}], 'model': 'gpt-5-nano', 'stream': False, 'temperature': 0.1, 'tools': None}} taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- Sending HTTP Request: POST https://api.openai.com/v1/responses taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- send_request_headers.started request=<Request [b'POST']> taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- send_request_headers.complete taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- send_request_body.started request=<Request [b'POST']> taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- send_request_body.complete taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:16+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- receive_response_headers.started request=<Request [b'POST']> taskName=None asctime=2026-01-22T17:58:16+0900
2026-01-22T17:58:17+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 22 Jan 2026 08:58:18 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'191'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-kaavui2jbkapfiamtwmmzph7'), (b'openai-project', b'proj_qScKRtu1GYNIlwsdnYLEkSAp'), (b'x-request-id', b'req_8996a0f283f0479c8d452637ec5ac681'), (b'openai-processing-ms', b'30'), (b'x-envoy-upstream-service-time', b'32'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9c1dd9456a38e9fd-ICN'), (b'alt-svc', b'h3=":443"; ma=86400')]) taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 INFO httpx request_id=- tenant_id=- trace_id=- mode=- HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request" taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- receive_response_body.started request=<Request [b'POST']> taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- receive_response_body.complete taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- response_closed.started taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 DEBUG httpcore.http11 request_id=- tenant_id=- trace_id=- mode=- response_closed.complete taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- HTTP Response: POST https://api.openai.com/v1/responses "400 Bad Request" Headers({'date': 'Thu, 22 Jan 2026 08:58:18 GMT', 'content-type': 'application/json', 'content-length': '191', 'connection': 'keep-alive', 'openai-version': '2020-10-01', 'openai-organization': 'user-kaavui2jbkapfiamtwmmzph7', 'openai-project': 'proj_qScKRtu1GYNIlwsdnYLEkSAp', 'x-request-id': 'req_8996a0f283f0479c8d452637ec5ac681', 'openai-processing-ms': '30', 'x-envoy-upstream-service-time': '32', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9c1dd9456a38e9fd-ICN', 'alt-svc': 'h3=":443"; ma=86400'}) taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- request_id: req_8996a0f283f0479c8d452637ec5ac681 taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1027, in request
    response.raise_for_status()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/responses'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400 taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- Not retrying taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 DEBUG openai._base_client request_id=- tenant_id=- trace_id=- mode=- Re-raising status error taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 ERROR root request_id=- tenant_id=- trace_id=- mode=- LangGraph plan failed
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/langgraph.py", line 43, in run
    plan = self._plan(question)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/langgraph.py", line 92, in _plan
    response = self._call_llm(prompt, system_prompt)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/langgraph.py", line 160, in _call_llm
    response = self._llm.create_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/llm/client.py", line 33, in create_response
    return self.client.responses.create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/resources/responses/responses.py", line 866, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': None}} taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- BEGIN (implicit) taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- INSERT INTO tb_execution_trace (trace_id, parent_trace_id, feature, endpoint, method, ops_mode, question, status, duration_ms, request_payload, applied_assets, asset_versions, fallbacks, plan_raw, plan_validated, execution_steps, "references", answer, ui_render, audit_links, flow_spans, route, stage_inputs, stage_outputs, replan_events, created_at) VALUES (%(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(feature)s::VARCHAR, %(endpoint)s::VARCHAR, %(method)s::VARCHAR, %(ops_mode)s::VARCHAR, %(question)s::VARCHAR, %(status)s::VARCHAR, %(duration_ms)s::INTEGER, %(request_payload)s::JSON, %(applied_assets)s::JSON, %(asset_versions)s::JSON, %(fallbacks)s::JSON, %(plan_raw)s::JSON, %(plan_validated)s::JSON, %(execution_steps)s::JSON, %(references)s::JSON, %(answer)s::JSON, %(ui_render)s::JSON, %(audit_links)s::JSON, %(flow_spans)s::JSON, %(route)s::VARCHAR, %(stage_inputs)s::JSON, %(stage_outputs)s::JSON, %(replan_events)s::JSON, %(created_at)s::TIMESTAMP WITH TIME ZONE) taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- [cached since 4.63s ago] {'trace_id': 'a8198dfa31e74921bce725e7c6917625', 'parent_trace_id': None, 'feature': 'all', 'endpoint': '/ops/query', 'method': 'POST', 'ops_mode': 'real', 'question': 'stub question', 'status': 'error', 'duration_ms': 214, 'request_payload': Json({'question': 'stub question', 'mode ... (44 chars)), 'applied_assets': Json({'prompt': None, 'policy': None, 'm ... (79 chars)), 'asset_versions': Json(None), 'fallbacks': Json({'prompt': True, 'policy': True, 'm ... (65 chars)), 'plan_raw': Json(None), 'plan_validated': Json(None), 'execution_steps': Json([]), 'references': Json([]), 'answer': Json({'envelope_meta': {'route': 'all',  ... (592 chars)), 'ui_render': Json(None), 'audit_links': Json({'related_audit_log_ids': []}), 'flow_spans': Json(None), 'route': 'orch', 'stage_inputs': Json([]), 'stage_outputs': Json([]), 'replan_events': Json([]), 'created_at': datetime.datetime(2026, 1, 22, 8, 58, 17, 64186)} taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 INFO sqlalchemy.engine.Engine request_id=- tenant_id=- trace_id=- mode=- ROLLBACK taskName=None asctime=2026-01-22T17:58:17+0900
2026-01-22T17:58:17+0900 ERROR root request_id=- tenant_id=- trace_id=- mode=- ops.trace.persist_failed
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/psycopg/cursor.py", line 117, in execute
    raise ex.with_traceback(None)
psycopg.errors.UndefinedColumn: "route"  "tb_execution_trace" (relation) 
LINE 1: ...ces", answer, ui_render, audit_links, flow_spans, route, sta...
                                                             ^

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/__init__.py", line 145, in handle_ops_query
    persist_execution_trace(
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/inspector/service.py", line 208, in persist_execution_trace
    return create_execution_trace(session, trace_entry)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/inspector/crud.py", line 20, in create_execution_trace
    session.commit()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2030, in commit
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1311, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1286, in _prepare_impl
    self.session.flush()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4331, in flush
    self._flush(objects)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4466, in _flush
    with util.safe_reraise():
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4427, in _flush
    flush_context.execute()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1048, in _emit_insert_statements
    result = connection.execute(
             ^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/psycopg/cursor.py", line 117, in execute
    raise ex.with_traceback(None)
sqlalchemy.exc.ProgrammingError: (psycopg.errors.UndefinedColumn) "route"  "tb_execution_trace" (relation) 
LINE 1: ...ces", answer, ui_render, audit_links, flow_spans, route, sta...
                                                             ^
[SQL: INSERT INTO tb_execution_trace (trace_id, parent_trace_id, feature, endpoint, method, ops_mode, question, status, duration_ms, request_payload, applied_assets, asset_versions, fallbacks, plan_raw, plan_validated, execution_steps, "references", answer, ui_render, audit_links, flow_spans, route, stage_inputs, stage_outputs, replan_events, created_at) VALUES (%(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(feature)s::VARCHAR, %(endpoint)s::VARCHAR, %(method)s::VARCHAR, %(ops_mode)s::VARCHAR, %(question)s::VARCHAR, %(status)s::VARCHAR, %(duration_ms)s::INTEGER, %(request_payload)s::JSON, %(applied_assets)s::JSON, %(asset_versions)s::JSON, %(fallbacks)s::JSON, %(plan_raw)s::JSON, %(plan_validated)s::JSON, %(execution_steps)s::JSON, %(references)s::JSON, %(answer)s::JSON, %(ui_render)s::JSON, %(audit_links)s::JSON, %(flow_spans)s::JSON, %(route)s::VARCHAR, %(stage_inputs)s::JSON, %(stage_outputs)s::JSON, %(replan_events)s::JSON, %(created_at)s::TIMESTAMP WITH TIME ZONE)]
[parameters: {'trace_id': 'a8198dfa31e74921bce725e7c6917625', 'parent_trace_id': None, 'feature': 'all', 'endpoint': '/ops/query', 'method': 'POST', 'ops_mode': 'real', 'question': 'stub question', 'status': 'error', 'duration_ms': 214, 'request_payload': Json({'question': 'stub question', 'mode ... (44 chars)), 'applied_assets': Json({'prompt': None, 'policy': None, 'm ... (79 chars)), 'asset_versions': Json(None), 'fallbacks': Json({'prompt': True, 'policy': True, 'm ... (65 chars)), 'plan_raw': Json(None), 'plan_validated': Json(None), 'execution_steps': Json([]), 'references': Json([]), 'answer': Json({'envelope_meta': {'route': 'all',  ... (592 chars)), 'ui_render': Json(None), 'audit_links': Json({'related_audit_log_ids': []}), 'flow_spans': Json(None), 'route': 'orch', 'stage_inputs': Json([]), 'stage_outputs': Json([]), 'replan_events': Json([]), 'created_at': datetime.datetime(2026, 1, 22, 8, 58, 17, 64186)}]
(Background on this error at: https://sqlalche.me/e/20/f405) taskName=None asctime=2026-01-22T17:58:17+0900
------------------------------ Captured log call -------------------------------
DEBUG    root:client.py:32 LLM create_response: model=gpt-5-nano, input=[{'role': 'system', 'content': 'You are a deterministic LangGraph planner/aggregator.\n'}, {'role': 
DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/responses', 'files': None, 'idempotency_key': 'stainless-python-retry-2dd91263-688d-4fea-8c19-7b13c21d3f7f', 'json_data': {'input': [{'role': 'system', 'content': 'You are a deterministic LangGraph planner/aggregator.\n'}, {'role': 'user', 'content': 'You are orchestrating OPS queries. The question is:\nstub question\n\nReturn only JSON that follows this schema:\n{\n  "run_metric": bool,\n  "run_hist": bool,\n  "run_graph": bool,\n  "time_hint": str | null,\n  "metric_hint": str | null,\n  "ci_hint": str | null\n}\n\nChoose the minimum set of executors needed to answer the question.\nHint fields help suffix the question to narrow the scope.\nIf unsure prefer both metric and hist.\n'}], 'model': 'gpt-5-nano', 'stream': False, 'temperature': 0.1, 'tools': None}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://api.openai.com/v1/responses
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Thu, 22 Jan 2026 08:58:18 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'191'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-kaavui2jbkapfiamtwmmzph7'), (b'openai-project', b'proj_qScKRtu1GYNIlwsdnYLEkSAp'), (b'x-request-id', b'req_8996a0f283f0479c8d452637ec5ac681'), (b'openai-processing-ms', b'30'), (b'x-envoy-upstream-service-time', b'32'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9c1dd9456a38e9fd-ICN'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://api.openai.com/v1/responses "400 Bad Request" Headers({'date': 'Thu, 22 Jan 2026 08:58:18 GMT', 'content-type': 'application/json', 'content-length': '191', 'connection': 'keep-alive', 'openai-version': '2020-10-01', 'openai-organization': 'user-kaavui2jbkapfiamtwmmzph7', 'openai-project': 'proj_qScKRtu1GYNIlwsdnYLEkSAp', 'x-request-id': 'req_8996a0f283f0479c8d452637ec5ac681', 'openai-processing-ms': '30', 'x-envoy-upstream-service-time': '32', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9c1dd9456a38e9fd-ICN', 'alt-svc': 'h3=":443"; ma=86400'})
DEBUG    openai._base_client:_base_client.py:1024 request_id: req_8996a0f283f0479c8d452637ec5ac681
DEBUG    openai._base_client:_base_client.py:1029 Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1027, in request
    response.raise_for_status()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/responses'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
DEBUG    openai._base_client:_base_client.py:782 Not retrying
DEBUG    openai._base_client:_base_client.py:1046 Re-raising status error
ERROR    root:langgraph.py:45 LangGraph plan failed
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/langgraph.py", line 43, in run
    plan = self._plan(question)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/langgraph.py", line 92, in _plan
    response = self._call_llm(prompt, system_prompt)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/langgraph.py", line 160, in _call_llm
    response = self._llm.create_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/llm/client.py", line 33, in create_response
    return self.client.responses.create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/resources/responses/responses.py", line 866, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': None}}
INFO     sqlalchemy.engine.Engine:base.py:2710 BEGIN (implicit)
INFO     sqlalchemy.engine.Engine:base.py:1846 INSERT INTO tb_execution_trace (trace_id, parent_trace_id, feature, endpoint, method, ops_mode, question, status, duration_ms, request_payload, applied_assets, asset_versions, fallbacks, plan_raw, plan_validated, execution_steps, "references", answer, ui_render, audit_links, flow_spans, route, stage_inputs, stage_outputs, replan_events, created_at) VALUES (%(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(feature)s::VARCHAR, %(endpoint)s::VARCHAR, %(method)s::VARCHAR, %(ops_mode)s::VARCHAR, %(question)s::VARCHAR, %(status)s::VARCHAR, %(duration_ms)s::INTEGER, %(request_payload)s::JSON, %(applied_assets)s::JSON, %(asset_versions)s::JSON, %(fallbacks)s::JSON, %(plan_raw)s::JSON, %(plan_validated)s::JSON, %(execution_steps)s::JSON, %(references)s::JSON, %(answer)s::JSON, %(ui_render)s::JSON, %(audit_links)s::JSON, %(flow_spans)s::JSON, %(route)s::VARCHAR, %(stage_inputs)s::JSON, %(stage_outputs)s::JSON, %(replan_events)s::JSON, %(created_at)s::TIMESTAMP WITH TIME ZONE)
INFO     sqlalchemy.engine.Engine:base.py:1846 [cached since 4.63s ago] {'trace_id': 'a8198dfa31e74921bce725e7c6917625', 'parent_trace_id': None, 'feature': 'all', 'endpoint': '/ops/query', 'method': 'POST', 'ops_mode': 'real', 'question': 'stub question', 'status': 'error', 'duration_ms': 214, 'request_payload': Json({'question': 'stub question', 'mode ... (44 chars)), 'applied_assets': Json({'prompt': None, 'policy': None, 'm ... (79 chars)), 'asset_versions': Json(None), 'fallbacks': Json({'prompt': True, 'policy': True, 'm ... (65 chars)), 'plan_raw': Json(None), 'plan_validated': Json(None), 'execution_steps': Json([]), 'references': Json([]), 'answer': Json({'envelope_meta': {'route': 'all',  ... (592 chars)), 'ui_render': Json(None), 'audit_links': Json({'related_audit_log_ids': []}), 'flow_spans': Json(None), 'route': 'orch', 'stage_inputs': Json([]), 'stage_outputs': Json([]), 'replan_events': Json([]), 'created_at': datetime.datetime(2026, 1, 22, 8, 58, 17, 64186)}
INFO     sqlalchemy.engine.Engine:base.py:2713 ROLLBACK
ERROR    root:__init__.py:164 ops.trace.persist_failed
Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/psycopg/cursor.py", line 117, in execute
    raise ex.with_traceback(None)
psycopg.errors.UndefinedColumn: "route"  "tb_execution_trace" (relation) 
LINE 1: ...ces", answer, ui_render, audit_links, flow_spans, route, sta...
                                                             ^

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/__init__.py", line 145, in handle_ops_query
    persist_execution_trace(
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/inspector/service.py", line 208, in persist_execution_trace
    return create_execution_trace(session, trace_entry)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/app/modules/inspector/crud.py", line 20, in create_execution_trace
    session.commit()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 2030, in commit
    trans.commit(_to_root=True)
  File "<string>", line 2, in commit
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1311, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
                ^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1286, in _prepare_impl
    self.session.flush()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4331, in flush
    self._flush(objects)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4466, in _flush
    with util.safe_reraise():
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 4427, in _flush
    flush_context.execute()
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 466, in execute
    rec.execute(self)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/orm/persistence.py", line 1048, in _emit_insert_statements
    result = connection.execute(
             ^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1419, in execute
    return meth(
           ^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 527, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2363, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 952, in do_execute
    cursor.execute(statement, parameters)
  File "/home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/psycopg/cursor.py", line 117, in execute
    raise ex.with_traceback(None)
sqlalchemy.exc.ProgrammingError: (psycopg.errors.UndefinedColumn) "route"  "tb_execution_trace" (relation) 
LINE 1: ...ces", answer, ui_render, audit_links, flow_spans, route, sta...
                                                             ^
[SQL: INSERT INTO tb_execution_trace (trace_id, parent_trace_id, feature, endpoint, method, ops_mode, question, status, duration_ms, request_payload, applied_assets, asset_versions, fallbacks, plan_raw, plan_validated, execution_steps, "references", answer, ui_render, audit_links, flow_spans, route, stage_inputs, stage_outputs, replan_events, created_at) VALUES (%(trace_id)s::VARCHAR, %(parent_trace_id)s::VARCHAR, %(feature)s::VARCHAR, %(endpoint)s::VARCHAR, %(method)s::VARCHAR, %(ops_mode)s::VARCHAR, %(question)s::VARCHAR, %(status)s::VARCHAR, %(duration_ms)s::INTEGER, %(request_payload)s::JSON, %(applied_assets)s::JSON, %(asset_versions)s::JSON, %(fallbacks)s::JSON, %(plan_raw)s::JSON, %(plan_validated)s::JSON, %(execution_steps)s::JSON, %(references)s::JSON, %(answer)s::JSON, %(ui_render)s::JSON, %(audit_links)s::JSON, %(flow_spans)s::JSON, %(route)s::VARCHAR, %(stage_inputs)s::JSON, %(stage_outputs)s::JSON, %(replan_events)s::JSON, %(created_at)s::TIMESTAMP WITH TIME ZONE)]
[parameters: {'trace_id': 'a8198dfa31e74921bce725e7c6917625', 'parent_trace_id': None, 'feature': 'all', 'endpoint': '/ops/query', 'method': 'POST', 'ops_mode': 'real', 'question': 'stub question', 'status': 'error', 'duration_ms': 214, 'request_payload': Json({'question': 'stub question', 'mode ... (44 chars)), 'applied_assets': Json({'prompt': None, 'policy': None, 'm ... (79 chars)), 'asset_versions': Json(None), 'fallbacks': Json({'prompt': True, 'policy': True, 'm ... (65 chars)), 'plan_raw': Json(None), 'plan_validated': Json(None), 'execution_steps': Json([]), 'references': Json([]), 'answer': Json({'envelope_meta': {'route': 'all',  ... (592 chars)), 'ui_render': Json(None), 'audit_links': Json({'related_audit_log_ids': []}), 'flow_spans': Json(None), 'route': 'orch', 'stage_inputs': Json([]), 'stage_outputs': Json([]), 'replan_events': Json([]), 'created_at': datetime.datetime(2026, 1, 22, 8, 58, 17, 64186)}]
(Background on this error at: https://sqlalche.me/e/20/f405)
_________________ TestRolePermissions.test_manager_permissions _________________

self = <test_permissions.TestRolePermissions object at 0x7f4b91223ad0>

    def developer_user(session: Session) -> TbUser:
        """Create a developer user."""
        user = TbUser(
            id="dev-001",
>           email="dev@example.com",
            username="Developer",
            password_hash=get_password_hash("dev123"),
            role=UserRole.DEVELOPER,
            tenant_id="t1",
            is_active=True,
        )
E       AssertionError: assert <ResourcePermission.API_DELETE: 'api:delete'> in [<ResourcePermission.API_READ: 'api:read'>, <ResourcePermission.API_CREATE: 'api:create'>, <ResourcePermission.API_UPDATE: 'api:update'>, <ResourcePermission.API_EXECUTE: 'api:execute'>, <ResourcePermission.API_EXPORT: 'api:export'>, <ResourcePermission.CI_READ: 'ci:read'>, ...]
E        +  where <ResourcePermission.API_DELETE: 'api:delete'> = ResourcePermission.API_DELETE

tests/test_permissions.py:132: AssertionError
______________ TestScreenEditorAuth.test_save_draft_requires_auth ______________

self = <test_screen_editor_auth.TestScreenEditorAuth object at 0x7f4b912780b0>
client = <starlette.testclient.TestClient object at 0x7f4b8f263830>

    def test_save_draft_requires_auth(self, client):
        """Test that save draft endpoint requires authentication."""
        # Try to POST without token
        response = client.post(
            "/asset-registry/assets",
            json={
                "asset_type": "screen",
                "screen_id": "test-screen",
                "name": "Test Screen",
                "description": "Test",
                "schema_json": {
                    "screen_id": "test-screen",
                    "layout": {"type": "dashboard"},
                    "components": [],
                    "state": {"initial": {}},
                },
            }
        )
    
        # Should return 401 Unauthorized
>       assert response.status_code == 401
E       assert 500 == 401
E        +  where 500 = <Response [500 Internal Server Error]>.status_code

tests/test_screen_editor_auth.py:72: AssertionError
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:58:22+0900 DEBUG asyncio request_id=- tenant_id=- trace_id=- mode=- Using selector: EpollSelector taskName=None asctime=2026-01-22T17:58:22+0900
2026-01-22T17:58:22+0900 INFO httpx request_id=- tenant_id=- trace_id=- mode=- HTTP Request: POST http://testserver/asset-registry/assets "HTTP/1.1 500 Internal Server Error" taskName=None asctime=2026-01-22T17:58:22+0900
------------------------------ Captured log call -------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
INFO     httpx:_client.py:1025 HTTP Request: POST http://testserver/asset-registry/assets "HTTP/1.1 500 Internal Server Error"
_______________ TestScreenEditorAuth.test_invalid_token_rejected _______________

self = <test_screen_editor_auth.TestScreenEditorAuth object at 0x7f4b9127af30>
client = <starlette.testclient.TestClient object at 0x7f4b8f11dc40>

    def test_invalid_token_rejected(self, client):
        """Test that invalid token is rejected."""
        response = client.post(
            "/asset-registry/assets",
            json={
                "asset_type": "screen",
                "screen_id": "test-screen",
                "name": "Test Screen",
                "description": "Test",
                "schema_json": {
                    "screen_id": "test-screen",
                    "layout": {"type": "dashboard"},
                    "components": [],
                    "state": {"initial": {}},
                },
            },
            headers={"Authorization": "Bearer invalid.token.here"},
        )
    
        # Should return 401
>       assert response.status_code == 401
E       assert 500 == 401
E        +  where 500 = <Response [500 Internal Server Error]>.status_code

tests/test_screen_editor_auth.py:117: AssertionError
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:58:22+0900 DEBUG asyncio request_id=- tenant_id=- trace_id=- mode=- Using selector: EpollSelector taskName=None asctime=2026-01-22T17:58:22+0900
2026-01-22T17:58:23+0900 INFO httpx request_id=- tenant_id=- trace_id=- mode=- HTTP Request: POST http://testserver/asset-registry/assets "HTTP/1.1 500 Internal Server Error" taskName=None asctime=2026-01-22T17:58:23+0900
------------------------------ Captured log call -------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
INFO     httpx:_client.py:1025 HTTP Request: POST http://testserver/asset-registry/assets "HTTP/1.1 500 Internal Server Error"
_________ TestScreenEditorAuth.test_missing_authorization_header_error _________

self = <test_screen_editor_auth.TestScreenEditorAuth object at 0x7f4b9127b260>
client = <starlette.testclient.TestClient object at 0x7f4b9127aff0>

    def test_missing_authorization_header_error(self, client):
        """Test that missing auth header returns proper error message."""
        response = client.post(
            "/asset-registry/assets",
            json={
                "asset_type": "screen",
                "screen_id": "test-screen",
                "name": "Test Screen",
                "description": "Test",
                "schema_json": {
                    "screen_id": "test-screen",
                    "layout": {"type": "dashboard"},
                    "components": [],
                    "state": {"initial": {}},
                },
            }
        )
    
        # Should return 401 with "Missing authorization header"
>       assert response.status_code == 401
E       assert 500 == 401
E        +  where 500 = <Response [500 Internal Server Error]>.status_code

tests/test_screen_editor_auth.py:138: AssertionError
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:58:24+0900 DEBUG asyncio request_id=- tenant_id=- trace_id=- mode=- Using selector: EpollSelector taskName=None asctime=2026-01-22T17:58:24+0900
2026-01-22T17:58:24+0900 INFO httpx request_id=- tenant_id=- trace_id=- mode=- HTTP Request: POST http://testserver/asset-registry/assets "HTTP/1.1 500 Internal Server Error" taskName=None asctime=2026-01-22T17:58:24+0900
------------------------------ Captured log call -------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
INFO     httpx:_client.py:1025 HTTP Request: POST http://testserver/asset-registry/assets "HTTP/1.1 500 Internal Server Error"
_______________ test_list_maintenance_filtered_with_state_patch ________________

mock_session = <MagicMock id='139962499591936'>

    @pytest.mark.asyncio
    async def test_list_maintenance_filtered_with_state_patch(mock_session):
        """
        Test Case A: Read-only list action with state_patch
    
        Demonstrates:
        - Action execution returns state_patch
        - State patch contains maintenance_list and pagination info
        - Trace can be recorded with applied_assets
        """
        from app.modules.ops.services.action_registry import (
            handle_list_maintenance_filtered,
        )
    
        inputs = {
            "device_id": "",
            "offset": 0,
            "limit": 20,
        }
    
        context = {
            "tenant_id": "t1",
            "mode": "real",
        }
    
        # Mock external dependencies
>       with patch('app.modules.ops.services.action_registry.get_pg_connection') as mock_pg_func, \
             patch('app.modules.ops.services.action_registry.load_text') as mock_load, \
             patch('app.modules.ops.services.action_registry.get_settings'):

tests/test_ui_actions_with_traces.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f4b8f11d310>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'app.modules.ops.services.action_registry' from '/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/action_registry.py'> does not have the attribute 'get_pg_connection'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
---------------------------- Captured stderr setup -----------------------------
2026-01-22T17:58:26+0900 DEBUG asyncio request_id=- tenant_id=- trace_id=- mode=- Using selector: EpollSelector taskName=None asctime=2026-01-22T17:58:26+0900
------------------------------ Captured log setup ------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
----------------------------- Captured stderr call -----------------------------
2026-01-22T17:58:26+0900 INFO ActionRegistry request_id=- tenant_id=- trace_id=- mode=- Registered action handler: fetch_device_detail taskName=Task-796 asctime=2026-01-22T17:58:26+0900
2026-01-22T17:58:26+0900 INFO ActionRegistry request_id=- tenant_id=- trace_id=- mode=- Registered action handler: list_maintenance_filtered taskName=Task-796 asctime=2026-01-22T17:58:26+0900
2026-01-22T17:58:26+0900 INFO ActionRegistry request_id=- tenant_id=- trace_id=- mode=- Registered action handler: create_maintenance_ticket taskName=Task-796 asctime=2026-01-22T17:58:26+0900
2026-01-22T17:58:26+0900 INFO ActionRegistry request_id=- tenant_id=- trace_id=- mode=- Registered action handler: open_maintenance_modal taskName=Task-796 asctime=2026-01-22T17:58:26+0900
2026-01-22T17:58:26+0900 INFO ActionRegistry request_id=- tenant_id=- trace_id=- mode=- Registered action handler: close_maintenance_modal taskName=Task-796 asctime=2026-01-22T17:58:26+0900
------------------------------ Captured log call -------------------------------
INFO     ActionRegistry:action_registry.py:51 Registered action handler: fetch_device_detail
INFO     ActionRegistry:action_registry.py:51 Registered action handler: list_maintenance_filtered
INFO     ActionRegistry:action_registry.py:51 Registered action handler: create_maintenance_ticket
INFO     ActionRegistry:action_registry.py:51 Registered action handler: open_maintenance_modal
INFO     ActionRegistry:action_registry.py:51 Registered action handler: close_maintenance_modal
_______________ test_create_maintenance_ticket_with_state_patch ________________

mock_session = <MagicMock id='139962499593856'>

    @pytest.mark.asyncio
    async def test_create_maintenance_ticket_with_state_patch(mock_session):
        """
        Test Case B: CRUD create action with state_patch and parent_trace linking
    
        Demonstrates:
        - Create action generates state_patch for UI update
        - State patch includes newly created ticket and modal state
        - Trace includes parent_trace_id for hierarchy
        """
        from app.modules.ops.services.action_registry import (
            handle_create_maintenance_ticket,
        )
    
        # Simulate parent trace from a previous screen render
        parent_trace_id = f"screen-render-{datetime.utcnow().timestamp()}"
    
        inputs = {
            "device_id": "DEVICE-001",
            "maintenance_type": "Preventive",
            "scheduled_date": "2024-02-01",
            "assigned_to": "Engineer-A",
        }
    
        context = {
            "tenant_id": "t1",
            "mode": "real",
        }
    
>       with patch('app.modules.ops.services.action_registry.get_pg_connection') as mock_pg_func, \
             patch('app.modules.ops.services.action_registry.get_settings'):

tests/test_ui_actions_with_traces.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/unittest/mock.py:1458: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f4b8d9095b0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'app.modules.ops.services.action_registry' from '/home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/action_registry.py'> does not have the attribute 'get_pg_connection'

/usr/lib/python3.12/unittest/mock.py:1431: AttributeError
---------------------------- Captured stderr setup -----------------------------
2026-01-22T17:58:26+0900 DEBUG asyncio request_id=- tenant_id=- trace_id=- mode=- Using selector: EpollSelector taskName=None asctime=2026-01-22T17:58:26+0900
------------------------------ Captured log setup ------------------------------
DEBUG    asyncio:selector_events.py:64 Using selector: EpollSelector
=============================== warnings summary ===============================
.venv/lib/python3.12/site-packages/passlib/utils/__init__.py:854
  /home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/passlib/utils/__init__.py:854: DeprecationWarning: 'crypt' is deprecated and slated for removal in Python 3.13
    from crypt import crypt as _crypt

schemas/api_manager.py:41
schemas/api_manager.py:41
  /home/spa/tobit-spa-ai/apps/api/schemas/api_manager.py:41: PydanticDeprecatedSince212: Using `@model_validator` with mode='after' on a classmethod is deprecated. Instead, use an instance method. See the documentation at https://docs.pydantic.dev/2.12/concepts/validators/#model-after-validator. Deprecated in Pydantic V2.12 to be removed in V3.0.
    @model_validator(mode="after")

.venv/lib/python3.12/site-packages/sqlmodel/main.py:534
.venv/lib/python3.12/site-packages/sqlmodel/main.py:534
.venv/lib/python3.12/site-packages/sqlmodel/main.py:534
  /home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/main.py:534: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    new_cls = super().__new__(cls, name, bases, dict_used, **config_kwargs)

app/modules/cep_builder/schemas.py:18
  /home/spa/tobit-spa-ai/apps/api/app/modules/cep_builder/schemas.py:18: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("trigger_spec", "action_spec", pre=True, always=True)

app/modules/cep_builder/schemas.py:39
  /home/spa/tobit-spa-ai/apps/api/app/modules/cep_builder/schemas.py:39: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("trigger_spec", "action_spec", pre=True, always=True)

app/modules/cep_builder/schemas.py:55
  /home/spa/tobit-spa-ai/apps/api/app/modules/cep_builder/schemas.py:55: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("rule_id", pre=True, always=True)

app/modules/cep_builder/schemas.py:95
  /home/spa/tobit-spa-ai/apps/api/app/modules/cep_builder/schemas.py:95: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("exec_id", "rule_id", pre=True, always=True)

app/modules/cep_builder/schemas.py:112
  /home/spa/tobit-spa-ai/apps/api/app/modules/cep_builder/schemas.py:112: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("headers", "trigger", "policy", pre=True, always=True)

app/modules/cep_builder/schemas.py:134
  /home/spa/tobit-spa-ai/apps/api/app/modules/cep_builder/schemas.py:134: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("headers", "trigger", "policy", pre=True, always=True)

app/modules/cep_builder/schemas.py:150
  /home/spa/tobit-spa-ai/apps/api/app/modules/cep_builder/schemas.py:150: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("notification_id", pre=True, always=True)

app/modules/cep_builder/schemas.py:173
  /home/spa/tobit-spa-ai/apps/api/app/modules/cep_builder/schemas.py:173: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("log_id", "notification_id", pre=True, always=True)

app/modules/api_manager/schemas.py:48
  /home/spa/tobit-spa-ai/apps/api/app/modules/api_manager/schemas.py:48: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("api_name", "method", "endpoint")

app/modules/api_manager/schemas.py:52
  /home/spa/tobit-spa-ai/apps/api/app/modules/api_manager/schemas.py:52: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("param_schema", pre=True, always=True)

app/modules/api_manager/schemas.py:56
  /home/spa/tobit-spa-ai/apps/api/app/modules/api_manager/schemas.py:56: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("runtime_policy", pre=True, always=True)

app/modules/api_manager/schemas.py:60
  /home/spa/tobit-spa-ai/apps/api/app/modules/api_manager/schemas.py:60: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("logic_spec", pre=True, always=True)

app/modules/api_manager/schemas.py:78
  /home/spa/tobit-spa-ai/apps/api/app/modules/api_manager/schemas.py:78: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("api_name", "method", "endpoint", pre=True)

app/modules/api_manager/schemas.py:82
  /home/spa/tobit-spa-ai/apps/api/app/modules/api_manager/schemas.py:82: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("param_schema", pre=True)

app/modules/api_manager/schemas.py:88
  /home/spa/tobit-spa-ai/apps/api/app/modules/api_manager/schemas.py:88: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("runtime_policy", pre=True)

app/modules/api_manager/schemas.py:94
  /home/spa/tobit-spa-ai/apps/api/app/modules/api_manager/schemas.py:94: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    @validator("logic_spec", pre=True)

app/modules/api_manager/schemas.py:101
  /home/spa/tobit-spa-ai/apps/api/app/modules/api_manager/schemas.py:101: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class ApiDefinitionRead(BaseModel):

app/modules/api_manager/schemas.py:201
  /home/spa/tobit-spa-ai/apps/api/app/modules/api_manager/schemas.py:201: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class ApiExecLogRead(BaseModel):

main.py:82
  /home/spa/tobit-spa-ai/apps/api/main.py:82: DeprecationWarning: 
          on_event is deprecated, use lifespan event handlers instead.
  
          Read more about it in the
          [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).
          
    @app.on_event("startup")

.venv/lib/python3.12/site-packages/fastapi/applications.py:4576
.venv/lib/python3.12/site-packages/fastapi/applications.py:4576
  /home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/fastapi/applications.py:4576: DeprecationWarning: 
          on_event is deprecated, use lifespan event handlers instead.
  
          Read more about it in the
          [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).
          
    return self.router.on_event(event_type)

main.py:119
  /home/spa/tobit-spa-ai/apps/api/main.py:119: DeprecationWarning: 
          on_event is deprecated, use lifespan event handlers instead.
  
          Read more about it in the
          [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).
          
    @app.on_event("shutdown")

tests/test_api_keys.py: 19 warnings
  /home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/main.py:632: SAWarning: This declarative base already contains a class with the same class name and module name as apps.api.app.modules.auth.models.TbUser, and will be replaced in the string-lookup table.
    DeclarativeMeta.__init__(cls, classname, bases, dict_, **kw)

tests/test_api_keys.py: 19 warnings
  /home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/main.py:632: SAWarning: This declarative base already contains a class with the same class name and module name as apps.api.app.modules.auth.models.TbRefreshToken, and will be replaced in the string-lookup table.
    DeclarativeMeta.__init__(cls, classname, bases, dict_, **kw)

tests/test_api_keys.py: 19 warnings
  /home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/main.py:632: SAWarning: This declarative base already contains a class with the same class name and module name as apps.api.app.modules.api_keys.models.TbApiKey, and will be replaced in the string-lookup table.
    DeclarativeMeta.__init__(cls, classname, bases, dict_, **kw)

tests/test_audit_log.py: 2 warnings
tests/test_ops_executor_tool_contracts.py: 1 warning
tests/test_ops_service.py: 9 warnings
tests/test_trace_id.py: 3 warnings
  /home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/pydantic/fields.py:747: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    return fac()

tests/test_ci_list_llm_output.py::test_llm_list_payload_forces_list_intent
tests/test_ci_list_llm_output.py::test_llm_list_default_limit_applies
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/planner/planner_llm.py:477: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    plan.list = plan.list.copy(update={"enabled": True, "limit": limit_int, "offset": offset_int})

tests/test_ci_list_llm_output.py::test_llm_list_payload_forces_list_intent
tests/test_ci_list_llm_output.py::test_llm_list_default_limit_applies
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/planner/planner_llm.py:479: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    plan.output = plan.output.copy(update={"blocks": ["table"], "primary": "table"})

tests/test_ci_list_llm_output.py::test_llm_list_payload_forces_list_intent
tests/test_ci_list_llm_output.py::test_llm_list_default_limit_applies
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/planner/planner_llm.py:480: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    plan.primary = plan.primary.copy(update={"keywords": []})

tests/test_ci_list_llm_output.py::test_llm_list_payload_forces_list_intent
tests/test_ci_list_llm_output.py::test_llm_list_default_limit_applies
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/planner/planner_llm.py:481: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    plan.secondary = plan.secondary.copy(update={"keywords": []})

tests/test_ci_runner_tool_contracts.py::TestToolCallContract::test_tool_call_serialization
  /home/spa/tobit-spa-ai/apps/api/tests/test_ci_runner_tool_contracts.py:49: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    call_dict = tool_call.dict()

tests/test_ci_runner_tool_contracts.py::TestToolCallTrace::test_multiple_tool_calls_accumulation
tests/test_ci_runner_tool_contracts.py::TestToolCallTrace::test_multiple_tool_calls_accumulation
tests/test_ci_runner_tool_contracts.py::TestToolCallTrace::test_multiple_tool_calls_accumulation
  /home/spa/tobit-spa-ai/apps/api/tests/test_ci_runner_tool_contracts.py:102: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    serialized = [call.dict() for call in tool_calls]

tests/test_ci_runner_tool_contracts.py::TestToolCallTrace::test_tool_calls_with_errors
tests/test_ci_runner_tool_contracts.py::TestToolCallTrace::test_tool_calls_with_errors
  /home/spa/tobit-spa-ai/apps/api/tests/test_ci_runner_tool_contracts.py:131: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    call_dicts = [call.dict() for call in tool_calls]

tests/test_health.py::test_health_endpoint_structure
tests/test_hello.py::test_hello_endpoint_structure
tests/test_trace_id.py::test_ops_query_includes_trace_id
tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
tests/test_trace_id.py::test_trace_id_persists_across_requests
tests/test_trace_id.py::test_parent_trace_id_in_response
  /home/spa/tobit-spa-ai/apps/api/schemas/common.py:24: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    return cls(time=datetime.utcnow(), code=code, message=message, data=data)

tests/test_ops_executor_tool_contracts.py::TestExecutorResultStructure::test_executor_result_serialization
  /home/spa/tobit-spa-ai/apps/api/tests/test_ops_executor_tool_contracts.py:65: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    result_dict = result.dict()

tests/test_ops_executor_tool_contracts.py::TestExecutorBackwardCompatibility::test_normalize_real_result_with_executor_result
tests/test_ops_service.py::test_handle_ops_query_real_mode_fallbacks_and_flags_error
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/executors/metric_executor.py:63: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    blocks=[markdown.dict()],

tests/test_ops_executor_tool_contracts.py::TestToolCallSerialization::test_executor_result_tool_calls_serialize_correctly
  /home/spa/tobit-spa-ai/apps/api/tests/test_ops_executor_tool_contracts.py:194: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    serialized = result.dict()

tests/test_ops_executor_tool_contracts.py::TestReferenceExtraction::test_reference_extraction_from_references_block
  /home/spa/tobit-spa-ai/apps/api/tests/test_ops_executor_tool_contracts.py:226: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    block_dict = references_block.dict()

tests/test_ops_executor_tool_contracts.py::TestReferenceExtraction::test_empty_references_handling
tests/test_ops_executor_tool_contracts.py::TestReferenceExtraction::test_empty_references_handling
  /home/spa/tobit-spa-ai/apps/api/tests/test_ops_executor_tool_contracts.py:245: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    blocks_dict = [block.dict() if hasattr(block, "dict") else block for block in blocks]

tests/test_ops_service.py::test_ops_metric_real_blocks_shape
tests/test_ops_service.py::test_ops_all_langgraph_without_key_falls_back
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/executors/metric_executor.py:127: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    references.append(item.dict())

tests/test_ops_service.py::test_ops_metric_real_blocks_shape
tests/test_ops_service.py::test_ops_metric_real_blocks_shape
tests/test_ops_service.py::test_ops_metric_real_blocks_shape
tests/test_ops_service.py::test_ops_all_langgraph_without_key_falls_back
tests/test_ops_service.py::test_ops_all_langgraph_without_key_falls_back
tests/test_ops_service.py::test_ops_all_langgraph_without_key_falls_back
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/executors/metric_executor.py:130: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    blocks_dict = [block.dict() if hasattr(block, "dict") else block for block in blocks]

tests/test_ops_service.py::test_ops_hist_real_blocks_shape
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/executors/hist_executor.py:123: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    references_list.append(item.dict())

tests/test_ops_service.py::test_ops_hist_real_blocks_shape
tests/test_ops_service.py::test_ops_hist_real_blocks_shape
tests/test_ops_service.py::test_ops_hist_real_blocks_shape
tests/test_ops_service.py::test_ops_hist_real_blocks_shape
tests/test_ops_service.py::test_ops_hist_real_blocks_shape
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/executors/hist_executor.py:126: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    blocks_dict = [block.dict() if hasattr(block, "dict") else block for block in blocks]

tests/test_ops_service.py::test_ops_graph_real_blocks_shape
tests/test_ops_service.py::test_ops_all_langgraph_without_key_falls_back
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/executors/graph_executor.py:131: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    references_list.append(item.dict())

tests/test_ops_service.py::test_ops_graph_real_blocks_shape
tests/test_ops_service.py::test_ops_graph_real_blocks_shape
tests/test_ops_service.py::test_ops_graph_real_blocks_shape
tests/test_ops_service.py::test_ops_all_langgraph_without_key_falls_back
tests/test_ops_service.py::test_ops_all_langgraph_without_key_falls_back
tests/test_ops_service.py::test_ops_all_langgraph_without_key_falls_back
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/executors/graph_executor.py:137: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    blocks_dict = [block.dict() if hasattr(block, "dict") else block for block in blocks]

tests/test_plan_multistep.py: 13 warnings
tests/test_trace_id.py: 1 warning
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/planner/validator.py:348: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    normalized = plan.copy()

tests/test_plan_multistep.py::TestPlanValidation::test_validate_simple_plan_success
tests/test_plan_multistep.py::TestPlanValidation::test_validate_with_custom_budget
tests/test_plan_multistep.py::TestPlanValidation::test_validate_multistep_disabled
tests/test_plan_multistep.py::TestPlanValidation::test_validate_complex_plan
tests/test_plan_multistep.py::TestPlanValidation::test_validate_timeout_valid_range
tests/test_plan_multistep.py::TestPlanValidation::test_validate_max_depth_valid_range
tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/planner/validator.py:388: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    "primary": normalized.primary.copy(update={"limit": primary_limit}),

tests/test_plan_multistep.py::TestPlanValidation::test_validate_simple_plan_success
tests/test_plan_multistep.py::TestPlanValidation::test_validate_with_custom_budget
tests/test_plan_multistep.py::TestPlanValidation::test_validate_multistep_disabled
tests/test_plan_multistep.py::TestPlanValidation::test_validate_complex_plan
tests/test_plan_multistep.py::TestPlanValidation::test_validate_timeout_valid_range
tests/test_plan_multistep.py::TestPlanValidation::test_validate_max_depth_valid_range
tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/planner/validator.py:390: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    "graph": normalized.graph.copy(update={"view": graph_view, "depth": clamped_depth}),

tests/test_plan_multistep.py::TestPlanValidation::test_validate_simple_plan_success
tests/test_plan_multistep.py::TestPlanValidation::test_validate_with_custom_budget
tests/test_plan_multistep.py::TestPlanValidation::test_validate_multistep_disabled
tests/test_plan_multistep.py::TestPlanValidation::test_validate_complex_plan
tests/test_plan_multistep.py::TestPlanValidation::test_validate_timeout_valid_range
tests/test_plan_multistep.py::TestPlanValidation::test_validate_max_depth_valid_range
tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/planner/validator.py:386: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    normalized = normalized.copy(

tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_save_draft_requires_auth
tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_invalid_token_rejected
tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_missing_authorization_header_error
  /home/spa/tobit-spa-ai/apps/api/core/auth.py:42: DeprecationWarning: 
           You probably want to use `session.exec()` instead of `session.query()`.
  
          `session.exec()` is SQLModel's own short version with increased type
          annotations.
  
          Or otherwise you might want to use `session.execute()` instead of
          `session.query()`.
          
    session.query(TbUser).filter(TbUser.username == "admin@tobit.local")

tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_save_draft_requires_auth
  /home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py:81: SADeprecationWarning: Object <sqlalchemy.orm.query.Query object at 0x7f4b8f104c50> should not be used directly in a SQL statement context, such as passing to methods such as session.execute().  This usage will be disallowed in a future release.  Please use Core select() / update() / delete() etc. with Session.execute() and other statement execution methods.
    results = super().execute(

tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_invalid_token_rejected
  /home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py:81: SADeprecationWarning: Object <sqlalchemy.orm.query.Query object at 0x7f4b8f106d50> should not be used directly in a SQL statement context, such as passing to methods such as session.execute().  This usage will be disallowed in a future release.  Please use Core select() / update() / delete() etc. with Session.execute() and other statement execution methods.
    results = super().execute(

tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_missing_authorization_header_error
  /home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/sqlmodel/orm/session.py:81: SADeprecationWarning: Object <sqlalchemy.orm.query.Query object at 0x7f4b8d908d10> should not be used directly in a SQL statement context, such as passing to methods such as session.execute().  This usage will be disallowed in a future release.  Please use Core select() / update() / delete() etc. with Session.execute() and other statement execution methods.
    results = super().execute(

tests/test_security_headers.py::TestCSRFMiddleware::test_csrf_token_in_header
tests/test_security_headers.py::TestCSRFMiddleware::test_csrf_token_mismatch
tests/test_security_headers.py::TestIntegration::test_full_security_stack
  /home/spa/tobit-spa-ai/apps/api/.venv/lib/python3.12/site-packages/starlette/testclient.py:445: DeprecationWarning: Setting per-request cookies=<...> is being deprecated, because the expected behaviour on cookie persistence is ambiguous. Set cookies directly on the client instance instead.
    return super().request(

tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/planner/planner_llm.py:501: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    plan.primary = plan.primary.copy(update={"keywords": keywords})

tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/planner/planner_llm.py:511: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    plan.aggregate = plan.aggregate.copy(update={"filters": aggregate_filters})

tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/planner/planner_llm.py:517: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    plan.secondary = plan.secondary.copy(update={"keywords": _extract_keywords(secondary_text)})

tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/planner/planner_llm.py:541: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    plan.graph = plan.graph.copy(update={"user_requested_depth": requested_depth})

tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/planner/planner_llm.py:570: PydanticDeprecatedSince20: The `copy` method is deprecated; use `model_copy` instead. See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    plan = plan.copy(update={"output": plan.output.copy(update=_build_output_updates(output_types))})

tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/orchestrator/runner.py:360: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    return [r.dict() for r in result.records]

tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/orchestrator/runner.py:959: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    "plan_raw": self.plan_raw.dict(),

tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/orchestrator/runner.py:960: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    "plan_validated": self.plan.dict(),

tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/services/ci/orchestrator/runner.py:962: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    "tool_calls": [call.dict() for call in self.tool_calls],

tests/test_trace_id.py::test_ops_ci_ask_includes_trace_id
  /home/spa/tobit-spa-ai/apps/api/app/modules/ops/router.py:408: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    response_payload = ResponseEnvelope.success(data=response.dict())

tests/test_ui_actions_with_traces.py::test_create_maintenance_ticket_with_state_patch
  /home/spa/tobit-spa-ai/apps/api/tests/test_ui_actions_with_traces.py:124: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    parent_trace_id = f"screen-render-{datetime.utcnow().timestamp()}"

tests/unit/test_document_processor.py::TestDocumentExportService::test_export_to_json
tests/unit/test_document_processor.py::TestDocumentExportService::test_export_chunks_format_selection
  /home/spa/tobit-spa-ai/apps/api/app/modules/document_processor/services/export_service.py:47: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    "exported_at": datetime.utcnow().isoformat(),

tests/unit/test_document_processor.py::TestDocumentExportService::test_export_to_markdown
tests/unit/test_document_processor.py::TestDocumentExportService::test_export_chunks_format_selection
  /home/spa/tobit-spa-ai/apps/api/app/modules/document_processor/services/export_service.py:108: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    f"Exported: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}",

tests/unit/test_document_processor.py::TestDocumentExportService::test_export_to_text
tests/unit/test_document_processor.py::TestDocumentExportService::test_export_chunks_format_selection
  /home/spa/tobit-spa-ai/apps/api/app/modules/document_processor/services/export_service.py:150: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    f"Exported: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}",

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/test_api_keys.py::TestApiKeyCrud::test_validate_api_key_expired
FAILED tests/test_audit_log.py::test_list_audit_logs_returns_matching_entries
FAILED tests/test_audit_log.py::test_get_audit_logs_by_trace_and_parent - sql...
FAILED tests/test_operation_settings.py::test_get_all_operation_settings - as...
FAILED tests/test_operation_settings.py::test_get_ops_mode_setting - assert 5...
FAILED tests/test_operation_settings.py::test_update_ops_mode_setting - asser...
FAILED tests/test_operation_settings.py::test_update_boolean_setting - assert...
FAILED tests/test_operation_settings.py::test_setting_persistence_across_requests
FAILED tests/test_ops_service.py::test_ops_all_real_blocks_shape - AssertionE...
FAILED tests/test_ops_service.py::test_ops_all_langgraph_without_key_falls_back
FAILED tests/test_ops_service.py::test_ops_all_partial_failure - assert ('Err...
FAILED tests/test_permissions.py::TestRolePermissions::test_manager_permissions
FAILED tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_save_draft_requires_auth
FAILED tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_invalid_token_rejected
FAILED tests/test_screen_editor_auth.py::TestScreenEditorAuth::test_missing_authorization_header_error
FAILED tests/test_ui_actions_with_traces.py::test_list_maintenance_filtered_with_state_patch
FAILED tests/test_ui_actions_with_traces.py::test_create_maintenance_ticket_with_state_patch
ERROR tests/test_ci_management.py::TestCIChangeCreation::test_create_change_basic
ERROR tests/test_ci_management.py::TestCIChangeCreation::test_create_change_minimal
ERROR tests/test_ci_management.py::TestCIChangeCreation::test_create_change_all_types
ERROR tests/test_ci_management.py::TestCIChangeCreation::test_get_change_by_id
ERROR tests/test_ci_management.py::TestCIChangeCreation::test_get_change_not_found
ERROR tests/test_ci_management.py::TestCIChangeCreation::test_list_changes_all
ERROR tests/test_ci_management.py::TestCIChangeCreation::test_list_changes_filter_by_ci_id
ERROR tests/test_ci_management.py::TestCIChangeCreation::test_list_changes_filter_by_status
ERROR tests/test_ci_management.py::TestCIChangeCreation::test_list_changes_pagination
ERROR tests/test_ci_management.py::TestCIChangeApproval::test_approve_change
ERROR tests/test_ci_management.py::TestCIChangeApproval::test_reject_change
ERROR tests/test_ci_management.py::TestCIChangeApproval::test_approve_non_existent_change
ERROR tests/test_ci_management.py::TestCIChangeApproval::test_apply_change
ERROR tests/test_ci_management.py::TestCIChangeApproval::test_apply_unapproved_change_fails
ERROR tests/test_ci_management.py::TestCIChangeHistory::test_get_change_history_single_ci
ERROR tests/test_ci_management.py::TestCIChangeHistory::test_change_history_counts
ERROR tests/test_ci_management.py::TestCIChangeHistory::test_change_history_pending_approvals
ERROR tests/test_ci_management.py::TestCIIntegrityValidation::test_create_integrity_issue
ERROR tests/test_ci_management.py::TestCIIntegrityValidation::test_get_integrity_issues
ERROR tests/test_ci_management.py::TestCIIntegrityValidation::test_filter_integrity_issues_unresolved
ERROR tests/test_ci_management.py::TestCIIntegrityValidation::test_resolve_integrity_issue
ERROR tests/test_ci_management.py::TestCIIntegrityValidation::test_validate_ci_integrity
ERROR tests/test_ci_management.py::TestCIIntegrityValidation::test_get_integrity_summary
ERROR tests/test_ci_management.py::TestCIDuplicateDetection::test_create_duplicate_entry
ERROR tests/test_ci_management.py::TestCIDuplicateDetection::test_get_duplicates_for_ci
ERROR tests/test_ci_management.py::TestCIDuplicateDetection::test_confirm_duplicate
ERROR tests/test_ci_management.py::TestCIDuplicateDetection::test_duplicate_statistics
ERROR tests/test_ci_management.py::TestCIChangeStatistics::test_get_change_statistics
ERROR tests/test_ci_management.py::TestCIChangeStatistics::test_change_statistics_time_range
ERROR tests/test_ci_management.py::TestCIIntegrationWorkflow::test_complete_change_workflow
ERROR tests/test_ci_management.py::TestCIIntegrationWorkflow::test_duplicate_detection_to_merge_workflow
ERROR tests/test_ci_management.py::TestCIIntegrationWorkflow::test_integrity_validation_workflow
ERROR tests/test_ci_management.py::TestTenantIsolation::test_changes_isolated_by_tenant
ERROR tests/test_ci_management.py::TestTenantIsolation::test_issues_isolated_by_tenant
ERROR tests/test_ci_management.py::TestTenantIsolation::test_duplicates_isolated_by_tenant
ERROR tests/test_documents.py::test_upload_creates_metadata_and_list - sqlalc...
ERROR tests/test_documents.py::test_document_stream_done_contains_references
ERROR tests/test_permissions.py::TestRolePermissions::test_initialize_role_permissions
ERROR tests/test_permissions.py::TestPermissionChecks::test_admin_check_permission
ERROR tests/test_permissions.py::TestPermissionChecks::test_developer_can_create_api
ERROR tests/test_permissions.py::TestPermissionChecks::test_developer_cannot_delete_api
ERROR tests/test_permissions.py::TestPermissionChecks::test_viewer_can_read
ERROR tests/test_permissions.py::TestPermissionChecks::test_viewer_cannot_write
ERROR tests/test_permissions.py::TestResourcePermissions::test_grant_resource_permission
ERROR tests/test_permissions.py::TestResourcePermissions::test_grant_resource_type_permission
ERROR tests/test_permissions.py::TestResourcePermissions::test_check_resource_specific_permission
ERROR tests/test_permissions.py::TestResourcePermissions::test_check_resource_type_permission
ERROR tests/test_permissions.py::TestResourcePermissions::test_revoke_resource_permission
ERROR tests/test_permissions.py::TestPermissionExpiration::test_expired_permission_denied
ERROR tests/test_permissions.py::TestPermissionExpiration::test_future_permission_allowed
ERROR tests/test_permissions.py::TestListPermissions::test_list_user_permissions
===== 17 failed, 317 passed, 7 skipped, 218 warnings, 51 errors in 56.53s ======
